{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f557b8-b885-4481-8f27-22df38b23332",
   "metadata": {},
   "source": [
    "# Manipulação de dados tabulares - Pandas e alternativas\n",
    "> Pandas, SQL e comparações (Dask, Polars, Datatable, PandaSQL e DuckDB)\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [demo, sql, pandas, duckdb, dask, datatable, polars, tabelas, benchmarks]\n",
    "- image: https://images.unsplash.com/photo-1526716121440-dc3b4f254a0a?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=700&q=80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0fd0a8-cf10-40a8-bfd6-f1c81d3e932a",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Em machine learning, a gente sempre comenta como nós precisamos de dados. E precisamos de dados bem curados. Talvez você até já tenha ouvido a frase: \"garbage in, garbage out\", né?\n",
    "\n",
    "Na vida real, isso é bem verdade. E gastar mais tempo criando novas features, ou limpando os dados acaba muitas vezes impactando os resultados dos modelos mais que qualquer outra coisa. Não é à toa que grande parte dos ganhadores das competições do [Kaggle](https://www.kaggle.com/) usam os mesmo modelos - [ensembles](https://towardsdatascience.com/xgboost-lightgbm-and-other-kaggle-competition-favorites-6212e8b0e835). E, na maior parte, quem ganha são os que tem os melhores dados.\n",
    "\n",
    "Então, antes de mexermos em modelos, temos que manipular os dados. Mas então como manipular esses dados?\n",
    "\n",
    "## Pandas\n",
    "\n",
    "A resposta mais comum é [pandas](https://pandas.pydata.org/)! Se você já mexeu com dados, provavelmente já ouviu falar sobre essa biblioteca. Ela é, de longe, a mais popular pra manipulação de dados tabulares. Ela foi construída em cima de [NumPy](https://numpy.org/), que usa C++ por trás dos panos.\n",
    "\n",
    "> Em Python temos o GIL que limita o uso de threads pra evitar que mais de um thread tente escrever/apagar as mesmas partes da memória ao mesmo tempo ([condição de corrida](https://pt.wikipedia.org/wiki/Condi%C3%A7%C3%A3o_de_corrida)). Quando usamos Numpy e chegamos no nível de C, o programa não está sujeito ao GIL e então podemos parallelizar as coisas.\n",
    "\n",
    "Mas se você já ouviu falar de pandas, é capaz que não tenha ouvido coisas boas. Especialmente quem vem da linguagem de programação em R usando o [dplyr](https://dplyr.tidyverse.org/) tem o que falar 😅. O número de perguntas no [StackOverflow](https://stackoverflow.com/) relacionadas à pandas cresceu bastante durante os anos. Parte pelo aumento em popularidade da biblioteca, mas parte pela dificuldade da API do pandas.\n",
    "\n",
    "![](https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/copied_from_nb/2021-06-13-pandas_and_alternatives/stackoverflow_questions.png \"Fonte: https://insights.stackoverflow.com/trends?tags=pandas%2Cnumpy%2Cdask%2Cspacy%2Ctensorflow%2Cpytorch%2Cscikit-learn%2Cpyspark%2Cpostgresql\")\n",
    "\n",
    "Além disso, existem vários pontos em que podemos otimizar a performance de pandas. Isso pelo fato da biblioteca ter sido criada em cima de uma outra. Vamos dar uma olhada na performance de pandas.\n",
    "\n",
    "### Dados\n",
    "\n",
    "Vamos usar o TPC-H dataset, focando no `lineitem` e `orders`, que são as maiores tabelas que somam 1GB. Para medir o tempo de execução, vamos unir as duas tabelas, filtram as linhas, agrupam os dados e computamos alguns dados agregados (máximo, mínimo, etc.). O que estamos fazendo em si não é muito importante, mas é um tipo de transformação que encontraríamos na vida real.\n",
    "\n",
    "Vamos tentar otimizar tudo ao máximo, e vamos focar na transformação dos dados\n",
    "\n",
    "- Vamos medir o tempo da transformação (excluindo o tempo de ler os dados)\n",
    "- Vamos filtrar o quanto antes\n",
    "- Vamos encadear operações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53cacd2-39d7-4034-ad7f-f3eb277bc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "!pip install duckdb pandas 'dask[dataframe]' datatable polars pandasql > /dev/null\n",
    "!wget -q https://github.com/cwida/duckdb-data/releases/download/v1.0/lineitemsf1.snappy.parquet\n",
    "!wget -q https://github.com/cwida/duckdb-data/releases/download/v1.0/orders.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3294070f-a9ce-42c2-88d4-1138337aab2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import dask.dataframe as dd\n",
    "import datatable as dt\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datatable import by, f, g, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56fcd81-904b-42ec-94a3-f3bde71fe336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "lineitem = pd.read_parquet(\"lineitemsf1.snappy.parquet\")\n",
    "orders = pd.read_parquet(\"orders.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c75cee5-fb0f-48e2-99ed-3bee6daadde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.63 s, sys: 2.34 s, total: 7.97 s\n",
      "Wall time: 8.09 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">l_extendedprice</th>\n",
       "      <th colspan=\"4\" halign=\"left\">l_quantity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_returnflag</th>\n",
       "      <th>l_linestatus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>F</th>\n",
       "      <td>2.267720e+10</td>\n",
       "      <td>904.0</td>\n",
       "      <td>104949.5</td>\n",
       "      <td>38303.426664</td>\n",
       "      <td>15123892</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>25.545346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">N</th>\n",
       "      <th>F</th>\n",
       "      <td>5.965302e+08</td>\n",
       "      <td>920.0</td>\n",
       "      <td>104049.0</td>\n",
       "      <td>38461.006847</td>\n",
       "      <td>397729</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>25.643391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>4.473406e+10</td>\n",
       "      <td>901.0</td>\n",
       "      <td>104749.5</td>\n",
       "      <td>38267.695102</td>\n",
       "      <td>29826993</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>25.515466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <td>2.268310e+10</td>\n",
       "      <td>906.0</td>\n",
       "      <td>104899.5</td>\n",
       "      <td>38240.140532</td>\n",
       "      <td>15126938</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>25.501645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          l_extendedprice                                 \\\n",
       "                                      sum    min       max          mean   \n",
       "l_returnflag l_linestatus                                                  \n",
       "A            F               2.267720e+10  904.0  104949.5  38303.426664   \n",
       "N            F               5.965302e+08  920.0  104049.0  38461.006847   \n",
       "             O               4.473406e+10  901.0  104749.5  38267.695102   \n",
       "R            F               2.268310e+10  906.0  104899.5  38240.140532   \n",
       "\n",
       "                          l_quantity                     \n",
       "                                 sum min max       mean  \n",
       "l_returnflag l_linestatus                                \n",
       "A            F              15123892   1  50  25.545346  \n",
       "N            F                397729   1  50  25.643391  \n",
       "             O              29826993   1  50  25.515466  \n",
       "R            F              15126938   1  50  25.501645  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lineitem.merge(orders, left_on=\"l_orderkey\", right_on=\"o_orderkey\").pipe(\n",
    "    lambda df: df.copy()[\n",
    "        (df[\"l_shipdate\"] < \"1998-09-02\")\n",
    "        & (df[\"o_orderpriority\"].isin((\"1-URGENT\", \"2-HIGH\")))\n",
    "    ]\n",
    ").groupby([\"l_returnflag\", \"l_linestatus\"]).agg(\n",
    "    {\n",
    "        \"l_extendedprice\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "        \"l_quantity\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01371b5e-4016-458f-af98-0f299fbec2a4",
   "metadata": {},
   "source": [
    "Executando todas essas transformações demorou 10.3 segundos. Mas podemos ser mais eficientes. Por exemplo, poderíamos esquecer várias colunas já que no fim só estamos interessados em `l_returnflag`, `l_linestatus`, `l_extendedprice` e `l_quantity` (além das colunas que usamos para filtrar os dados). Também somos ineficientes quando temos de filtrar e agregar os valores (escaneamos a tabela duas vezes, quando poderíamos fazer isso de uma vez só). Além disso, poderíamos melhorar na implementação de paralelismo e do algoritmo.\n",
    "\n",
    "Vamos então deixar pandas de lado e ver como podemos melhorar isso.\n",
    "\n",
    "![](https://media.giphy.com/media/EPcvhM28ER9XW/giphy.gif)\n",
    "\n",
    "## Dask\n",
    "\n",
    "[Dask](https://docs.dask.org/en/latest/dataframe.html) provavelmente é a primeira solução que vem à cabeça. Dask basicamente cria várias tabelas em pandas e vai paralelizando as operações em cores diferentes. Também é mais eficiente por usar [avaliação preguiçosa](https://pt.wikipedia.org/wiki/Avalia%C3%A7%C3%A3o_pregui%C3%A7osa) (lazy evaluation) - primeiro traçamos o que queremos fazer e depois mandamos o computador executar as transformações. Isso nos deixa otimizar a computação das transformações (por exemplo, podemos filtrar linhas antes de fazer qualquer outra coisa, mesmo que o código não represente isso).\n",
    "\n",
    "![](https://media.giphy.com/media/26ufnwz3wDUli7GU0/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaa8d7c-b80c-4c55-80e1-ead5986ebba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse\n",
    "# dask\n",
    "dd_lineitem = dd.from_pandas(lineitem, npartitions=1)\n",
    "dd_orders = dd.from_pandas(orders, npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254fef8b-cd23-48d5-a980-ff0d5facab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.14 s ± 20.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dd_lineitem.merge(dd_orders, left_on=\"l_orderkey\", right_on=\"o_orderkey\").pipe(\n",
    "    lambda df: df.copy()[\n",
    "        (df[\"l_shipdate\"] < \"1998-09-02\")\n",
    "        & (df[\"o_orderpriority\"].isin((\"1-URGENT\", \"2-HIGH\")))\n",
    "    ]\n",
    ").groupby([\"l_returnflag\", \"l_linestatus\"]).agg(\n",
    "    {\n",
    "        \"l_extendedprice\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "        \"l_quantity\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "    }\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b67e181-b1b3-4144-92d8-76a5e9b04b08",
   "metadata": {},
   "source": [
    "Usando Dask e com essas melhorias de parallelismo a gente ganha alguns segundos. O que faz Dask muito popular é o fato de ele imitar a API do Pandas. Aí fica muito mais fácil de pegar e começar a codar. Mas ainda assim, estamos usando Pandas. Temos espaços para melhorias.\n",
    "\n",
    "## Polars\n",
    "\n",
    "[Polars](https://pola-rs.github.io/polars-book/) é uma biblioteca implementada em [Rust](https://www.rust-lang.org/), que é muito eficiente em termos de velocidade e uso de memória. O lugar de Polars (de acordo com a documentação) é para quando os dados são muito grandes para Pandas mas muito pequenos para realizar as transformações num cluster de máquinas (Spark). Ou seja, se os dados são muito grandes pra sua máquina, mesmo depois de filtrar algumas entradas, precisamos procurar outras soluções (o que é verdade pra Dask e todas as outras bibliotecas que vamos ver aqui). E assim como Dask, Polars vai usar todas as threads da sua máquina.\n",
    "\n",
    "Uma outra idéia de Polars é permitir o use da [avaliação ansiosa](https://pt.wikipedia.org/wiki/Avalia%C3%A7%C3%A3o_ansiosa) (eager evaluation), como em Pandas e da [avaliação preguiçosa](https://pt.wikipedia.org/wiki/Avalia%C3%A7%C3%A3o_pregui%C3%A7osa) (lazy evaluation), como em Dask. A availação ansiosa é como em Pandas, e a API é bem parecida. A API da avaliação preguiçosa é um pouco diferente, e é otimizada pelos mesmo motivos que citamos quando falamos de Dask (paralelização e otimização das transformações).\n",
    "\n",
    "![](https://media.giphy.com/media/2FmmbTZMl6lQQ/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e183160a-2b1d-4a0c-b117-8ebf62ed0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse\n",
    "# polars\n",
    "pl_lineitem = pl.DataFrame(lineitem)\n",
    "pl_orders = pl.DataFrame(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8d60db-104d-44e7-9080-ba93704631ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 s ± 1.03 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pl_lineitem.join(pl_orders, left_on=\"l_orderkey\", right_on=\"o_orderkey\").filter(\n",
    "    (pl.col(\"l_shipdate\") < \"1998-09-02\")\n",
    "    & (\n",
    "        (pl.col(\"o_orderpriority\") == \"1-URGENT\")\n",
    "        | (pl.col(\"o_orderpriority\") == \"2-HIGH\")\n",
    "    )\n",
    ").groupby([\"l_returnflag\", \"l_linestatus\"]).agg(\n",
    "    {\n",
    "        \"l_extendedprice\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "        \"l_quantity\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9def685-67ab-4028-a8a5-10736ef9bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# using lazy eval\n",
    "import time\n",
    "\n",
    "pl_lineitem = pl_lineitem.lazy()\n",
    "pl_orders = pl_orders.lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3eecaf1-45d8-4647-9bf8-e93386c77769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1 \"class=\"dataframe \">\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "l_returnflag\n",
       "</th>\n",
       "<th>\n",
       "l_linestatus\n",
       "</th>\n",
       "<th>\n",
       "l_extendedprice_sum\n",
       "</th>\n",
       "<th>\n",
       "l_extendedprice_min\n",
       "</th>\n",
       "<th>\n",
       "l_extendedprice_max\n",
       "</th>\n",
       "<th>\n",
       "l_extendedprice_mean\n",
       "</th>\n",
       "<th>\n",
       "l_quantity_sum\n",
       "</th>\n",
       "<th>\n",
       "l_quantity_min\n",
       "</th>\n",
       "<th>\n",
       "l_quantity_max\n",
       "</th>\n",
       "<th>\n",
       "l_quantity_mean\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "\"N\"\n",
       "</td>\n",
       "<td>\n",
       "\"O\"\n",
       "</td>\n",
       "<td>\n",
       "4.473405541680963e10\n",
       "</td>\n",
       "<td>\n",
       "901\n",
       "</td>\n",
       "<td>\n",
       "1.047495e5\n",
       "</td>\n",
       "<td>\n",
       "3.8267695101622725e4\n",
       "</td>\n",
       "<td>\n",
       "29826993\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "50\n",
       "</td>\n",
       "<td>\n",
       "25.515466087014545\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "\"R\"\n",
       "</td>\n",
       "<td>\n",
       "\"F\"\n",
       "</td>\n",
       "<td>\n",
       "2.2683095360319317e10\n",
       "</td>\n",
       "<td>\n",
       "906\n",
       "</td>\n",
       "<td>\n",
       "1.048995e5\n",
       "</td>\n",
       "<td>\n",
       "3.824014053242183e4\n",
       "</td>\n",
       "<td>\n",
       "15126938\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "50\n",
       "</td>\n",
       "<td>\n",
       "25.501644539975555\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "\"A\"\n",
       "</td>\n",
       "<td>\n",
       "\"F\"\n",
       "</td>\n",
       "<td>\n",
       "2.2677199025699192e10\n",
       "</td>\n",
       "<td>\n",
       "904\n",
       "</td>\n",
       "<td>\n",
       "1.049495e5\n",
       "</td>\n",
       "<td>\n",
       "3.830342666419926e4\n",
       "</td>\n",
       "<td>\n",
       "15123892\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "50\n",
       "</td>\n",
       "<td>\n",
       "25.54534567707304\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "\"N\"\n",
       "</td>\n",
       "<td>\n",
       "\"F\"\n",
       "</td>\n",
       "<td>\n",
       "5.965302162000039e8\n",
       "</td>\n",
       "<td>\n",
       "920\n",
       "</td>\n",
       "<td>\n",
       "1.04049e5\n",
       "</td>\n",
       "<td>\n",
       "3.8461006847195604e4\n",
       "</td>\n",
       "<td>\n",
       "397729\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "50\n",
       "</td>\n",
       "<td>\n",
       "25.643391360412636\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (4, 10)\n",
       "╭───────────┬───────────┬───────────┬───────────┬─────┬───────────┬──────────┬──────────┬──────────╮\n",
       "│ l_returnf ┆ l_linesta ┆ l_extende ┆ l_extende ┆ ... ┆ l_quantit ┆ l_quanti ┆ l_quanti ┆ l_quanti │\n",
       "│ lag       ┆ tus       ┆ dprice_su ┆ dprice_mi ┆     ┆ y_sum     ┆ ty_min   ┆ ty_max   ┆ ty_mean  │\n",
       "│ ---       ┆ ---       ┆ m         ┆ n         ┆     ┆ ---       ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str       ┆ str       ┆ ---       ┆ ---       ┆     ┆ i64       ┆ i64      ┆ i64      ┆ f64      │\n",
       "│           ┆           ┆ f64       ┆ f64       ┆     ┆           ┆          ┆          ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═════╪═══════════╪══════════╪══════════╪══════════╡\n",
       "│ \"N\"       ┆ \"O\"       ┆ 4.4734055 ┆ 901       ┆ ... ┆ 29826993  ┆ 1        ┆ 50       ┆ 25.51546 │\n",
       "│           ┆           ┆ 41680963e ┆           ┆     ┆           ┆          ┆          ┆ 60870145 │\n",
       "│           ┆           ┆ 10        ┆           ┆     ┆           ┆          ┆          ┆ 45       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ \"R\"       ┆ \"F\"       ┆ 2.2683095 ┆ 906       ┆ ... ┆ 15126938  ┆ 1        ┆ 50       ┆ 25.50164 │\n",
       "│           ┆           ┆ 360319317 ┆           ┆     ┆           ┆          ┆          ┆ 45399755 │\n",
       "│           ┆           ┆ e10       ┆           ┆     ┆           ┆          ┆          ┆ 55       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ \"A\"       ┆ \"F\"       ┆ 2.2677199 ┆ 904       ┆ ... ┆ 15123892  ┆ 1        ┆ 50       ┆ 25.54534 │\n",
       "│           ┆           ┆ 025699192 ┆           ┆     ┆           ┆          ┆          ┆ 56770730 │\n",
       "│           ┆           ┆ e10       ┆           ┆     ┆           ┆          ┆          ┆ 4        │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ \"N\"       ┆ \"F\"       ┆ 5.9653021 ┆ 920       ┆ ... ┆ 397729    ┆ 1        ┆ 50       ┆ 25.64339 │\n",
       "│           ┆           ┆ 62000039e ┆           ┆     ┆           ┆          ┆          ┆ 13604126 │\n",
       "│           ┆           ┆ 8         ┆           ┆     ┆           ┆          ┆          ┆ 36       │\n",
       "╰───────────┴───────────┴───────────┴───────────┴─────┴───────────┴──────────┴──────────┴──────────╯"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "start = time.monotonic()\n",
    "\n",
    "# lazy dataframe\n",
    "_df = (\n",
    "    pl_lineitem.join(pl_orders, left_on=\"l_orderkey\", right_on=\"o_orderkey\").filter(\n",
    "        (pl.col(\"l_shipdate\") < \"1998-09-02\")\n",
    "        & (\n",
    "            (pl.col(\"o_orderpriority\") == \"1-URGENT\")\n",
    "            | (pl.col(\"o_orderpriority\") == \"2-HIGH\")\n",
    "        )\n",
    "    )\n",
    "    # could not delay collection - error (not finding `o_orderkey` column)\n",
    "    .collect()\n",
    ")\n",
    "# eager dataframe\n",
    "_df = _df.groupby([\"l_returnflag\", \"l_linestatus\"]).agg(\n",
    "    [\n",
    "        pl.sum(\"l_extendedprice\"),\n",
    "        pl.min(\"l_extendedprice\"),\n",
    "        pl.max(\"l_extendedprice\"),\n",
    "        pl.mean(\"l_extendedprice\"),\n",
    "        pl.sum(\"l_quantity\"),\n",
    "        pl.min(\"l_quantity\"),\n",
    "        pl.max(\"l_quantity\"),\n",
    "        pl.mean(\"l_quantity\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Wall time: {time.monotonic() - start:.2f}s\")\n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c768f-d635-4eee-9b39-f8415d12fadc",
   "metadata": {},
   "source": [
    "Com isso conseguimos reduzir o tempo em **<30%** (comparando com Dask)! Então, o que ainda podemos melhorar? Quando usamos a avaliação ansiosa, ainda podemos melhorar a execução das queries. Além disso, a biblioteca não tem tantas funções quanto Pandas (e consequentemente Dask). E falando em Pandas, se a API é igual, e você não está satisfeito com ela, provavelmente não vai estar muito contente com a API do Polars também.\n",
    "\n",
    "## Datatable\n",
    "\n",
    "Se você gosta de R e está fazendo a transição para python, talvez essa seja uma boa opção. Datatable é inspirada pela biblioteca em R [data.table](https://rdatatable.gitlab.io/data.table/). A API é parecida, e tem várias otimizações para tratar com dados grandes. Que cabem **ou não** em memória (dados que não caberiam em memória usando Pandas cabem quando usamos Datatable). Essa biblioteca também usa algoritmos que supportam o paralelismo em diferentes [threads](https://pt.wikipedia.org/wiki/Thread_(computa%C3%A7%C3%A3o)), aumentando de novo a velocidade de execução.\n",
    "\n",
    "![](https://media.giphy.com/media/rGlAZysKBcjRCkAX7S/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7807673d-df77-40c0-b1b7-a0d8addb1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse\n",
    "# datatable\n",
    "dt_lineitem = dt.Frame(lineitem)\n",
    "dt_orders = dt.Frame(orders)\n",
    "\n",
    "# preparação\n",
    "dt_lineitem.names = {\"l_orderkey\": \"orderkey\"}\n",
    "dt_orders.names = {\"o_orderkey\": \"orderkey\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd7f90b-dd3b-4cea-b45f-aacca1b03ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32 s ± 106 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# dt_lineitem.key = \"orderkey\"  # não podemos usar como `key` existem valores repetidos\n",
    "dt_orders.key = \"orderkey\"\n",
    "\n",
    "# executando a query\n",
    "dt_lineitem[\n",
    "    (g.o_orderpriority == \"1-URGENT\") | (g.o_orderpriority == \"2-HIGH\"),\n",
    "    :,\n",
    "    join(dt_orders),\n",
    "][\n",
    "    :,\n",
    "    {\n",
    "        \"sum(l_extendedprice)\": dt.sum(f.l_extendedprice),\n",
    "        \"min(l_extendedprice)\": dt.min(f.l_extendedprice),\n",
    "        \"max(l_extendedprice)\": dt.max(f.l_extendedprice),\n",
    "        \"mean(l_extendedprice)\": dt.mean(f.l_extendedprice),\n",
    "        \"sum(l_quantity)\": dt.sum(f.l_quantity),\n",
    "        \"min(l_quantity)\": dt.min(f.l_quantity),\n",
    "        \"max(l_quantity)\": dt.max(f.l_quantity),\n",
    "        \"mean(l_quantity)\": dt.mean(f.l_quantity),\n",
    "    },\n",
    "    by(f.l_returnflag, f.l_linestatus),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ffb2ec-d780-47be-9cd9-c86890bf82b3",
   "metadata": {},
   "source": [
    "**~10%** do tempo (comparando com Pandas)! Você pode reparar também como a API muda bastante. Pessoalmente, foi um pouco mais trabalhoso pra escrever o código equivalente, mas na documentação eles também oferecem uma comparação da API do Datatable com a API do Pandas, o que ajuda bastante.\n",
    "\n",
    "Além disso, eles também comparam a API do Datatable com SQL. Afinal de contas, SQL é muito usado até hoje, e mais familiar pra muitas pessoas. Além disso, SQL tem sido usado bastante através dos anos e oferece uma maneira eficiente de manipular dados tabulares. Quando os dados aumentam ainda mais e nos tornamos para um método distribuído como [Spark](https://spark.apache.org/) ainda podemos usar [SparkSQL](https://spark.apache.org/docs/latest/sql-programming-guide.html). Spark e SQL precisam de um [cluster](https://pt.wikipedia.org/wiki/Cluster) e de um [servidor](https://pt.wikipedia.org/wiki/Servidor_(computa%C3%A7%C3%A3o)) próprio pra executar as transformações. Mas existem algumas bibliotecas que nos permitem usar SQL para manipular dados em dataframes.\n",
    "\n",
    "## PandaSQL\n",
    "\n",
    "PandasSQL é uma solução mais antiga. A biblioteca permite usar SQL (SQLite) em tabelas Pandas. Você só tem que passar a query em SQL e as variáveis locais. Por trás dos panos, eles criam um [SQL engine](https://pt.wikipedia.org/wiki/Mecanismo_de_armazenamento) usando SQLAlchemy e os métodos de `to_sql` e `read_sql` de Pandas. O que faz possível executar queries em Pandas, mas é um truque, que acaba sendo bem ineficiente em relação a tempo de execução e uso de memória #gambiarra\n",
    "\n",
    "![](https://media.giphy.com/media/L2HCO7avkR5H9MvS9Y/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737d6586-162c-40e8-87b5-5b9610a332d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "PandaSQLException",
     "evalue": "(sqlite3.OperationalError) near \"'1998-09-02'\": syntax error\n[SQL: \nSELECT l_returnflag,\n       l_linestatus,\n       SUM(l_extendedprice),\n       MIN(l_extendedprice),\n       MAX(l_extendedprice),\n       AVG(l_extendedprice),\n       SUM(l_quantity),\n       MIN(l_quantity),\n       MAX(l_quantity),\n       AVG(l_quantity)\nFROM lineitem AS lineitem\nJOIN orders AS orders ON (l_orderkey=o_orderkey)\nWHERE l_shipdate <= DATE '1998-09-02'\n  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\nGROUP BY l_returnflag,\n         l_linestatus\n]\n(Background on this error at: http://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1769\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1771\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \"'1998-09-02'\": syntax error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, env)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDatabaseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m             return self._exec_driver_sql(\n\u001b[0m\u001b[1;32m   1248\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1547\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1814\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1993\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   1995\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1769\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1771\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) near \"'1998-09-02'\": syntax error\n[SQL: \nSELECT l_returnflag,\n       l_linestatus,\n       SUM(l_extendedprice),\n       MIN(l_extendedprice),\n       MAX(l_extendedprice),\n       AVG(l_extendedprice),\n       SUM(l_quantity),\n       MIN(l_quantity),\n       MAX(l_quantity),\n       AVG(l_quantity)\nFROM lineitem AS lineitem\nJOIN orders AS orders ON (l_orderkey=o_orderkey)\nWHERE l_shipdate <= DATE '1998-09-02'\n  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\nGROUP BY l_returnflag,\n         l_linestatus\n]\n(Background on this error at: http://sqlalche.me/e/14/e3q8)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPandaSQLException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ea5ba4c431ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m _df = sqldf(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0ml_returnflag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36msqldf\u001b[0;34m(query, env, db_uri)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0msqldf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select avg(x) from df;\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPandaSQL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, env)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDatabaseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mPandaSQLException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mResourceClosedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;31m# query returns nothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPandaSQLException\u001b[0m: (sqlite3.OperationalError) near \"'1998-09-02'\": syntax error\n[SQL: \nSELECT l_returnflag,\n       l_linestatus,\n       SUM(l_extendedprice),\n       MIN(l_extendedprice),\n       MAX(l_extendedprice),\n       AVG(l_extendedprice),\n       SUM(l_quantity),\n       MIN(l_quantity),\n       MAX(l_quantity),\n       AVG(l_quantity)\nFROM lineitem AS lineitem\nJOIN orders AS orders ON (l_orderkey=o_orderkey)\nWHERE l_shipdate <= DATE '1998-09-02'\n  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\nGROUP BY l_returnflag,\n         l_linestatus\n]\n(Background on this error at: http://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from pandasql import sqldf\n",
    "\n",
    "start = time.monotonic()\n",
    "\n",
    "_df = sqldf(\n",
    "    \"\"\"\n",
    "SELECT l_returnflag,\n",
    "       l_linestatus,\n",
    "       SUM(l_extendedprice),\n",
    "       MIN(l_extendedprice),\n",
    "       MAX(l_extendedprice),\n",
    "       AVG(l_extendedprice),\n",
    "       SUM(l_quantity),\n",
    "       MIN(l_quantity),\n",
    "       MAX(l_quantity),\n",
    "       AVG(l_quantity)\n",
    "FROM lineitem AS lineitem\n",
    "JOIN orders AS orders ON (l_orderkey=o_orderkey)\n",
    "WHERE l_shipdate <= DATE '1998-09-02'\n",
    "  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\n",
    "GROUP BY l_returnflag,\n",
    "         l_linestatus\n",
    "\"\"\",\n",
    "    globals(),\n",
    ")\n",
    "\n",
    "# o código retorna um erro interno (`OperationalError`) - visite o notebook para mais detalhes\n",
    "print(f\"Wall time: {time.monotonic() - start:.2f}s\")\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d741a2e-4d50-4f74-a6de-1a1e60e3f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pandasql 0.7.3\n",
      "Uninstalling pandasql-0.7.3:\n",
      "  Successfully uninstalled pandasql-0.7.3\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "!pip uninstall pandasql -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0e3c4-6d46-4a2f-93fd-6c33aa00bde8",
   "metadata": {},
   "source": [
    "Não muito bom... Mas **deve** existir outro jeito de usar SQL em Pandas, e ainda aproveitando a eficiência de SQL, não? Na verdade sim. Acontece que tem gente que basicamente reconstruiu um servidor de SQL pra ser executado em memória, com uma API em python!\n",
    "\n",
    "## DuckDB\n",
    "\n",
    "DuckDB permite aos desenvolvedores à executar queries nas suas tabelas em Pandas ou direto de arquivos CSV, parquet, etc. A biblioteca foi desenvolvida com C++ por trás dos panos, e também permite paralelização e otimização da query. Ou seja, eles evitam problemas que encontramos em outras bibliotecas - antes nós tinhamos de escanear a tabela duas vezes quando executamos nossa query: uma para filtrar as linhas e outra vez pra agroupar os dados. Isso não acontece com DuckDB. Eles também são inteligente no uso de memória.\n",
    "\n",
    "Também pensando no ambiente python, onde Pandas ainda é prevalente, eles oferecem métodos para transformar os dados numa tabela Pandas.\n",
    "\n",
    "![](https://media.giphy.com/media/vIJaz7nMJhTUc/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c294f804-ec74-4401-ac73-9bc218e3a420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_orderkey</th>\n",
       "      <th>l_partkey</th>\n",
       "      <th>l_suppkey</th>\n",
       "      <th>l_linenumber</th>\n",
       "      <th>l_quantity</th>\n",
       "      <th>l_extendedprice</th>\n",
       "      <th>l_discount</th>\n",
       "      <th>l_tax</th>\n",
       "      <th>l_returnflag</th>\n",
       "      <th>l_linestatus</th>\n",
       "      <th>l_shipdate</th>\n",
       "      <th>l_commitdate</th>\n",
       "      <th>l_receiptdate</th>\n",
       "      <th>l_shipinstruct</th>\n",
       "      <th>l_shipmode</th>\n",
       "      <th>l_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>155190</td>\n",
       "      <td>7706</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>21168.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-03-13</td>\n",
       "      <td>1996-02-12</td>\n",
       "      <td>1996-03-22</td>\n",
       "      <td>DELIVER IN PERSON</td>\n",
       "      <td>TRUCK</td>\n",
       "      <td>egular courts above the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>67310</td>\n",
       "      <td>7311</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>45983.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-04-12</td>\n",
       "      <td>1996-02-28</td>\n",
       "      <td>1996-04-20</td>\n",
       "      <td>TAKE BACK RETURN</td>\n",
       "      <td>MAIL</td>\n",
       "      <td>ly final dependencies: slyly bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63700</td>\n",
       "      <td>3701</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13309.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-01-29</td>\n",
       "      <td>1996-03-05</td>\n",
       "      <td>1996-01-31</td>\n",
       "      <td>TAKE BACK RETURN</td>\n",
       "      <td>REG AIR</td>\n",
       "      <td>riously. regular, express dep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2132</td>\n",
       "      <td>4633</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28955.64</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-04-21</td>\n",
       "      <td>1996-03-30</td>\n",
       "      <td>1996-05-16</td>\n",
       "      <td>NONE</td>\n",
       "      <td>AIR</td>\n",
       "      <td>lites. fluffily even de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24027</td>\n",
       "      <td>1534</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>22824.48</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-03-30</td>\n",
       "      <td>1996-03-14</td>\n",
       "      <td>1996-04-01</td>\n",
       "      <td>NONE</td>\n",
       "      <td>FOB</td>\n",
       "      <td>pending foxes. slyly re</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   l_orderkey  l_partkey  l_suppkey  l_linenumber  l_quantity  \\\n",
       "0           1     155190       7706             1          17   \n",
       "1           1      67310       7311             2          36   \n",
       "2           1      63700       3701             3           8   \n",
       "3           1       2132       4633             4          28   \n",
       "4           1      24027       1534             5          24   \n",
       "\n",
       "   l_extendedprice  l_discount  l_tax l_returnflag l_linestatus  l_shipdate  \\\n",
       "0         21168.23        0.04   0.02            N            O  1996-03-13   \n",
       "1         45983.16        0.09   0.06            N            O  1996-04-12   \n",
       "2         13309.60        0.10   0.02            N            O  1996-01-29   \n",
       "3         28955.64        0.09   0.06            N            O  1996-04-21   \n",
       "4         22824.48        0.10   0.04            N            O  1996-03-30   \n",
       "\n",
       "  l_commitdate l_receiptdate     l_shipinstruct l_shipmode  \\\n",
       "0   1996-02-12    1996-03-22  DELIVER IN PERSON      TRUCK   \n",
       "1   1996-02-28    1996-04-20   TAKE BACK RETURN       MAIL   \n",
       "2   1996-03-05    1996-01-31   TAKE BACK RETURN    REG AIR   \n",
       "3   1996-03-30    1996-05-16               NONE        AIR   \n",
       "4   1996-03-14    1996-04-01               NONE        FOB   \n",
       "\n",
       "                            l_comment  \n",
       "0             egular courts above the  \n",
       "1  ly final dependencies: slyly bold   \n",
       "2       riously. regular, express dep  \n",
       "3             lites. fluffily even de  \n",
       "4             pending foxes. slyly re  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ler arquivos em parquet e colocar em uma dataframe\n",
    "lineitem = duckdb.query(\"SELECT * FROM 'lineitemsf1.snappy.parquet'\").to_df()\n",
    "orders = duckdb.query(\"SELECT * FROM 'orders.parquet'\").to_df()\n",
    "\n",
    "lineitem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c3a24a9-da4f-434d-a0a5-f2ee7a79ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648 ms ± 5.47 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# executar uma query na nossa tabela Pandas\n",
    "duckdb.query(\n",
    "    \"\"\"\n",
    "SELECT l_returnflag,\n",
    "       l_linestatus,\n",
    "       SUM(l_extendedprice),\n",
    "       MIN(l_extendedprice),\n",
    "       MAX(l_extendedprice),\n",
    "       AVG(l_extendedprice),\n",
    "       SUM(l_quantity),\n",
    "       MIN(l_quantity),\n",
    "       MAX(l_quantity),\n",
    "       AVG(l_quantity)\n",
    "FROM lineitem AS lineitem\n",
    "JOIN orders AS orders ON (l_orderkey=o_orderkey)\n",
    "WHERE l_shipdate <= DATE '1998-09-02'\n",
    "  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\n",
    "GROUP BY l_returnflag,\n",
    "         l_linestatus\n",
    "\"\"\"\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92830f75-3fb0-4d00-9ec4-5f4f87ca609a",
   "metadata": {},
   "source": [
    "Além de ser a mais rápida, repare que DuckDB já pega as variáveis locais quando tentamos executar as queries. A biblioteca também suporta (código testado) vários tipos de SQL, incluindo PostgreSQL, MySQL e SQLite.\n",
    "\n",
    "# Mais informações\n",
    "\n",
    "O DuckDB foi a solução mais rápida. Mas como você deve ter imaginado, esse não é sempre o caso. Tudo depende do volume de dados que temos e das transformações que vamos fazer. Os [criadores do Datatable](https://www.h2o.ai/blog/speed-up-your-data-analysis-with-pythons-datatable-package/#:~:text=H2O%20AI%20Hybrid%20Cloud&text=Deploy%20models%20in%20any%20environment,%2C%20and%20real%2Dtime%20monitoring.&text=H2O%20Wave%20enables%20fast%20development,light%2Dweight%20Python%20development%20framework.) também comparam o tempo de execução das queries para diferentes cenários. As comparações são atualizadas com o passar do tempo e você pode encontrar os últimos resultados [aqui](https://h2oai.github.io/db-benchmark/).\n",
    "\n",
    "Para os interessados, também tem um artigo muito interessante no blog do DuckDB, onde eles explicam um pouco os motivos quais DuckDB tem uma performance elevada à Pandas, e como que podemos otimizar nossas queries (mesmo que só em Pandas). Esse post também foi inspirado no blog post deles (as queries e os dados). Vale à pena dar uma olhada.\n",
    "\n",
    "Quando falamos de Big Data também não podemos deixar de falar de outras tecnologias, como Spark, Apache Beam, etc. Quando os dados são muito grandes pra uma máquina só, o que nos resta é utilizar um cluster de computadores e paralelizar as computações e dividir o uso de memória - [escalabilidade horizontal](https://pt.wikipedia.org/wiki/Escalabilidade). Mas com esses clusters precisamos de uma parte administrativa maior, e não seria algo que qualquer um poderia testar rapidamente. Nesse post incluímos apenas os casos de quando os dados caberiam em uma máquina, e estamos avaliando a eficiência de bibliotecas em python (existem outras bibliotecas em outras linguagens que também são bem eficientes).\n",
    "\n",
    "Em outras palavras, nós comparamos algumas ferramentas pra um específico caso, mas pra determinar a **melhor** ferramenta, precisamos ir de caso-a-caso. Qual o volume de dados? Precisamos um cluster? Qual o tempo de execução aceitável? Qual o nível técnico da equipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafff9b7-50fe-4be7-8064-b24fb2cc973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# deletar os arquivos baixados\n",
    "!rm lineitemsf1.snappy.parquet\n",
    "!rm orders.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4afe8-0bf9-4b3e-9653-6c7e5abb10c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
