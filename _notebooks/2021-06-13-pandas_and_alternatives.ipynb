{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f557b8-b885-4481-8f27-22df38b23332",
   "metadata": {},
   "source": [
    "# ManipulaÃ§Ã£o de dados tabulares - Pandas e alternativas\n",
    "> Pandas, SQL e comparaÃ§Ãµes (Dask, Polars, Datatable, PandaSQL e DuckDB)\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [demo, sql, pandas, duckdb, dask, datatable, polars, tabelas, benchmarks]\n",
    "- image: https://images.unsplash.com/photo-1526716121440-dc3b4f254a0a?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=700&q=80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0fd0a8-cf10-40a8-bfd6-f1c81d3e932a",
   "metadata": {},
   "source": [
    "# IntroduÃ§Ã£o\n",
    "\n",
    "Em machine learning, a gente sempre comenta como nÃ³s precisamos de dados. E precisamos de dados bem curados. Talvez vocÃª atÃ© jÃ¡ tenha ouvido a frase: \"garbage in, garbage out\", nÃ©?\n",
    "\n",
    "Na vida real, isso Ã© bem verdade. E gastar mais tempo criando novas features, ou limpando os dados acaba muitas vezes impactando os resultados dos modelos mais que qualquer outra coisa. NÃ£o Ã© Ã  toa que grande parte dos ganhadores das competiÃ§Ãµes do [Kaggle](https://www.kaggle.com/) usam os mesmo modelos - [ensembles](https://towardsdatascience.com/xgboost-lightgbm-and-other-kaggle-competition-favorites-6212e8b0e835). E, na maior parte, quem ganha sÃ£o os que tem os melhores dados.\n",
    "\n",
    "EntÃ£o, antes de mexermos em modelos, temos que manipular os dados. Mas entÃ£o como manipular esses dados?\n",
    "\n",
    "## Pandas\n",
    "\n",
    "A resposta mais comum Ã© [pandas](https://pandas.pydata.org/)! Se vocÃª jÃ¡ mexeu com dados, provavelmente jÃ¡ ouviu falar sobre essa biblioteca. Ela Ã©, de longe, a mais popular pra manipulaÃ§Ã£o de dados tabulares. Ela foi construÃ­da em cima de [NumPy](https://numpy.org/), que usa C++ por trÃ¡s dos panos.\n",
    "\n",
    "> Em Python temos o GIL que limita o uso de threads pra evitar que mais de um thread tente escrever/apagar as mesmas partes da memÃ³ria ao mesmo tempo ([condiÃ§Ã£o de corrida](https://pt.wikipedia.org/wiki/Condi%C3%A7%C3%A3o_de_corrida)). Quando usamos Numpy e chegamos no nÃ­vel de C, o programa nÃ£o estÃ¡ sujeito ao GIL e entÃ£o podemos parallelizar as coisas.\n",
    "\n",
    "Mas se vocÃª jÃ¡ ouviu falar de pandas, Ã© capaz que nÃ£o tenha ouvido coisas boas. Especialmente quem vem da linguagem de programaÃ§Ã£o em R usando o [dplyr](https://dplyr.tidyverse.org/) tem o que falar ğŸ˜…. O nÃºmero de perguntas no [StackOverflow](https://stackoverflow.com/) relacionadas Ã  pandas cresceu bastante durante os anos. Parte pelo aumento em popularidade da biblioteca, mas parte pela dificuldade da API do pandas.\n",
    "\n",
    "![](https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/copied_from_nb/2021-06-13-pandas_and_alternatives/stackoverflow_questions.png \"Fonte: https://insights.stackoverflow.com/trends?tags=pandas%2Cnumpy%2Cdask%2Cspacy%2Ctensorflow%2Cpytorch%2Cscikit-learn%2Cpyspark%2Cpostgresql\")\n",
    "\n",
    "AlÃ©m disso, existem vÃ¡rios pontos em que podemos otimizar a performance de pandas. Isso pelo fato da biblioteca ter sido criada em cima de uma outra. Vamos dar uma olhada na performance de pandas.\n",
    "\n",
    "### Dados\n",
    "\n",
    "Vamos usar o TPC-H dataset, focando no `lineitem` e `orders`, que sÃ£o as maiores tabelas que somam 1GB. Para medir o tempo de execuÃ§Ã£o, vamos unir as duas tabelas, filtram as linhas, agrupam os dados e computamos alguns dados agregados (mÃ¡ximo, mÃ­nimo, etc.). O que estamos fazendo em si nÃ£o Ã© muito importante, mas Ã© um tipo de transformaÃ§Ã£o que encontrarÃ­amos na vida real.\n",
    "\n",
    "Vamos tentar otimizar tudo ao mÃ¡ximo, e vamos focar na transformaÃ§Ã£o dos dados\n",
    "\n",
    "- Vamos medir o tempo da transformaÃ§Ã£o (excluindo o tempo de ler os dados)\n",
    "- Vamos filtrar o quanto antes\n",
    "- Vamos encadear operaÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53cacd2-39d7-4034-ad7f-f3eb277bc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "!pip install duckdb pandas 'dask[dataframe]' datatable polars pandasql > /dev/null\n",
    "!wget -q https://github.com/cwida/duckdb-data/releases/download/v1.0/lineitemsf1.snappy.parquet\n",
    "!wget -q https://github.com/cwida/duckdb-data/releases/download/v1.0/orders.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3294070f-a9ce-42c2-88d4-1138337aab2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import dask.dataframe as dd\n",
    "import datatable as dt\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datatable import by, f, g, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56fcd81-904b-42ec-94a3-f3bde71fe336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "lineitem = pd.read_parquet(\"lineitemsf1.snappy.parquet\")\n",
    "orders = pd.read_parquet(\"orders.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c75cee5-fb0f-48e2-99ed-3bee6daadde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.63 s, sys: 2.34 s, total: 7.97 s\n",
      "Wall time: 8.09 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">l_extendedprice</th>\n",
       "      <th colspan=\"4\" halign=\"left\">l_quantity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_returnflag</th>\n",
       "      <th>l_linestatus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>F</th>\n",
       "      <td>2.267720e+10</td>\n",
       "      <td>904.0</td>\n",
       "      <td>104949.5</td>\n",
       "      <td>38303.426664</td>\n",
       "      <td>15123892</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>25.545346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">N</th>\n",
       "      <th>F</th>\n",
       "      <td>5.965302e+08</td>\n",
       "      <td>920.0</td>\n",
       "      <td>104049.0</td>\n",
       "      <td>38461.006847</td>\n",
       "      <td>397729</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>25.643391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>4.473406e+10</td>\n",
       "      <td>901.0</td>\n",
       "      <td>104749.5</td>\n",
       "      <td>38267.695102</td>\n",
       "      <td>29826993</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>25.515466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <td>2.268310e+10</td>\n",
       "      <td>906.0</td>\n",
       "      <td>104899.5</td>\n",
       "      <td>38240.140532</td>\n",
       "      <td>15126938</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>25.501645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          l_extendedprice                                 \\\n",
       "                                      sum    min       max          mean   \n",
       "l_returnflag l_linestatus                                                  \n",
       "A            F               2.267720e+10  904.0  104949.5  38303.426664   \n",
       "N            F               5.965302e+08  920.0  104049.0  38461.006847   \n",
       "             O               4.473406e+10  901.0  104749.5  38267.695102   \n",
       "R            F               2.268310e+10  906.0  104899.5  38240.140532   \n",
       "\n",
       "                          l_quantity                     \n",
       "                                 sum min max       mean  \n",
       "l_returnflag l_linestatus                                \n",
       "A            F              15123892   1  50  25.545346  \n",
       "N            F                397729   1  50  25.643391  \n",
       "             O              29826993   1  50  25.515466  \n",
       "R            F              15126938   1  50  25.501645  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lineitem.merge(orders, left_on=\"l_orderkey\", right_on=\"o_orderkey\").pipe(\n",
    "    lambda df: df.copy()[\n",
    "        (df[\"l_shipdate\"] < \"1998-09-02\")\n",
    "        & (df[\"o_orderpriority\"].isin((\"1-URGENT\", \"2-HIGH\")))\n",
    "    ]\n",
    ").groupby([\"l_returnflag\", \"l_linestatus\"]).agg(\n",
    "    {\n",
    "        \"l_extendedprice\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "        \"l_quantity\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01371b5e-4016-458f-af98-0f299fbec2a4",
   "metadata": {},
   "source": [
    "Executando todas essas transformaÃ§Ãµes demorou 10.3 segundos. Mas podemos ser mais eficientes. Por exemplo, poderÃ­amos esquecer vÃ¡rias colunas jÃ¡ que no fim sÃ³ estamos interessados em `l_returnflag`, `l_linestatus`, `l_extendedprice` e `l_quantity` (alÃ©m das colunas que usamos para filtrar os dados). TambÃ©m somos ineficientes quando temos de filtrar e agregar os valores (escaneamos a tabela duas vezes, quando poderÃ­amos fazer isso de uma vez sÃ³). AlÃ©m disso, poderÃ­amos melhorar na implementaÃ§Ã£o de paralelismo e do algoritmo.\n",
    "\n",
    "Vamos entÃ£o deixar pandas de lado e ver como podemos melhorar isso.\n",
    "\n",
    "![](https://media.giphy.com/media/EPcvhM28ER9XW/giphy.gif)\n",
    "\n",
    "## Dask\n",
    "\n",
    "[Dask](https://docs.dask.org/en/latest/dataframe.html) provavelmente Ã© a primeira soluÃ§Ã£o que vem Ã  cabeÃ§a. Dask basicamente cria vÃ¡rias tabelas em pandas e vai paralelizando as operaÃ§Ãµes em cores diferentes. TambÃ©m Ã© mais eficiente por usar [avaliaÃ§Ã£o preguiÃ§osa](https://pt.wikipedia.org/wiki/Avalia%C3%A7%C3%A3o_pregui%C3%A7osa) (lazy evaluation) - primeiro traÃ§amos o que queremos fazer e depois mandamos o computador executar as transformaÃ§Ãµes. Isso nos deixa otimizar a computaÃ§Ã£o das transformaÃ§Ãµes (por exemplo, podemos filtrar linhas antes de fazer qualquer outra coisa, mesmo que o cÃ³digo nÃ£o represente isso).\n",
    "\n",
    "![](https://media.giphy.com/media/26ufnwz3wDUli7GU0/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaa8d7c-b80c-4c55-80e1-ead5986ebba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse\n",
    "# dask\n",
    "dd_lineitem = dd.from_pandas(lineitem, npartitions=1)\n",
    "dd_orders = dd.from_pandas(orders, npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254fef8b-cd23-48d5-a980-ff0d5facab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.14 s Â± 20.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dd_lineitem.merge(dd_orders, left_on=\"l_orderkey\", right_on=\"o_orderkey\").pipe(\n",
    "    lambda df: df.copy()[\n",
    "        (df[\"l_shipdate\"] < \"1998-09-02\")\n",
    "        & (df[\"o_orderpriority\"].isin((\"1-URGENT\", \"2-HIGH\")))\n",
    "    ]\n",
    ").groupby([\"l_returnflag\", \"l_linestatus\"]).agg(\n",
    "    {\n",
    "        \"l_extendedprice\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "        \"l_quantity\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "    }\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b67e181-b1b3-4144-92d8-76a5e9b04b08",
   "metadata": {},
   "source": [
    "Usando Dask e com essas melhorias de parallelismo a gente ganha alguns segundos. O que faz Dask muito popular Ã© o fato de ele imitar a API do Pandas. AÃ­ fica muito mais fÃ¡cil de pegar e comeÃ§ar a codar. Mas ainda assim, estamos usando Pandas. Temos espaÃ§os para melhorias.\n",
    "\n",
    "## Polars\n",
    "\n",
    "[Polars](https://pola-rs.github.io/polars-book/) Ã© uma biblioteca implementada em [Rust](https://www.rust-lang.org/), que Ã© muito eficiente em termos de velocidade e uso de memÃ³ria. O lugar de Polars (de acordo com a documentaÃ§Ã£o) Ã© para quando os dados sÃ£o muito grandes para Pandas mas muito pequenos para realizar as transformaÃ§Ãµes num cluster de mÃ¡quinas (Spark). Ou seja, se os dados sÃ£o muito grandes pra sua mÃ¡quina, mesmo depois de filtrar algumas entradas, precisamos procurar outras soluÃ§Ãµes (o que Ã© verdade pra Dask e todas as outras bibliotecas que vamos ver aqui). E assim como Dask, Polars vai usar todas as threads da sua mÃ¡quina.\n",
    "\n",
    "Uma outra idÃ©ia de Polars Ã© permitir o use da [avaliaÃ§Ã£o ansiosa](https://pt.wikipedia.org/wiki/Avalia%C3%A7%C3%A3o_ansiosa) (eager evaluation), como em Pandas e da [avaliaÃ§Ã£o preguiÃ§osa](https://pt.wikipedia.org/wiki/Avalia%C3%A7%C3%A3o_pregui%C3%A7osa) (lazy evaluation), como em Dask. A availaÃ§Ã£o ansiosa Ã© como em Pandas, e a API Ã© bem parecida. A API da avaliaÃ§Ã£o preguiÃ§osa Ã© um pouco diferente, e Ã© otimizada pelos mesmo motivos que citamos quando falamos de Dask (paralelizaÃ§Ã£o e otimizaÃ§Ã£o das transformaÃ§Ãµes).\n",
    "\n",
    "![](https://media.giphy.com/media/2FmmbTZMl6lQQ/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e183160a-2b1d-4a0c-b117-8ebf62ed0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse\n",
    "# polars\n",
    "pl_lineitem = pl.DataFrame(lineitem)\n",
    "pl_orders = pl.DataFrame(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8d60db-104d-44e7-9080-ba93704631ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 s Â± 1.03 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pl_lineitem.join(pl_orders, left_on=\"l_orderkey\", right_on=\"o_orderkey\").filter(\n",
    "    (pl.col(\"l_shipdate\") < \"1998-09-02\")\n",
    "    & (\n",
    "        (pl.col(\"o_orderpriority\") == \"1-URGENT\")\n",
    "        | (pl.col(\"o_orderpriority\") == \"2-HIGH\")\n",
    "    )\n",
    ").groupby([\"l_returnflag\", \"l_linestatus\"]).agg(\n",
    "    {\n",
    "        \"l_extendedprice\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "        \"l_quantity\": [\"sum\", \"min\", \"max\", \"mean\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9def685-67ab-4028-a8a5-10736ef9bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# using lazy eval\n",
    "import time\n",
    "\n",
    "pl_lineitem = pl_lineitem.lazy()\n",
    "pl_orders = pl_orders.lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3eecaf1-45d8-4647-9bf8-e93386c77769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1 \"class=\"dataframe \">\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "l_returnflag\n",
       "</th>\n",
       "<th>\n",
       "l_linestatus\n",
       "</th>\n",
       "<th>\n",
       "l_extendedprice_sum\n",
       "</th>\n",
       "<th>\n",
       "l_extendedprice_min\n",
       "</th>\n",
       "<th>\n",
       "l_extendedprice_max\n",
       "</th>\n",
       "<th>\n",
       "l_extendedprice_mean\n",
       "</th>\n",
       "<th>\n",
       "l_quantity_sum\n",
       "</th>\n",
       "<th>\n",
       "l_quantity_min\n",
       "</th>\n",
       "<th>\n",
       "l_quantity_max\n",
       "</th>\n",
       "<th>\n",
       "l_quantity_mean\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "\"N\"\n",
       "</td>\n",
       "<td>\n",
       "\"O\"\n",
       "</td>\n",
       "<td>\n",
       "4.473405541680963e10\n",
       "</td>\n",
       "<td>\n",
       "901\n",
       "</td>\n",
       "<td>\n",
       "1.047495e5\n",
       "</td>\n",
       "<td>\n",
       "3.8267695101622725e4\n",
       "</td>\n",
       "<td>\n",
       "29826993\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "50\n",
       "</td>\n",
       "<td>\n",
       "25.515466087014545\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "\"R\"\n",
       "</td>\n",
       "<td>\n",
       "\"F\"\n",
       "</td>\n",
       "<td>\n",
       "2.2683095360319317e10\n",
       "</td>\n",
       "<td>\n",
       "906\n",
       "</td>\n",
       "<td>\n",
       "1.048995e5\n",
       "</td>\n",
       "<td>\n",
       "3.824014053242183e4\n",
       "</td>\n",
       "<td>\n",
       "15126938\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "50\n",
       "</td>\n",
       "<td>\n",
       "25.501644539975555\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "\"A\"\n",
       "</td>\n",
       "<td>\n",
       "\"F\"\n",
       "</td>\n",
       "<td>\n",
       "2.2677199025699192e10\n",
       "</td>\n",
       "<td>\n",
       "904\n",
       "</td>\n",
       "<td>\n",
       "1.049495e5\n",
       "</td>\n",
       "<td>\n",
       "3.830342666419926e4\n",
       "</td>\n",
       "<td>\n",
       "15123892\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "50\n",
       "</td>\n",
       "<td>\n",
       "25.54534567707304\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "\"N\"\n",
       "</td>\n",
       "<td>\n",
       "\"F\"\n",
       "</td>\n",
       "<td>\n",
       "5.965302162000039e8\n",
       "</td>\n",
       "<td>\n",
       "920\n",
       "</td>\n",
       "<td>\n",
       "1.04049e5\n",
       "</td>\n",
       "<td>\n",
       "3.8461006847195604e4\n",
       "</td>\n",
       "<td>\n",
       "397729\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "50\n",
       "</td>\n",
       "<td>\n",
       "25.643391360412636\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (4, 10)\n",
       "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ l_returnf â”† l_linesta â”† l_extende â”† l_extende â”† ... â”† l_quantit â”† l_quanti â”† l_quanti â”† l_quanti â”‚\n",
       "â”‚ lag       â”† tus       â”† dprice_su â”† dprice_mi â”†     â”† y_sum     â”† ty_min   â”† ty_max   â”† ty_mean  â”‚\n",
       "â”‚ ---       â”† ---       â”† m         â”† n         â”†     â”† ---       â”† ---      â”† ---      â”† ---      â”‚\n",
       "â”‚ str       â”† str       â”† ---       â”† ---       â”†     â”† i64       â”† i64      â”† i64      â”† f64      â”‚\n",
       "â”‚           â”†           â”† f64       â”† f64       â”†     â”†           â”†          â”†          â”†          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ \"N\"       â”† \"O\"       â”† 4.4734055 â”† 901       â”† ... â”† 29826993  â”† 1        â”† 50       â”† 25.51546 â”‚\n",
       "â”‚           â”†           â”† 41680963e â”†           â”†     â”†           â”†          â”†          â”† 60870145 â”‚\n",
       "â”‚           â”†           â”† 10        â”†           â”†     â”†           â”†          â”†          â”† 45       â”‚\n",
       "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
       "â”‚ \"R\"       â”† \"F\"       â”† 2.2683095 â”† 906       â”† ... â”† 15126938  â”† 1        â”† 50       â”† 25.50164 â”‚\n",
       "â”‚           â”†           â”† 360319317 â”†           â”†     â”†           â”†          â”†          â”† 45399755 â”‚\n",
       "â”‚           â”†           â”† e10       â”†           â”†     â”†           â”†          â”†          â”† 55       â”‚\n",
       "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
       "â”‚ \"A\"       â”† \"F\"       â”† 2.2677199 â”† 904       â”† ... â”† 15123892  â”† 1        â”† 50       â”† 25.54534 â”‚\n",
       "â”‚           â”†           â”† 025699192 â”†           â”†     â”†           â”†          â”†          â”† 56770730 â”‚\n",
       "â”‚           â”†           â”† e10       â”†           â”†     â”†           â”†          â”†          â”† 4        â”‚\n",
       "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
       "â”‚ \"N\"       â”† \"F\"       â”† 5.9653021 â”† 920       â”† ... â”† 397729    â”† 1        â”† 50       â”† 25.64339 â”‚\n",
       "â”‚           â”†           â”† 62000039e â”†           â”†     â”†           â”†          â”†          â”† 13604126 â”‚\n",
       "â”‚           â”†           â”† 8         â”†           â”†     â”†           â”†          â”†          â”† 36       â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "start = time.monotonic()\n",
    "\n",
    "# lazy dataframe\n",
    "_df = (\n",
    "    pl_lineitem.join(pl_orders, left_on=\"l_orderkey\", right_on=\"o_orderkey\").filter(\n",
    "        (pl.col(\"l_shipdate\") < \"1998-09-02\")\n",
    "        & (\n",
    "            (pl.col(\"o_orderpriority\") == \"1-URGENT\")\n",
    "            | (pl.col(\"o_orderpriority\") == \"2-HIGH\")\n",
    "        )\n",
    "    )\n",
    "    # could not delay collection - error (not finding `o_orderkey` column)\n",
    "    .collect()\n",
    ")\n",
    "# eager dataframe\n",
    "_df = _df.groupby([\"l_returnflag\", \"l_linestatus\"]).agg(\n",
    "    [\n",
    "        pl.sum(\"l_extendedprice\"),\n",
    "        pl.min(\"l_extendedprice\"),\n",
    "        pl.max(\"l_extendedprice\"),\n",
    "        pl.mean(\"l_extendedprice\"),\n",
    "        pl.sum(\"l_quantity\"),\n",
    "        pl.min(\"l_quantity\"),\n",
    "        pl.max(\"l_quantity\"),\n",
    "        pl.mean(\"l_quantity\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Wall time: {time.monotonic() - start:.2f}s\")\n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c768f-d635-4eee-9b39-f8415d12fadc",
   "metadata": {},
   "source": [
    "Com isso conseguimos reduzir o tempo em **<30%** (comparando com Dask)! EntÃ£o, o que ainda podemos melhorar? Quando usamos a avaliaÃ§Ã£o ansiosa, ainda podemos melhorar a execuÃ§Ã£o das queries. AlÃ©m disso, a biblioteca nÃ£o tem tantas funÃ§Ãµes quanto Pandas (e consequentemente Dask). E falando em Pandas, se a API Ã© igual, e vocÃª nÃ£o estÃ¡ satisfeito com ela, provavelmente nÃ£o vai estar muito contente com a API do Polars tambÃ©m.\n",
    "\n",
    "## Datatable\n",
    "\n",
    "Se vocÃª gosta de R e estÃ¡ fazendo a transiÃ§Ã£o para python, talvez essa seja uma boa opÃ§Ã£o. Datatable Ã© inspirada pela biblioteca em R [data.table](https://rdatatable.gitlab.io/data.table/). A API Ã© parecida, e tem vÃ¡rias otimizaÃ§Ãµes para tratar com dados grandes. Que cabem **ou nÃ£o** em memÃ³ria (dados que nÃ£o caberiam em memÃ³ria usando Pandas cabem quando usamos Datatable). Essa biblioteca tambÃ©m usa algoritmos que supportam o paralelismo em diferentes [threads](https://pt.wikipedia.org/wiki/Thread_(computa%C3%A7%C3%A3o)), aumentando de novo a velocidade de execuÃ§Ã£o.\n",
    "\n",
    "![](https://media.giphy.com/media/rGlAZysKBcjRCkAX7S/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7807673d-df77-40c0-b1b7-a0d8addb1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse\n",
    "# datatable\n",
    "dt_lineitem = dt.Frame(lineitem)\n",
    "dt_orders = dt.Frame(orders)\n",
    "\n",
    "# preparaÃ§Ã£o\n",
    "dt_lineitem.names = {\"l_orderkey\": \"orderkey\"}\n",
    "dt_orders.names = {\"o_orderkey\": \"orderkey\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd7f90b-dd3b-4cea-b45f-aacca1b03ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32 s Â± 106 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# dt_lineitem.key = \"orderkey\"  # nÃ£o podemos usar como `key` existem valores repetidos\n",
    "dt_orders.key = \"orderkey\"\n",
    "\n",
    "# executando a query\n",
    "dt_lineitem[\n",
    "    (g.o_orderpriority == \"1-URGENT\") | (g.o_orderpriority == \"2-HIGH\"),\n",
    "    :,\n",
    "    join(dt_orders),\n",
    "][\n",
    "    :,\n",
    "    {\n",
    "        \"sum(l_extendedprice)\": dt.sum(f.l_extendedprice),\n",
    "        \"min(l_extendedprice)\": dt.min(f.l_extendedprice),\n",
    "        \"max(l_extendedprice)\": dt.max(f.l_extendedprice),\n",
    "        \"mean(l_extendedprice)\": dt.mean(f.l_extendedprice),\n",
    "        \"sum(l_quantity)\": dt.sum(f.l_quantity),\n",
    "        \"min(l_quantity)\": dt.min(f.l_quantity),\n",
    "        \"max(l_quantity)\": dt.max(f.l_quantity),\n",
    "        \"mean(l_quantity)\": dt.mean(f.l_quantity),\n",
    "    },\n",
    "    by(f.l_returnflag, f.l_linestatus),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ffb2ec-d780-47be-9cd9-c86890bf82b3",
   "metadata": {},
   "source": [
    "**~10%** do tempo (comparando com Pandas)! VocÃª pode reparar tambÃ©m como a API muda bastante. Pessoalmente, foi um pouco mais trabalhoso pra escrever o cÃ³digo equivalente, mas na documentaÃ§Ã£o eles tambÃ©m oferecem uma comparaÃ§Ã£o da API do Datatable com a API do Pandas, o que ajuda bastante.\n",
    "\n",
    "AlÃ©m disso, eles tambÃ©m comparam a API do Datatable com SQL. Afinal de contas, SQL Ã© muito usado atÃ© hoje, e mais familiar pra muitas pessoas. AlÃ©m disso, SQL tem sido usado bastante atravÃ©s dos anos e oferece uma maneira eficiente de manipular dados tabulares. Quando os dados aumentam ainda mais e nos tornamos para um mÃ©todo distribuÃ­do como [Spark](https://spark.apache.org/) ainda podemos usar [SparkSQL](https://spark.apache.org/docs/latest/sql-programming-guide.html). Spark e SQL precisam de um [cluster](https://pt.wikipedia.org/wiki/Cluster) e de um [servidor](https://pt.wikipedia.org/wiki/Servidor_(computa%C3%A7%C3%A3o)) prÃ³prio pra executar as transformaÃ§Ãµes. Mas existem algumas bibliotecas que nos permitem usar SQL para manipular dados em dataframes.\n",
    "\n",
    "## PandaSQL\n",
    "\n",
    "PandasSQL Ã© uma soluÃ§Ã£o mais antiga. A biblioteca permite usar SQL (SQLite) em tabelas Pandas. VocÃª sÃ³ tem que passar a query em SQL e as variÃ¡veis locais. Por trÃ¡s dos panos, eles criam um [SQL engine](https://pt.wikipedia.org/wiki/Mecanismo_de_armazenamento) usando SQLAlchemy e os mÃ©todos de `to_sql` e `read_sql` de Pandas. O que faz possÃ­vel executar queries em Pandas, mas Ã© um truque, que acaba sendo bem ineficiente em relaÃ§Ã£o a tempo de execuÃ§Ã£o e uso de memÃ³ria #gambiarra\n",
    "\n",
    "![](https://media.giphy.com/media/L2HCO7avkR5H9MvS9Y/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737d6586-162c-40e8-87b5-5b9610a332d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "PandaSQLException",
     "evalue": "(sqlite3.OperationalError) near \"'1998-09-02'\": syntax error\n[SQL: \nSELECT l_returnflag,\n       l_linestatus,\n       SUM(l_extendedprice),\n       MIN(l_extendedprice),\n       MAX(l_extendedprice),\n       AVG(l_extendedprice),\n       SUM(l_quantity),\n       MIN(l_quantity),\n       MAX(l_quantity),\n       AVG(l_quantity)\nFROM lineitem AS lineitem\nJOIN orders AS orders ON (l_orderkey=o_orderkey)\nWHERE l_shipdate <= DATE '1998-09-02'\n  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\nGROUP BY l_returnflag,\n         l_linestatus\n]\n(Background on this error at: http://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1769\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1771\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \"'1998-09-02'\": syntax error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, env)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDatabaseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m             return self._exec_driver_sql(\n\u001b[0m\u001b[1;32m   1248\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1547\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1814\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1993\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   1995\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1769\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1771\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) near \"'1998-09-02'\": syntax error\n[SQL: \nSELECT l_returnflag,\n       l_linestatus,\n       SUM(l_extendedprice),\n       MIN(l_extendedprice),\n       MAX(l_extendedprice),\n       AVG(l_extendedprice),\n       SUM(l_quantity),\n       MIN(l_quantity),\n       MAX(l_quantity),\n       AVG(l_quantity)\nFROM lineitem AS lineitem\nJOIN orders AS orders ON (l_orderkey=o_orderkey)\nWHERE l_shipdate <= DATE '1998-09-02'\n  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\nGROUP BY l_returnflag,\n         l_linestatus\n]\n(Background on this error at: http://sqlalche.me/e/14/e3q8)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPandaSQLException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ea5ba4c431ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m _df = sqldf(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0ml_returnflag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36msqldf\u001b[0;34m(query, env, db_uri)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0msqldf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select avg(x) from df;\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPandaSQL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/inteligencia-superficial/lib/python3.8/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, env)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDatabaseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mPandaSQLException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mResourceClosedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;31m# query returns nothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPandaSQLException\u001b[0m: (sqlite3.OperationalError) near \"'1998-09-02'\": syntax error\n[SQL: \nSELECT l_returnflag,\n       l_linestatus,\n       SUM(l_extendedprice),\n       MIN(l_extendedprice),\n       MAX(l_extendedprice),\n       AVG(l_extendedprice),\n       SUM(l_quantity),\n       MIN(l_quantity),\n       MAX(l_quantity),\n       AVG(l_quantity)\nFROM lineitem AS lineitem\nJOIN orders AS orders ON (l_orderkey=o_orderkey)\nWHERE l_shipdate <= DATE '1998-09-02'\n  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\nGROUP BY l_returnflag,\n         l_linestatus\n]\n(Background on this error at: http://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from pandasql import sqldf\n",
    "\n",
    "start = time.monotonic()\n",
    "\n",
    "_df = sqldf(\n",
    "    \"\"\"\n",
    "SELECT l_returnflag,\n",
    "       l_linestatus,\n",
    "       SUM(l_extendedprice),\n",
    "       MIN(l_extendedprice),\n",
    "       MAX(l_extendedprice),\n",
    "       AVG(l_extendedprice),\n",
    "       SUM(l_quantity),\n",
    "       MIN(l_quantity),\n",
    "       MAX(l_quantity),\n",
    "       AVG(l_quantity)\n",
    "FROM lineitem AS lineitem\n",
    "JOIN orders AS orders ON (l_orderkey=o_orderkey)\n",
    "WHERE l_shipdate <= DATE '1998-09-02'\n",
    "  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\n",
    "GROUP BY l_returnflag,\n",
    "         l_linestatus\n",
    "\"\"\",\n",
    "    globals(),\n",
    ")\n",
    "\n",
    "# o cÃ³digo retorna um erro interno (`OperationalError`) - visite o notebook para mais detalhes\n",
    "print(f\"Wall time: {time.monotonic() - start:.2f}s\")\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d741a2e-4d50-4f74-a6de-1a1e60e3f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pandasql 0.7.3\n",
      "Uninstalling pandasql-0.7.3:\n",
      "  Successfully uninstalled pandasql-0.7.3\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "!pip uninstall pandasql -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0e3c4-6d46-4a2f-93fd-6c33aa00bde8",
   "metadata": {},
   "source": [
    "NÃ£o muito bom... Mas **deve** existir outro jeito de usar SQL em Pandas, e ainda aproveitando a eficiÃªncia de SQL, nÃ£o? Na verdade sim. Acontece que tem gente que basicamente reconstruiu um servidor de SQL pra ser executado em memÃ³ria, com uma API em python!\n",
    "\n",
    "## DuckDB\n",
    "\n",
    "DuckDB permite aos desenvolvedores Ã  executar queries nas suas tabelas em Pandas ou direto de arquivos CSV, parquet, etc. A biblioteca foi desenvolvida com C++ por trÃ¡s dos panos, e tambÃ©m permite paralelizaÃ§Ã£o e otimizaÃ§Ã£o da query. Ou seja, eles evitam problemas que encontramos em outras bibliotecas - antes nÃ³s tinhamos de escanear a tabela duas vezes quando executamos nossa query: uma para filtrar as linhas e outra vez pra agroupar os dados. Isso nÃ£o acontece com DuckDB. Eles tambÃ©m sÃ£o inteligente no uso de memÃ³ria.\n",
    "\n",
    "TambÃ©m pensando no ambiente python, onde Pandas ainda Ã© prevalente, eles oferecem mÃ©todos para transformar os dados numa tabela Pandas.\n",
    "\n",
    "![](https://media.giphy.com/media/vIJaz7nMJhTUc/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c294f804-ec74-4401-ac73-9bc218e3a420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_orderkey</th>\n",
       "      <th>l_partkey</th>\n",
       "      <th>l_suppkey</th>\n",
       "      <th>l_linenumber</th>\n",
       "      <th>l_quantity</th>\n",
       "      <th>l_extendedprice</th>\n",
       "      <th>l_discount</th>\n",
       "      <th>l_tax</th>\n",
       "      <th>l_returnflag</th>\n",
       "      <th>l_linestatus</th>\n",
       "      <th>l_shipdate</th>\n",
       "      <th>l_commitdate</th>\n",
       "      <th>l_receiptdate</th>\n",
       "      <th>l_shipinstruct</th>\n",
       "      <th>l_shipmode</th>\n",
       "      <th>l_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>155190</td>\n",
       "      <td>7706</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>21168.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-03-13</td>\n",
       "      <td>1996-02-12</td>\n",
       "      <td>1996-03-22</td>\n",
       "      <td>DELIVER IN PERSON</td>\n",
       "      <td>TRUCK</td>\n",
       "      <td>egular courts above the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>67310</td>\n",
       "      <td>7311</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>45983.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-04-12</td>\n",
       "      <td>1996-02-28</td>\n",
       "      <td>1996-04-20</td>\n",
       "      <td>TAKE BACK RETURN</td>\n",
       "      <td>MAIL</td>\n",
       "      <td>ly final dependencies: slyly bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63700</td>\n",
       "      <td>3701</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13309.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-01-29</td>\n",
       "      <td>1996-03-05</td>\n",
       "      <td>1996-01-31</td>\n",
       "      <td>TAKE BACK RETURN</td>\n",
       "      <td>REG AIR</td>\n",
       "      <td>riously. regular, express dep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2132</td>\n",
       "      <td>4633</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28955.64</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-04-21</td>\n",
       "      <td>1996-03-30</td>\n",
       "      <td>1996-05-16</td>\n",
       "      <td>NONE</td>\n",
       "      <td>AIR</td>\n",
       "      <td>lites. fluffily even de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24027</td>\n",
       "      <td>1534</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>22824.48</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>1996-03-30</td>\n",
       "      <td>1996-03-14</td>\n",
       "      <td>1996-04-01</td>\n",
       "      <td>NONE</td>\n",
       "      <td>FOB</td>\n",
       "      <td>pending foxes. slyly re</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   l_orderkey  l_partkey  l_suppkey  l_linenumber  l_quantity  \\\n",
       "0           1     155190       7706             1          17   \n",
       "1           1      67310       7311             2          36   \n",
       "2           1      63700       3701             3           8   \n",
       "3           1       2132       4633             4          28   \n",
       "4           1      24027       1534             5          24   \n",
       "\n",
       "   l_extendedprice  l_discount  l_tax l_returnflag l_linestatus  l_shipdate  \\\n",
       "0         21168.23        0.04   0.02            N            O  1996-03-13   \n",
       "1         45983.16        0.09   0.06            N            O  1996-04-12   \n",
       "2         13309.60        0.10   0.02            N            O  1996-01-29   \n",
       "3         28955.64        0.09   0.06            N            O  1996-04-21   \n",
       "4         22824.48        0.10   0.04            N            O  1996-03-30   \n",
       "\n",
       "  l_commitdate l_receiptdate     l_shipinstruct l_shipmode  \\\n",
       "0   1996-02-12    1996-03-22  DELIVER IN PERSON      TRUCK   \n",
       "1   1996-02-28    1996-04-20   TAKE BACK RETURN       MAIL   \n",
       "2   1996-03-05    1996-01-31   TAKE BACK RETURN    REG AIR   \n",
       "3   1996-03-30    1996-05-16               NONE        AIR   \n",
       "4   1996-03-14    1996-04-01               NONE        FOB   \n",
       "\n",
       "                            l_comment  \n",
       "0             egular courts above the  \n",
       "1  ly final dependencies: slyly bold   \n",
       "2       riously. regular, express dep  \n",
       "3             lites. fluffily even de  \n",
       "4             pending foxes. slyly re  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ler arquivos em parquet e colocar em uma dataframe\n",
    "lineitem = duckdb.query(\"SELECT * FROM 'lineitemsf1.snappy.parquet'\").to_df()\n",
    "orders = duckdb.query(\"SELECT * FROM 'orders.parquet'\").to_df()\n",
    "\n",
    "lineitem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c3a24a9-da4f-434d-a0a5-f2ee7a79ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648 ms Â± 5.47 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# executar uma query na nossa tabela Pandas\n",
    "duckdb.query(\n",
    "    \"\"\"\n",
    "SELECT l_returnflag,\n",
    "       l_linestatus,\n",
    "       SUM(l_extendedprice),\n",
    "       MIN(l_extendedprice),\n",
    "       MAX(l_extendedprice),\n",
    "       AVG(l_extendedprice),\n",
    "       SUM(l_quantity),\n",
    "       MIN(l_quantity),\n",
    "       MAX(l_quantity),\n",
    "       AVG(l_quantity)\n",
    "FROM lineitem AS lineitem\n",
    "JOIN orders AS orders ON (l_orderkey=o_orderkey)\n",
    "WHERE l_shipdate <= DATE '1998-09-02'\n",
    "  AND o_orderpriority IN ('1-URGENT', '2-HIGH')\n",
    "GROUP BY l_returnflag,\n",
    "         l_linestatus\n",
    "\"\"\"\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92830f75-3fb0-4d00-9ec4-5f4f87ca609a",
   "metadata": {},
   "source": [
    "AlÃ©m de ser a mais rÃ¡pida, repare que DuckDB jÃ¡ pega as variÃ¡veis locais quando tentamos executar as queries. A biblioteca tambÃ©m suporta (cÃ³digo testado) vÃ¡rios tipos de SQL, incluindo PostgreSQL, MySQL e SQLite.\n",
    "\n",
    "# Mais informaÃ§Ãµes\n",
    "\n",
    "O DuckDB foi a soluÃ§Ã£o mais rÃ¡pida. Mas como vocÃª deve ter imaginado, esse nÃ£o Ã© sempre o caso. Tudo depende do volume de dados que temos e das transformaÃ§Ãµes que vamos fazer. Os [criadores do Datatable](https://www.h2o.ai/blog/speed-up-your-data-analysis-with-pythons-datatable-package/#:~:text=H2O%20AI%20Hybrid%20Cloud&text=Deploy%20models%20in%20any%20environment,%2C%20and%20real%2Dtime%20monitoring.&text=H2O%20Wave%20enables%20fast%20development,light%2Dweight%20Python%20development%20framework.) tambÃ©m comparam o tempo de execuÃ§Ã£o das queries para diferentes cenÃ¡rios. As comparaÃ§Ãµes sÃ£o atualizadas com o passar do tempo e vocÃª pode encontrar os Ãºltimos resultados [aqui](https://h2oai.github.io/db-benchmark/).\n",
    "\n",
    "Para os interessados, tambÃ©m tem um artigo muito interessante no blog do DuckDB, onde eles explicam um pouco os motivos quais DuckDB tem uma performance elevada Ã  Pandas, e como que podemos otimizar nossas queries (mesmo que sÃ³ em Pandas). Esse post tambÃ©m foi inspirado no blog post deles (as queries e os dados). Vale Ã  pena dar uma olhada.\n",
    "\n",
    "Quando falamos de Big Data tambÃ©m nÃ£o podemos deixar de falar de outras tecnologias, como Spark, Apache Beam, etc. Quando os dados sÃ£o muito grandes pra uma mÃ¡quina sÃ³, o que nos resta Ã© utilizar um cluster de computadores e paralelizar as computaÃ§Ãµes e dividir o uso de memÃ³ria - [escalabilidade horizontal](https://pt.wikipedia.org/wiki/Escalabilidade). Mas com esses clusters precisamos de uma parte administrativa maior, e nÃ£o seria algo que qualquer um poderia testar rapidamente. Nesse post incluÃ­mos apenas os casos de quando os dados caberiam em uma mÃ¡quina, e estamos avaliando a eficiÃªncia de bibliotecas em python (existem outras bibliotecas em outras linguagens que tambÃ©m sÃ£o bem eficientes).\n",
    "\n",
    "Em outras palavras, nÃ³s comparamos algumas ferramentas pra um especÃ­fico caso, mas pra determinar a **melhor** ferramenta, precisamos ir de caso-a-caso. Qual o volume de dados? Precisamos um cluster? Qual o tempo de execuÃ§Ã£o aceitÃ¡vel? Qual o nÃ­vel tÃ©cnico da equipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafff9b7-50fe-4be7-8064-b24fb2cc973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# deletar os arquivos baixados\n",
    "!rm lineitemsf1.snappy.parquet\n",
    "!rm orders.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4afe8-0bf9-4b3e-9653-6c7e5abb10c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
