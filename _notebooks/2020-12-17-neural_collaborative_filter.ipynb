{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de recommenda√ß√£o - Neural Collaborative Filtering\n",
    "> Com demo sobre Neural Collaborative Filtering\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [demo, neural networks, deep learning, recommender systems, paper]\n",
    "- image: https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/2020-09-11-neural_collaborative_filter/cover.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural collaborative filtering\n",
    "\n",
    "# TL; DR\n",
    "\n",
    "> youtube: https://youtu.be/SD3irxdKfxk\n",
    "\n",
    "Rootlabs @ lunch session on Neural Collaborative Filtering\n",
    "\n",
    "---\n",
    "\n",
    "# Sistemas de recomenda√ß√£o\n",
    "\n",
    "## ü•Ö Objetivo\n",
    "\n",
    "O objetivo √© gerar recomenda√ß√µes para um usu√°rio. O sistema de recomenda√ß√£o perfeito recomendaria a um usu√°rio um item que ele gostaria, e que a pessoa n√£o chegaria ao item sozinha. Portanto, um modelo que recomenda os itens mais populares para todos os usu√°rios n√£o √© considerado um bom sistema de recomenda√ß√£o - as recomenda√ß√µes n√£o s√£o personalizadas.\n",
    "\n",
    "O resultado principal de um modelo seria, por exemplo, os 10 principais itens que um usu√°rio pode gostar e ainda n√£o viu.\n",
    "\n",
    "## üìö Dados\n",
    "\n",
    "Os dados **podem** incluir informa√ß√µes sobre o usu√°rio (ou seja: idade, sexo, informa√ß√µes sobre compras anteriores), mas **deve** incluir informa√ß√µes da intera√ß√£o entre usu√°rios e itens - se um usu√°rio comprou/gostou/avaliou um item. Essa intera√ß√£o costuma ser chamada de **feedback**. Existem dois tipos diferentes de feedback: expl√≠cito e impl√≠cito.\n",
    "\n",
    "### üí¨ Feedback expl√≠cito x impl√≠cito\n",
    "\n",
    " **Feedback expl√≠cito** √© a intera√ß√£o que o usu√°rio fornece intencionalmente - classifica√ß√µes de 5 estrelas em um produto, a üëç em um produto etc.\n",
    "\n",
    " **Feedback impl√≠cito** ocorre sempre que temos uma \"dica\" das prefer√™ncias do usu√°rio. Comprou, viu um filme, etc. Recebemos um interesse entre o usu√°rio e o item, mas n√£o um feedback concreto - se o usu√°rio realmente gostou do item (s√≥ porque eu vi o filme, n√£o significa que gostei).\n",
    "\n",
    "Como se poderia imaginar, o feedback expl√≠cito √© mais informativo do que o impl√≠cito. Mas, na maioria dos casos, esses dados n√£o est√£o prontamente dispon√≠veis ou s√£o muito escassos. No restante desta postagem, vamos nos concentrar em situa√ß√µes nas quais recebemos feedback impl√≠cito.\n",
    "\n",
    "Ao trabalhar com feedback impl√≠cito, antes de dividir os dados em teste e treinamento, precisamos fazer a suposi√ß√£o de que toda intera√ß√£o observada √© positiva e a aus√™ncia de intera√ß√£o √© negativa. No exemplo, todos os filmes que assisti eu gostei e todos os filmes que n√£o assisti eu n√£o gostaria (n√£o √© realista, mas necess√°rio para definir o problema).\n",
    "\n",
    "### üî™ Divis√£o de \"test\" e \"train\"\n",
    "\n",
    "Depois de reunir todas as informa√ß√µes, temos todos os usu√°rios, itens e intera√ß√µes. Podemos coloc√°-los em uma matriz - tamb√©m conhecida como **matriz de intera√ß√£o**.\n",
    "\n",
    "<center><img src=\"https://developers.google.com/machine-learning/recommendation/images/1Dmatrix.svg\" width=\"70%\" description=\"Exemplo de matriz de intera√ß√£o entre usu√°rios e filmes, do [Google Developers](https://developers.google.com/machine-learning/recommendation/collaborative/basics).\" /> </center>\n",
    "\n",
    "Ao construir o teste, uma ideia √© manter uma intera√ß√£o entre um usu√°rio e um item e tentar prever isso. Pela imagem acima, poder√≠amos impedir a entrada do casal ruivo Shrek para o teste.\n",
    "\n",
    "Pode-se fazer isso amostrando uma intera√ß√£o aleatoriamente para cada usu√°rio, mas √© interessante ter em mente a taxa de teste do trem e a possibilidade de vazamento de dados. Pode ser melhor tentar dividir os dados usando os √∫ltimos *d* dias para teste e o restante para treinamento, ou algo mais pr√≥ximo do caso de uso para o qual o modelo est√° sendo constru√≠do.\n",
    "\n",
    "De certa forma, temos uma abordagem de aprendizado supervisionado, uma vez que estamos tentando prever dados rotulados. Mas, como mencionado antes, √© anormal no sentido de que um r√≥tulo \"verdadeiro\" no feedback impl√≠cito pode n√£o corresponder ao usu√°rio realmente ter gostado do item. A ruiva pode n√£o ter gostado de Shrek, embora isso seja desconhecido para n√≥s. Por outro lado, ela pode gostar de \"Memento\", mas n√£o tinha conhecimento desse filme.\n",
    "\n",
    "Mas isso √© o melhor que podemos fazer com os dados que temos. Depois que os dados forem rotulados, as suposi√ß√µes feitas e tivermos uma divis√£o de teste e trem, podemos ver como modelar nossos problemas.\n",
    "\n",
    "## ü§ñ Abordagens\n",
    "\n",
    "Existem duas abordagens principais quando se trata de sistemas de recomenda√ß√£o - **content based filtering** e **collaborative filtering**.\n",
    "\n",
    "### Content based filtering\n",
    "\n",
    "A ideia √© usar as informa√ß√µes dos usu√°rios para fazer previs√µes sobre se ele gostar√° no futuro. Essas informa√ß√µes podem incluir informa√ß√µes pessoais e informa√ß√µes de compras anteriores. A √∫nica coisa a se considerar √© que o recurso est√° dispon√≠vel para a maioria dos usu√°rios.\n",
    "\n",
    "A abordagem pode ser resumida a qualquer configura√ß√£o de aprendizado supervisionado - temos recursos (do usu√°rio e do item) e um r√≥tulo que queremos prever. A partir da√≠, podemos usar qualquer modelo para classifica√ß√£o - de regress√£o log√≠stica a redes neurais.\n",
    "\n",
    "Se tivermos um feedback expl√≠cito, tamb√©m poder√≠amos construir um usu√°rio [embedding](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture) que tenha recursos no mesmo espa√ßo que os itens, e calcular a semelhan√ßa entre eles. Por exemplo, se um usu√°rio definiu que gosta de filmes de a√ß√£o e drama, podemos procurar filmes de a√ß√£o e drama.\n",
    "\n",
    "Mas a ideia geral √© ter recomenda√ß√µes espec√≠ficas para um √∫nico usu√°rio - o que ele gosta, em oposi√ß√£o ao collaborative filtering.\n",
    "\n",
    " **Compara√ß√£o:** \n",
    "\n",
    "- üëç Escala bem - usa apenas dados de um usu√°rio\n",
    "- üëç Posso recomendar interesses de nicho muito espec√≠ficos - muito espec√≠ficos para um usu√°rio\n",
    "- üëé O modelo √© incapaz de explorar e expandir os interesses dos usu√°rios (coisas novas que ele n√£o manifestou interesse no passado)\n",
    "- üëé Se o modelo for constru√≠do com recursos de engenharia manual, √© necess√°rio muito conhecimento de dom√≠nio e o modelo √© t√£o bom quanto seus recursos\n",
    "\n",
    "### Collaborative filtering\n",
    "\n",
    "Na collaborative filtering, n√£o usamos recursos de usu√°rio ou item. N√≥s nos concentramos inteiramente em nossa matriz de intera√ß√£o. A principal ideia de alto n√≠vel √© descobrir o que um usu√°rio vai gostar com base no que usu√°rios semelhantes gostaram no passado.\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/2020-09-11-neural_collaborative_filter/colab_filtering_high_lvl.png\" width=\"70%\" description=\"Ideia geral de collaborative filtering\" /> </center>\n",
    "\n",
    "Ideia principal com collaborative filtering.\n",
    "\n",
    "Na imagem acima - o emoji de festa seria recomendado para ca√ßa-n√≠queis por ser semelhante ao dem√¥nio. Aqui, \"usu√°rios semelhantes\" s√£o aqueles que compraram os mesmos itens (ou semelhantes) no passado.\n",
    "\n",
    "No collaborative filtering, olhamos apenas para todas as compras e todos os itens. Ent√£o o modelo n√£o liga para o que s√£o os itens e nem os usu√°rios. Tentamos criar embeddings de usu√°rio e item √∫teis com base nas intera√ß√µes entre usu√°rios e itens - ou seja: a matriz de intera√ß√£o.\n",
    "\n",
    "Essa √© a ideia principal, mas vamos mergulhar no funcionamento desse modelo mais tarde.\n",
    "\n",
    " **Compara√ß√£o:** \n",
    "\n",
    "- üëç Nenhum conhecimento necess√°rio - n√£o precisamos saber nada sobre o problema para o qual estamos modelando\n",
    "- üëç Pode generalizar interesses e recomendar mais itens novos para um usu√°rio\n",
    "- üëé N√£o dimensiona bem - precisa de todas as intera√ß√µes de todos os itens e todos os usu√°rios\n",
    "- üëé N√£o inclu√≠mos quaisquer outros recursos espec√≠ficos do usu√°rio nem recursos espec√≠ficos do item\n",
    "- üëé Baseamos nosso modelo na matriz de intera√ß√£o - n√£o podemos gerar previs√µes para usu√°rios sem intera√ß√£o registrada (um novo usu√°rio no varejo online, por exemplo); isso √© conhecido como **problema de inicializa√ß√£o a frio** \n",
    "\n",
    "### Abordagem h√≠brida\n",
    "\n",
    "√â poss√≠vel um h√≠brido entre as duas abordagens. E na maioria dos casos o que √© implementado. Em uma vis√£o mais geral, o que √© feito √© ter os dois modelos lado a lado e pesar suas previs√µes. Tamb√©m podemos determinar esses pesos de maneira orientada por dados.\n",
    "\n",
    "Isso tamb√©m permite o fallback quando n√£o h√° dados de intera√ß√£o para um usu√°rio. Nesse caso, nos concentramos na abordagem \"content based\" at√© que os dados de intera√ß√£o estejam dispon√≠veis.\n",
    "\n",
    "Uma implementa√ß√£o muito popular e f√°cil de usar √© o [modelo LightFM](https://making.lyst.com/lightfm/docs/home.html), que √© conhecido por alcan√ßar resultados muito bons.\n",
    "\n",
    "## ü§î Avalia√ß√£o\n",
    "\n",
    "Como se poderia imaginar, t√©cnicas de avalia√ß√£o de aprendizagem supervisionada podem ser aplicadas aqui, incluindo curvas de sustenta√ß√£o, ganhos cumulativos, entre outros. No entanto, como se espera que forne√ßamos ao usu√°rio um conjunto de recomenda√ß√µes e n√£o nos importamos necessariamente com previs√µes de baixa classifica√ß√£o, outros m√©todos de avalia√ß√£o que diferem das abordagens tradicionais se aplicam.\n",
    "\n",
    "As m√©tricas populares incluem precis√£o superior @k, precis√£o @k e recall @k. *K* √© o n√∫mero de itens que recomendamos a um usu√°rio (no exemplo inicial, usei k = 10). A ideia √© calcular as m√©tricas olhando apenas para os K itens mais bem classificados. [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/metrics?hl=fr) tamb√©m oferece essas m√©tricas como uma op√ß√£o para precis√£o regular e m√©tricas de recall.\n",
    "\n",
    "Tamb√©m √© poss√≠vel avaliar que gama de itens est√£o sendo recomendados - para evitar modelos em que apenas um subconjunto de todos os itens aparecem como recomenda√ß√µes. Ou personaliza√ß√£o - evite que os itens mais populares acabem como recomenda√ß√µes. [Recmetrics](https://github.com/statisticianinstilettos/recmetrics) oferece algumas id√©ias para avalia√ß√£o de motores de recomenda√ß√£o.\n",
    "\n",
    "# üíÅ‚Äç‚ôÇÔ∏è Collaborative filtering\n",
    "\n",
    "‚ö†Ô∏è Agora vamos mergulhar na matem√°tica ‚ö†Ô∏è\n",
    "\n",
    "## Fatora√ß√£o de matriz\n",
    "\n",
    "Matematicamente falando, √© uma ideia bastante direta - podemos fatorar a matriz de intera√ß√£o para obter os embeddings para os itens e usu√°rios.\n",
    "\n",
    "Semelhante √† fatora√ß√£o normal, estamos procurando as matrizes $U$ (para usu√°rios) e $I$ (para itens) que, quando multiplicadas, geram a matriz de intera√ß√£o $R$ (para avalia√ß√µes), ou\n",
    "\n",
    "$$U \\cdot I = R$$\n",
    "\n",
    "Observe que $\\cdot$ denota multiplica√ß√£o de matrizes e que as matrizes $U$ e $I$ podem variar em suas dimens√µes dependendo do tamanho de seu vetor de incorpora√ß√£o.\n",
    "\n",
    "![https://developers.google.com/machine-learning/recommendation/images/2Dmatrix.svg](https://developers.google.com/machine-learning/recommendation/images/2Dmatrix.svg)\n",
    "\n",
    "Exemplo de matriz de intera√ß√£o e matrizes de usu√°rio (√† esquerda) e item (em cima). O tamanho de incorpora√ß√£o neste exemplo √© 2. Imagem de [Google Developers](https://developers.google.com/machine-learning/recommendation/collaborative/basics).\n",
    "\n",
    "## ML\n",
    "\n",
    "Agora que sabemos o que queremos, como podemos implementar a solu√ß√£o?\n",
    "\n",
    "√â aqui que o aprendizado de m√°quina entra em a√ß√£o. Aproximamos essas matrizes $U$ e $I$ com base em exemplos. Come√ßamos com valores aleat√≥rios para $U$ e $I$, produzindo um conjunto aleat√≥rio de n√∫meros para $R_{pred}$, a matriz de intera√ß√£o aproximada. Podemos comparar $R_ {actual}$ e $R_ {pred}$ usando qualquer fun√ß√£o de perda (pode pensar em algo como [entropia cruzada bin√°ria](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression) , mas somando para cada elemento na matriz) e iterar usando qualquer algoritmo de otimiza√ß√£o (pode pensar em \"[gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)\"), alterando $U$ e $I$ incrementalmente para chegar mais perto de $R_ {real}$.\n",
    "\n",
    "Depois de muitas itera√ß√µes, devemos ter algo semelhante a\n",
    "\n",
    "![https://developers.google.com/machine-learning/recommendation/images/Matrixfactor.svg](https://developers.google.com/machine-learning/recommendation/images/Matrixfactor.svg)\n",
    "\n",
    "A matriz de intera√ß√£o real √† esquerda ($R_ {real}$) e a matriz aproximada, ou prevista, dadas as matrizes treinadas $U$ e $I$ ($R_ {pred}$). Imagem de [Google Developers](https://developers.google.com/machine-learning/recommendation/collaborative/matrix).\n",
    "\n",
    "Depois de muitas itera√ß√µes, a matriz converge na aproxima√ß√£o das intera√ß√µes reais e podemos produzir os itens com as pontua√ß√µes de predi√ß√£o mais altas (que ele ainda n√£o gostou). Voltando para a mulher ruiva, a modelo recomendaria \"The Dark Knight Rises\".\n",
    "\n",
    "Existem outras alternativas alternativas como para perdas e algoritmos de otimiza√ß√£o, que podem convergir mais rapidamente, mas podem ser mais caros computacionalmente, como os m√≠nimos quadrados alternados ponderados (WALS). Os [Google Developers](https://developers.google.com/machine-learning/recommendation/) oferecem uma [compara√ß√£o geral](https://developers.google.com/machine-learning/recommendation/collaborative/matrix) entre o \"gradient descent\" e o WALS. Continuaremos com a \"gradient descent\" assim que falaremos sobre redes neurais.\n",
    "\n",
    "### Isso faz sentido?\n",
    "\n",
    "Por que isso faz sentido com o que descrevemos acima?\n",
    "\n",
    "Para tornar as coisas mais simples, digamos que os encaixes dos itens sejam fixos. √â mais f√°cil ver que, se dois usu√°rios com comportamento muito semelhante, eles acabariam com embeddings semelhantes e, portanto, um item apreciado por um usu√°rio seria recomendado ao outro.\n",
    "\n",
    "# üß† Neural collaborative filtering\n",
    "\n",
    "## Parte \"Neural\"\n",
    "\n",
    "A principal adi√ß√£o que temos nesta parte √© incluir uma rede neural com esses embeddings que criamos. Isso n√£o √© diferente do processo de cria√ß√£o de embeddings de palavras com redes neurais. N√≥s aproximamos os embeddings aleat√≥rios inicializados com base nos r√≥tulos, usando retropropaga√ß√£o. √â interessante adicionar fun√ß√µes n√£o lineares √†s camadas da rede, uma vez que o \"collaborative filtering\" \"vanilla\" j√° cuida das combina√ß√µes lineares entre os embeddings de usu√°rio e item (no [produto matriz](https://dzone.com/articles/visualizing-matrix)).\n",
    "\n",
    "![Https://lh6.googleusercontent.com/kioqr4bQsvJdfvl0YJwnnyNyLG3f55ChHzkYt9cRMQYHttemX9-5vK3-005tMBZdWCSkfkSt0hQjcNxDrV46wqOLRWCLQWyuxoNfX9dSYEF7JBWXIqH1oMcQlmAy6mtMyF1KuiZ2jjs](https://lh6.googleusercontent.com/kioqr4bQsvJdfvl0YJwnnyNyLG3f55ChHzkYt9cRMQYHttemX9-5vK3-005tMBZdWCSkfkSt0hQjcNxDrV46wqOLRWCLQWyuxoNfX9dSYEF7JBWXIqH1oMcQlmAy6mtMyF1KuiZ2jjs)\n",
    "\n",
    "Rede neural para \"collaborative filtering\", com base no usu√°rio e embeddings de itens. Na camada de entrada, $u$ e $i$ s√£o uma codifica√ß√£o ativa que representa o √≠ndice desse usu√°rio. Imagem do artigo [Neural Collaborative Filtering](https://arxiv.org/pdf/1708.05031.pdf).\n",
    "\n",
    "Pode-se notar que as representa√ß√µes aqui ser√£o diferentes daquelas encontradas no \"collaborative filtering\" \"vanilla\". A ideia n√£o √© \"substituir\", mas \"adicionar\". Podemos realizar a fatora√ß√£o da matriz como uma rede neural, concatenar as camadas finais e pass√°-las por uma camada final que produzir√° as previs√µes. Todos juntos, vai parecer\n",
    "\n",
    "![Https://lh4.googleusercontent.com/_UeIXyWB5RiO-wapO60ZpeB2f9MjGmXRnJk2hCUHtXdAuGyHtbTRgO8RmYCix4bWt4Snh8LUEBgiuexUR_VmsdQjo9aH4i35G3YiI8lBcyMYbNuOs1po_xjlfhudWDpnJ5O4RsKj3mw](https://lh4.googleusercontent.com/_UeIXyWB5RiO-wapO60ZpeB2f9MjGmXRnJk2hCUHtXdAuGyHtbTRgO8RmYCix4bWt4Snh8LUEBgiuexUR_VmsdQjo9aH4i35G3YiI8lBcyMYbNuOs1po_xjlfhudWDpnJ5O4RsKj3mw)\n",
    "\n",
    "Arquitetura neural colaborativa. Imagem do artigo [Neural Collaborative Filtering](https://arxiv.org/pdf/1708.05031.pdf).\n",
    "\n",
    "Esses dois modelos diferentes juntos formam a arquitetura geral. Eles podem, no entanto, ser treinados separadamente e ajustados no final (aprendizagem por transfer√™ncia). Isso pode acelerar o tempo de treinamento e produzir melhores resultados.\n",
    "\n",
    "## üí™ Ganhos\n",
    "\n",
    "A quest√£o √©: a complexidade adicional vale a pena?\n",
    "\n",
    "Ao comparar experimentalmente os resultados usando o [conjunto de dados MovieLens](https://grouplens.org/datasets/movielens/), os resultados entre o LightFM e o neural collaborative filtering foram semelhantes (sinta-se √† vontade para dar uma olhada na demo!), com um custo computacional consideravelmente maior para redes neurais.\n",
    "\n",
    "Mas, por outro lado, obtemos mais flexibilidade com o modelo. Al√©m do mais, podemos integrar facilmente um modelo de content based filtering (usando redes neurais) para formar um sistema de recomenda√ß√£o h√≠brido no Tensorflow. E a complexidade dos problemas que podem ser resolvidos tamb√©m aumenta - problemas complexos de PNL ou de s√©rie temporal podem ser integrados. Poder√≠amos, por exemplo, alavancar modelos pr√©-treinados como o BERT e integr√°-los neste sistema h√≠brido de recomenda√ß√£o.\n",
    "\n",
    "# üíª Demo\n",
    "\n",
    "Caso esteja rodando o notebook n√£o esque√ßa de fazer o download das bibliotecas e inicie o `tensorboard` no background:\n",
    "\n",
    "No terminal\n",
    "```bash\n",
    "pip install tensorflow lightfm pandas\n",
    "tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs\n",
    "```\n",
    "\n",
    "ou no notebook\n",
    "```python\n",
    "!pip install tensorflow lightfm pandas\n",
    "```\n",
    "\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "!tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs &\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import lightfm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.3.0\n",
      "LightFM version: 1.15\n",
      "Pandas version: 1.1.1\n",
      "Numpy version: 1.18.5\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"LightFM version: {lightfm.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "TOP_K = 5\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Os dados\n",
    "\n",
    "![](https://developers.google.com/machine-learning/recommendation/images/Matrixfactor.svg \"Credit: https://developers.google.com/machine-learning/recommendation/collaborative/basics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix:\n",
      "[[5 3 4 3 3 5 4 0 5 3]\n",
      " [4 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0 4 4 0]\n",
      " [0 0 0 5 0 0 5 5 5 4]\n",
      " [0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0]\n",
      " [4 0 0 4 0 0 0 0 4 0]]\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "data = fetch_movielens(min_rating=3.0)\n",
    "\n",
    "print(\"Interaction matrix:\")\n",
    "print(data[\"train\"].toarray()[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix:\n",
      "[[1 1 1 1 1 1 1 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 1 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 0]]\n",
      "\n",
      "Ratings:\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# collapse\n",
    "for dataset in [\"test\", \"train\"]:\n",
    "    data[dataset] = (data[dataset].toarray() > 0).astype(\"int8\")\n",
    "\n",
    "# Make the ratings binary\n",
    "print(\"Interaction matrix:\")\n",
    "print(data[\"train\"][:10, :10])\n",
    "\n",
    "print(\"\\nRatings:\")\n",
    "unique_ratings = np.unique(data[\"train\"])\n",
    "print(unique_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def wide_to_long(wide: np.array, possible_ratings: List[int]) -> np.array:\n",
    "    \"\"\"Go from wide table to long.\n",
    "    :param wide: wide array with user-item interactions\n",
    "    :param possible_ratings: list of possible ratings that we may have.\"\"\"\n",
    "\n",
    "    def _get_ratings(arr: np.array, rating: int) -> np.array:\n",
    "        \"\"\"Generate long array for the rating provided\n",
    "        :param arr: wide array with user-item interactions\n",
    "        :param rating: the rating that we are interested\"\"\"\n",
    "        idx = np.where(arr == rating)\n",
    "        return np.vstack(\n",
    "            (idx[0], idx[1], np.ones(idx[0].size, dtype=\"int8\") * rating)\n",
    "        ).T\n",
    "\n",
    "    long_arrays = []\n",
    "    for r in possible_ratings:\n",
    "        long_arrays.append(_get_ratings(wide, r))\n",
    "\n",
    "    return np.vstack(long_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_train = wide_to_long(data[\"train\"], unique_ratings)\n",
    "df_train = pd.DataFrame(long_train, columns=[\"user_id\", \"item_id\", \"interaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All interactions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  interaction\n",
       "0        0        7            0\n",
       "1        0       10            0\n",
       "2        0       19            0\n",
       "3        0       20            0\n",
       "4        0       26            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_input\n",
    "print(\"All interactions:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only positive interactions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1511499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511500</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511501</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511502</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511503</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  interaction\n",
       "1511499        0        0            1\n",
       "1511500        0        1            1\n",
       "1511501        0        2            1\n",
       "1511502        0        3            1\n",
       "1511503        0        4            1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_input\n",
    "print(\"Only positive interactions:\")\n",
    "df_train[df_train[\"interaction\"] > 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O modelo (Neural Collaborative Filtering)\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/2020-09-11-neural_collaborative_filter/ncf_all_with_alpha.png\" width=\"70%\" url=\"https://developers.google.com/machine-learning/recommendation/collaborative/basics\" description=\"Fonte: https://developers.google.com/machine-learning/recommendation/collaborative/basics\" /> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Multiply,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "def create_ncf(\n",
    "    number_of_users: int,\n",
    "    number_of_items: int,\n",
    "    latent_dim_mf: int = 4,\n",
    "    latent_dim_mlp: int = 32,\n",
    "    reg_mf: int = 0,\n",
    "    reg_mlp: int = 0.01,\n",
    "    dense_layers: List[int] = [8, 4],\n",
    "    reg_layers: List[int] = [0.01, 0.01],\n",
    "    activation_dense: str = \"relu\",\n",
    ") -> keras.Model:\n",
    "\n",
    "    # input layer\n",
    "    user = Input(shape=(), dtype=\"int32\", name=\"user_id\")\n",
    "    item = Input(shape=(), dtype=\"int32\", name=\"item_id\")\n",
    "\n",
    "    # embedding layers\n",
    "    mf_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mf_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    mlp_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mlp_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    # MF vector\n",
    "    mf_user_latent = Flatten()(mf_user_embedding(user))\n",
    "    mf_item_latent = Flatten()(mf_item_embedding(item))\n",
    "    mf_cat_latent = Multiply()([mf_user_latent, mf_item_latent])\n",
    "\n",
    "    # MLP vector\n",
    "    mlp_user_latent = Flatten()(mlp_user_embedding(user))\n",
    "    mlp_item_latent = Flatten()(mlp_item_embedding(item))\n",
    "    mlp_cat_latent = Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    mlp_vector = mlp_cat_latent\n",
    "\n",
    "    # build dense layers for model\n",
    "    for i in range(len(dense_layers)):\n",
    "        layer = Dense(\n",
    "            dense_layers[i],\n",
    "            activity_regularizer=l2(reg_layers[i]),\n",
    "            activation=activation_dense,\n",
    "            name=\"layer%d\" % i,\n",
    "        )\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "\n",
    "    predict_layer = Concatenate()([mf_cat_latent, mlp_vector])\n",
    "\n",
    "    result = Dense(\n",
    "        1, activation=\"sigmoid\", kernel_initializer=\"lecun_uniform\", name=\"interaction\"\n",
    "    )\n",
    "\n",
    "    output = result(predict_layer)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[user, item],\n",
    "        outputs=[output],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"neural_collaborative_filtering\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_user_embedding (Embedding)  (None, 32)           30176       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mlp_item_embedding (Embedding)  (None, 32)           53824       item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 32)           0           mlp_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           mlp_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mf_user_embedding (Embedding)   (None, 4)            3772        user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mf_item_embedding (Embedding)   (None, 4)            6728        item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4)            0           mf_user_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4)            0           mf_item_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer0 (Dense)                  (None, 8)            520         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 4)            0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 4)            36          layer0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8)            0           multiply[0][0]                   \n",
      "                                                                 layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "interaction (Dense)             (None, 1)            9           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 95,065\n",
      "Trainable params: 95,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# collapse\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "n_users, n_items = data[\"train\"].shape\n",
    "ncf_model = create_ncf(n_users, n_items)\n",
    "\n",
    "ncf_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")\n",
    "ncf_model._name = \"neural_collaborative_filtering\"\n",
    "ncf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    targets: List[str],\n",
    "    val_split: float = 0.1,\n",
    "    batch_size: int = 512,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"Make TensorFlow dataset from Pandas DataFrame.\n",
    "    :param df: input DataFrame - only contains features and target(s)\n",
    "    :param targets: list of columns names corresponding to targets\n",
    "    :param val_split: fraction of the data that should be used for validation\n",
    "    :param batch_size: batch size for training\n",
    "    :param seed: random seed for shuffling data - set to `None` to not shuffle\"\"\"\n",
    "\n",
    "    n_val = round(df.shape[0] * val_split)\n",
    "    if seed:\n",
    "        # shuffle all the rows\n",
    "        x = df.sample(frac=1, random_state=seed).to_dict(\"series\")\n",
    "    else:\n",
    "        x = df.to_dict(\"series\")\n",
    "    y = dict()\n",
    "    for t in targets:\n",
    "        y[t] = x.pop(t)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "    ds_val = ds.take(n_val).batch(batch_size)\n",
    "    ds_train = ds.skip(n_val).batch(batch_size)\n",
    "    return ds_train, ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation datasets\n",
    "ds_train, ds_val = make_tf_dataset(df_train, [\"interaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2789 [..............................] - ETA: 0s - loss: 2.7761 - tp: 1.0000 - fp: 32.0000 - tn: 459.0000 - fn: 20.0000 - accuracy: 0.8984 - precision: 0.0303 - recall: 0.0476 - auc: 0.4325WARNING:tensorflow:From /usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0254s). Check your callbacks.\n",
      "2789/2789 [==============================] - 9s 3ms/step - loss: 0.2318 - tp: 1691.0000 - fp: 789.0000 - tn: 1359625.0000 - fn: 65408.0000 - accuracy: 0.9536 - precision: 0.6819 - recall: 0.0252 - auc: 0.8033 - val_loss: 0.1408 - val_tp: 902.0000 - val_fp: 416.0000 - val_tn: 150669.0000 - val_fn: 6626.0000 - val_accuracy: 0.9556 - val_precision: 0.6844 - val_recall: 0.1198 - val_auc: 0.9020\n",
      "Epoch 2/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1279 - tp: 11668.0000 - fp: 6340.0000 - tn: 1354074.0000 - fn: 55431.0000 - accuracy: 0.9567 - precision: 0.6479 - recall: 0.1739 - auc: 0.9164 - val_loss: 0.1236 - val_tp: 1532.0000 - val_fp: 854.0000 - val_tn: 150231.0000 - val_fn: 5996.0000 - val_accuracy: 0.9568 - val_precision: 0.6421 - val_recall: 0.2035 - val_auc: 0.9195\n",
      "Epoch 3/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1191 - tp: 13715.0000 - fp: 7758.0000 - tn: 1352656.0000 - fn: 53384.0000 - accuracy: 0.9572 - precision: 0.6387 - recall: 0.2044 - auc: 0.9254 - val_loss: 0.1198 - val_tp: 1587.0000 - val_fp: 835.0000 - val_tn: 150250.0000 - val_fn: 5941.0000 - val_accuracy: 0.9573 - val_precision: 0.6552 - val_recall: 0.2108 - val_auc: 0.9232\n",
      "Epoch 4/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1148 - tp: 14333.0000 - fp: 7576.0000 - tn: 1352838.0000 - fn: 52766.0000 - accuracy: 0.9577 - precision: 0.6542 - recall: 0.2136 - auc: 0.9293 - val_loss: 0.1160 - val_tp: 1610.0000 - val_fp: 797.0000 - val_tn: 150288.0000 - val_fn: 5918.0000 - val_accuracy: 0.9577 - val_precision: 0.6689 - val_recall: 0.2139 - val_auc: 0.9267\n",
      "Epoch 5/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1114 - tp: 15531.0000 - fp: 7649.0000 - tn: 1352765.0000 - fn: 51568.0000 - accuracy: 0.9585 - precision: 0.6700 - recall: 0.2315 - auc: 0.9335 - val_loss: 0.1138 - val_tp: 1777.0000 - val_fp: 877.0000 - val_tn: 150208.0000 - val_fn: 5751.0000 - val_accuracy: 0.9582 - val_precision: 0.6696 - val_recall: 0.2361 - val_auc: 0.9294\n",
      "Epoch 6/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1088 - tp: 16978.0000 - fp: 8344.0000 - tn: 1352070.0000 - fn: 50121.0000 - accuracy: 0.9590 - precision: 0.6705 - recall: 0.2530 - auc: 0.9373 - val_loss: 0.1120 - val_tp: 1927.0000 - val_fp: 975.0000 - val_tn: 150110.0000 - val_fn: 5601.0000 - val_accuracy: 0.9585 - val_precision: 0.6640 - val_recall: 0.2560 - val_auc: 0.9317\n",
      "Epoch 7/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1069 - tp: 18235.0000 - fp: 9057.0000 - tn: 1351357.0000 - fn: 48864.0000 - accuracy: 0.9594 - precision: 0.6681 - recall: 0.2718 - auc: 0.9401 - val_loss: 0.1108 - val_tp: 2033.0000 - val_fp: 1031.0000 - val_tn: 150054.0000 - val_fn: 5495.0000 - val_accuracy: 0.9589 - val_precision: 0.6635 - val_recall: 0.2701 - val_auc: 0.9338\n",
      "Epoch 8/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1055 - tp: 19127.0000 - fp: 9621.0000 - tn: 1350793.0000 - fn: 47972.0000 - accuracy: 0.9597 - precision: 0.6653 - recall: 0.2851 - auc: 0.9421 - val_loss: 0.1100 - val_tp: 2113.0000 - val_fp: 1069.0000 - val_tn: 150016.0000 - val_fn: 5415.0000 - val_accuracy: 0.9591 - val_precision: 0.6640 - val_recall: 0.2807 - val_auc: 0.9350\n",
      "Epoch 9/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1046 - tp: 19749.0000 - fp: 9984.0000 - tn: 1350430.0000 - fn: 47350.0000 - accuracy: 0.9598 - precision: 0.6642 - recall: 0.2943 - auc: 0.9435 - val_loss: 0.1094 - val_tp: 2154.0000 - val_fp: 1107.0000 - val_tn: 149978.0000 - val_fn: 5374.0000 - val_accuracy: 0.9591 - val_precision: 0.6605 - val_recall: 0.2861 - val_auc: 0.9357\n",
      "Epoch 10/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1040 - tp: 20082.0000 - fp: 10168.0000 - tn: 1350246.0000 - fn: 47017.0000 - accuracy: 0.9599 - precision: 0.6639 - recall: 0.2993 - auc: 0.9445 - val_loss: 0.1090 - val_tp: 2191.0000 - val_fp: 1126.0000 - val_tn: 149959.0000 - val_fn: 5337.0000 - val_accuracy: 0.9593 - val_precision: 0.6605 - val_recall: 0.2910 - val_auc: 0.9364\n",
      "CPU times: user 2min 29s, sys: 43.4 s, total: 3min 12s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define logs and callbacks\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=0\n",
    ")\n",
    "\n",
    "train_hist = ncf_model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_test = wide_to_long(data[\"train\"], unique_ratings)\n",
    "df_test = pd.DataFrame(long_test, columns=[\"user_id\", \"item_id\", \"interaction\"])\n",
    "ds_test, _ = make_tf_dataset(df_test, [\"interaction\"], val_split=0, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.81 s, sys: 210 ms, total: 4.02 s\n",
      "Wall time: 3.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ncf_predictions = ncf_model.predict(ds_test)\n",
    "df_test[\"ncf_predictions\"] = ncf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "      <th>ncf_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.719504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  interaction  ncf_predictions\n",
       "0        0        7            0         0.523643\n",
       "1        0       10            0         0.719504\n",
       "2        0       19            0         0.100669\n",
       "3        0       20            0         0.123813\n",
       "4        0       26            0         0.102480"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_input\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# sanity checks\n",
    "# stop execution if low standard deviation (all recommendations are the same)\n",
    "std = df_test.describe().loc[\"std\", \"ncf_predictions\"]\n",
    "if std < 0.01:\n",
    "    raise ValueError(\"Model predictions have standard deviation of less than 1e-2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural collaborative filtering predictions\n",
      "[[7.7809501e-01 3.4897393e-01 2.3736593e-01 7.5093412e-01]\n",
      " [1.5352371e-01 1.8476248e-03 2.3163706e-02 3.6399364e-03]\n",
      " [4.6624422e-02 4.7096610e-04 1.2840241e-02 1.1576419e-04]\n",
      " [8.5962385e-02 1.4925003e-03 6.1967373e-03 5.1632524e-04]\n",
      " [5.8516884e-01 2.8336483e-01 7.5634271e-02 3.0715367e-01]\n",
      " [4.0988737e-01 2.2669524e-02 1.0599941e-02 4.0282601e-01]\n",
      " [6.0177052e-01 6.6075641e-01 7.8367621e-02 8.1673837e-01]\n",
      " [4.9012059e-01 8.9323461e-02 6.3689947e-03 6.7939401e-02]\n",
      " [1.5069479e-01 1.3713539e-03 2.8979778e-04 2.2239387e-03]\n",
      " [5.0181168e-01 6.9155514e-02 3.4887791e-02 4.8452517e-01]]\n"
     ]
    }
   ],
   "source": [
    "# collapse\n",
    "data[\"ncf_predictions\"] = df_test.pivot(\n",
    "    index=\"user_id\", columns=\"item_id\", values=\"ncf_predictions\"\n",
    ").values\n",
    "print(\"Neural collaborative filtering predictions\")\n",
    "print(data[\"ncf_predictions\"][:10, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At K = 5, we have a precision of 0.10859 and a recall of 0.06487\n"
     ]
    }
   ],
   "source": [
    "precision_ncf = tf.keras.metrics.Precision(top_k=TOP_K)\n",
    "recall_ncf = tf.keras.metrics.Recall(top_k=TOP_K)\n",
    "\n",
    "precision_ncf.update_state(data[\"test\"], data[\"ncf_predictions\"])\n",
    "recall_ncf.update_state(data[\"test\"], data[\"ncf_predictions\"])\n",
    "print(\n",
    "    f\"At K = {TOP_K}, we have a precision of {precision_ncf.result().numpy():.5f}\",\n",
    "    f\"and a recall of {recall_ncf.result().numpy():.5f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At K = 5, we have a precision of 0.10541 and a recall of 0.06297\n",
      "CPU times: user 1.01 s, sys: 235 ms, total: 1.25 s\n",
      "Wall time: 858 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LightFM model\n",
    "def norm(x: float) -> float:\n",
    "    \"\"\"Normalize vector\"\"\"\n",
    "    return (x - np.min(x)) / np.ptp(x)\n",
    "\n",
    "\n",
    "lightfm_model = LightFM(loss=\"warp\")\n",
    "lightfm_model.fit(sparse.coo_matrix(data[\"train\"]), epochs=N_EPOCHS)\n",
    "\n",
    "lightfm_predictions = lightfm_model.predict(\n",
    "    df_test[\"user_id\"].values, df_test[\"item_id\"].values\n",
    ")\n",
    "df_test[\"lightfm_predictions\"] = lightfm_predictions\n",
    "wide_predictions = df_test.pivot(\n",
    "    index=\"user_id\", columns=\"item_id\", values=\"lightfm_predictions\"\n",
    ").values\n",
    "data[\"lightfm_predictions\"] = norm(wide_predictions)\n",
    "\n",
    "# compute the metrics\n",
    "precision_lightfm = tf.keras.metrics.Precision(top_k=TOP_K)\n",
    "recall_lightfm = tf.keras.metrics.Recall(top_k=TOP_K)\n",
    "precision_lightfm.update_state(data[\"test\"], data[\"lightfm_predictions\"])\n",
    "recall_lightfm.update_state(data[\"test\"], data[\"lightfm_predictions\"])\n",
    "print(\n",
    "    f\"At K = {TOP_K}, we have a precision of {precision_lightfm.result().numpy():.5f}\",\n",
    "    \"and a recall of {recall_lightfm.result().numpy():.5f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
