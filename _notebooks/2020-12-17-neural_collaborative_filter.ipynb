{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de recommendaÃ§Ã£o - Neural Collaborative Filtering\n",
    "> Com demo sobre Neural Collaborative Filtering\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [demo, neural networks, deep learning, recommender systems, paper]\n",
    "- image: https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/2020-09-11-neural_collaborative_filter/cover.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtragem Neural Colaborativa\n",
    "\n",
    "# TL; DR\n",
    "\n",
    "[https://www.youtube.com/watch?v=SD3irxdKfxk](https://www.youtube.com/watch?v=SD3irxdKfxk)\n",
    "\n",
    "Rootlabs @ lunch session on Neural Collaborative Filtering\n",
    "\n",
    "---\n",
    "\n",
    "# Sistemas de recomendaÃ§Ã£o\n",
    "\n",
    "## ðŸ¥… Objetivo\n",
    "\n",
    "O objetivo Ã© gerar recomendaÃ§Ãµes para um usuÃ¡rio. O sistema de recomendaÃ§Ã£o perfeito recomendaria a um usuÃ¡rio um item que ele gostaria, e que a pessoa nÃ£o chegaria ao item sozinha. Portanto, um modelo que recomenda os itens mais populares para todos os usuÃ¡rios nÃ£o Ã© considerado um bom sistema de recomendaÃ§Ã£o - as recomendaÃ§Ãµes nÃ£o sÃ£o personalizadas.\n",
    "\n",
    "O resultado principal de um modelo seria, por exemplo, os 10 principais itens que um usuÃ¡rio pode gostar e ainda nÃ£o viu.\n",
    "\n",
    "## ðŸ“š Dados\n",
    "\n",
    "Os dados ** podem ** incluir informaÃ§Ãµes sobre o usuÃ¡rio (ou seja: idade, sexo, informaÃ§Ãµes sobre compras anteriores), mas ** deve ** incluir informaÃ§Ãµes da interaÃ§Ã£o entre usuÃ¡rios e itens - se um usuÃ¡rio comprou / gostou / avaliou um item. Essa interaÃ§Ã£o costuma ser chamada de ** feedback **. Existem dois tipos diferentes de feedback: explÃ­cito e implÃ­cito.\n",
    "\n",
    "### ðŸ’¬ Feedback explÃ­cito x implÃ­cito\n",
    "\n",
    "** Feedback explÃ­cito ** Ã© a interaÃ§Ã£o que o usuÃ¡rio fornece intencionalmente - classificaÃ§Ãµes de 5 estrelas em um produto, a ðŸ‘ em um produto etc.\n",
    "\n",
    "** Feedback implÃ­cito ** ocorre sempre que temos uma \"dica\" das preferÃªncias do usuÃ¡rio. Comprou, viu um filme, etc. Recebemos um interesse entre o usuÃ¡rio e o item, mas nÃ£o um feedback concreto - se o usuÃ¡rio realmente gostou do item (sÃ³ porque eu vi o filme, nÃ£o significa que gostei).\n",
    "\n",
    "Como se poderia imaginar, o feedback explÃ­cito Ã© mais informativo do que o implÃ­cito. Mas, na maioria dos casos, esses dados nÃ£o estÃ£o prontamente disponÃ­veis ou sÃ£o muito escassos. No restante desta postagem, vamos nos concentrar em situaÃ§Ãµes nas quais recebemos feedback implÃ­cito.\n",
    "\n",
    "Ao trabalhar com feedback implÃ­cito, antes de dividir os dados em teste e treinamento, precisamos fazer a suposiÃ§Ã£o de que toda interaÃ§Ã£o observada Ã© positiva e a ausÃªncia de interaÃ§Ã£o Ã© negativa. No exemplo, todos os filmes que assisti eu gostei e todos os filmes que nÃ£o assisti eu nÃ£o gostaria (nÃ£o Ã© realista, mas necessÃ¡rio para definir o problema).\n",
    "\n",
    "### ðŸ”ª DivisÃ£o de \"test\" e \"train\"\n",
    "\n",
    "Depois de reunir todas as informaÃ§Ãµes, temos todos os usuÃ¡rios, itens e interaÃ§Ãµes. Podemos colocÃ¡-los em uma matriz - tambÃ©m conhecida como ** matriz de interaÃ§Ã£o **.\n",
    "\n",
    "! [https://developers.google.com/machine-learning/recommendation/images/1Dmatrix.svg] (https://developers.google.com/machine-learning/recommendation/images/1Dmatrix.svg)\n",
    "\n",
    "Exemplo de matriz de interaÃ§Ã£o entre usuÃ¡rios e filmes, do [Google Developers] (https://developers.google.com/machine-learning/recommendation/collaborative/basics).\n",
    "\n",
    "Ao construir o teste, uma ideia Ã© manter uma interaÃ§Ã£o entre um usuÃ¡rio e um item e tentar prever isso. Pela imagem acima, poderÃ­amos impedir a entrada do casal ruivo Shrek para o teste.\n",
    "\n",
    "Pode-se fazer isso amostrando uma interaÃ§Ã£o aleatoriamente para cada usuÃ¡rio, mas Ã© interessante ter em mente a taxa de teste do trem e a possibilidade de vazamento de dados. Pode ser melhor tentar dividir os dados usando os Ãºltimos * d * dias para teste e o restante para treinamento, ou algo mais prÃ³ximo do caso de uso para o qual o modelo estÃ¡ sendo construÃ­do.\n",
    "\n",
    "De certa forma, temos uma abordagem de aprendizado supervisionado, uma vez que estamos tentando prever dados rotulados. Mas, como mencionado antes, Ã© anormal no sentido de que um rÃ³tulo \"verdadeiro\" no feedback implÃ­cito pode nÃ£o corresponder ao usuÃ¡rio realmente ter gostado do item. A ruiva pode nÃ£o ter gostado de Shrek, embora isso seja desconhecido para nÃ³s. Por outro lado, ela pode gostar de \"Memento\", mas nÃ£o tinha conhecimento desse filme.\n",
    "\n",
    "Mas isso Ã© o melhor que podemos fazer com os dados que temos. Depois que os dados forem rotulados, as suposiÃ§Ãµes feitas e tivermos uma divisÃ£o de teste e trem, podemos ver como modelar nossos problemas.\n",
    "\n",
    "## ðŸ¤– Abordagens\n",
    "\n",
    "Existem duas abordagens principais quando se trata de sistemas de recomendaÃ§Ã£o - ** baseada em conteÃºdo ** e ** filtragem colaborativa **.\n",
    "\n",
    "### Content based filtering\n",
    "\n",
    "A ideia Ã© usar as informaÃ§Ãµes dos usuÃ¡rios para fazer previsÃµes sobre se ele gostarÃ¡ no futuro. Essas informaÃ§Ãµes podem incluir informaÃ§Ãµes pessoais e informaÃ§Ãµes de compras anteriores. A Ãºnica coisa a se considerar Ã© que o recurso estÃ¡ disponÃ­vel para a maioria dos usuÃ¡rios.\n",
    "\n",
    "A abordagem pode ser resumida a qualquer configuraÃ§Ã£o de aprendizado supervisionado - temos recursos (do usuÃ¡rio e do item) e um rÃ³tulo que queremos prever. A partir daÃ­, podemos usar qualquer modelo para classificaÃ§Ã£o - de regressÃ£o logÃ­stica a redes neurais.\n",
    "\n",
    "Se tivermos um feedback explÃ­cito, tambÃ©m poderÃ­amos construir um usuÃ¡rio [embedding] (https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture) que tenha recursos no mesmo espaÃ§o que os itens, e calcular a semelhanÃ§a entre eles. Por exemplo, se um usuÃ¡rio definiu que gosta de filmes de aÃ§Ã£o e drama, podemos procurar filmes de aÃ§Ã£o e drama.\n",
    "\n",
    "Mas a ideia geral Ã© ter recomendaÃ§Ãµes especÃ­ficas para um Ãºnico usuÃ¡rio - o que ele gosta, em oposiÃ§Ã£o Ã  filtragem colaborativa.\n",
    "\n",
    "**ComparaÃ§Ã£o:**\n",
    "\n",
    "- ðŸ‘ Escala bem - usa apenas dados de um usuÃ¡rio\n",
    "- ðŸ‘ Posso recomendar interesses de nicho muito especÃ­ficos - muito especÃ­ficos para um usuÃ¡rio\n",
    "- ðŸ‘Ž O modelo Ã© incapaz de explorar e expandir os interesses dos usuÃ¡rios (coisas novas que ele nÃ£o manifestou interesse no passado)\n",
    "- ðŸ‘Ž Se o modelo for construÃ­do com recursos de engenharia manual, Ã© necessÃ¡rio muito conhecimento de domÃ­nio e o modelo Ã© tÃ£o bom quanto seus recursos\n",
    "\n",
    "### Collaborative filtering\n",
    "\n",
    "Na collaborative filtering, nÃ£o usamos recursos de usuÃ¡rio ou item. NÃ³s nos concentramos inteiramente em nossa matriz de interaÃ§Ã£o. A principal ideia de alto nÃ­vel Ã© descobrir o que um usuÃ¡rio vai gostar com base no que usuÃ¡rios semelhantes gostaram no passado.\n",
    "\n",
    "! [Neural% 20Collaborative% 20Filtering% 205825ae6607e6466bb8cc70724f63af0f / Untitled.png] (Neural% 20Collaborative% 20Filtering% 205825ae6607e6466bb8cc70724f63af0f / Untitled.png)\n",
    "\n",
    "Ideia principal com filtragem colaborativa.\n",
    "\n",
    "Na imagem acima - o emoji de festa seria recomendado para caÃ§a-nÃ­queis por ser semelhante ao demÃ´nio. Aqui, \"usuÃ¡rios semelhantes\" sÃ£o aqueles que compraram os mesmos itens (ou semelhantes) no passado.\n",
    "\n",
    "Na filtragem colaborativa, olhamos apenas para todas as compras e todos os itens. EntÃ£o o modelo nÃ£o liga para o que sÃ£o os itens e nem os usuÃ¡rios. Tentamos criar embeddings de usuÃ¡rio e item Ãºteis com base nas interaÃ§Ãµes entre usuÃ¡rios e itens - ou seja: a matriz de interaÃ§Ã£o.\n",
    "\n",
    "Essa Ã© a ideia principal, mas vamos mergulhar no funcionamento desse modelo mais tarde.\n",
    "\n",
    "**ComparaÃ§Ã£o:**\n",
    "\n",
    "- ðŸ‘ Nenhum conhecimento necessÃ¡rio - nÃ£o precisamos saber nada sobre o problema para o qual estamos modelando\n",
    "- ðŸ‘ Pode generalizar interesses e recomendar mais itens novos para um usuÃ¡rio\n",
    "- ðŸ‘Ž NÃ£o dimensiona bem - precisa de todas as interaÃ§Ãµes de todos os itens e todos os usuÃ¡rios\n",
    "- ðŸ‘Ž NÃ£o incluÃ­mos quaisquer outros recursos especÃ­ficos do usuÃ¡rio nem recursos especÃ­ficos do item\n",
    "- ðŸ‘Ž Baseamos nosso modelo na matriz de interaÃ§Ã£o - nÃ£o podemos gerar previsÃµes para usuÃ¡rios sem interaÃ§Ã£o registrada (um novo usuÃ¡rio no varejo online, por exemplo); isso Ã© conhecido como ** problema de inicializaÃ§Ã£o a frio **\n",
    "\n",
    "### Abordagem hÃ­brida\n",
    "\n",
    "Ã‰ possÃ­vel um hÃ­brido entre as duas abordagens. E na maioria dos casos o que Ã© implementado. Em uma visÃ£o geral de alto nÃ­vel, o que Ã© feito Ã© ter os dois modelos lado a lado e pesar suas previsÃµes. TambÃ©m podemos determinar esses pesos de maneira orientada por dados.\n",
    "\n",
    "Isso tambÃ©m permite o fallback quando nÃ£o hÃ¡ dados de interaÃ§Ã£o para um usuÃ¡rio. Nesse caso, nos concentramos na abordagem baseada em conteÃºdo atÃ© que os dados de interaÃ§Ã£o estejam disponÃ­veis.\n",
    "\n",
    "Uma implementaÃ§Ã£o muito popular e fÃ¡cil de usar Ã© o [modelo LightFM] (https://making.lyst.com/lightfm/docs/home.html), que Ã© conhecido por alcanÃ§ar resultados muito bons.\n",
    "\n",
    "## ðŸ¤” AvaliaÃ§Ã£o\n",
    "\n",
    "Como se poderia imaginar, tÃ©cnicas de avaliaÃ§Ã£o de aprendizagem supervisionada podem ser aplicadas aqui, incluindo curvas de sustentaÃ§Ã£o, ganhos cumulativos, entre outros. No entanto, como se espera que forneÃ§amos ao usuÃ¡rio um conjunto de recomendaÃ§Ãµes e nÃ£o nos importamos necessariamente com previsÃµes de baixa classificaÃ§Ã£o, outros mÃ©todos de avaliaÃ§Ã£o que diferem das abordagens tradicionais se aplicam.\n",
    "\n",
    "As mÃ©tricas populares incluem precisÃ£o superior @k, precisÃ£o @k e recall @k. * K * Ã© o nÃºmero de itens que recomendamos a um usuÃ¡rio (no exemplo inicial, usei k = 10). A ideia Ã© calcular as mÃ©tricas olhando apenas para os K itens mais bem classificados. [Tensorflow] (https://www.tensorflow.org/api_docs/python/tf/keras/metrics?hl=fr) tambÃ©m oferece essas mÃ©tricas como uma opÃ§Ã£o para precisÃ£o regular e mÃ©tricas de recall.\n",
    "\n",
    "TambÃ©m Ã© possÃ­vel avaliar que gama de itens estÃ£o sendo recomendados - para evitar modelos em que apenas um subconjunto de todos os itens aparecem como recomendaÃ§Ãµes. Ou personalizaÃ§Ã£o - evite que os itens mais populares acabem como recomendaÃ§Ãµes. [Recmetrics] (https://github.com/statisticianinstilettos/recmetrics) oferece algumas idÃ©ias para avaliaÃ§Ã£o de motores de recomendaÃ§Ã£o.\n",
    "\n",
    "# ðŸ’â€â™‚ï¸ Filtragem Colaborativa\n",
    "\n",
    "âš ï¸ Agora vamos mergulhar na matemÃ¡tica âš ï¸\n",
    "\n",
    "## FatoraÃ§Ã£o de matriz\n",
    "\n",
    "Matematicamente falando, Ã© uma ideia bastante direta - podemos fatorar a matriz de interaÃ§Ã£o para obter os embeddings para os itens e usuÃ¡rios.\n",
    "\n",
    "Semelhante Ã  fatoraÃ§Ã£o normal, estamos procurando as matrizes $ U $ (para usuÃ¡rios) e $ I $ (para itens) que, quando multiplicadas, geram a matriz de interaÃ§Ã£o $ R $ (para avaliaÃ§Ãµes), ou\n",
    "\n",
    "$$ U \\ vezes I = R $$\n",
    "\n",
    "Observe que $ \\ times $ denota multiplicaÃ§Ã£o de matrizes e que as matrizes $ U $ e $ I $ podem variar em suas dimensÃµes dependendo do tamanho de seu vetor de incorporaÃ§Ã£o.\n",
    "\n",
    "! [https://developers.google.com/machine-learning/recommendation/images/2Dmatrix.svg] (https://developers.google.com/machine-learning/recommendation/images/2Dmatrix.svg)\n",
    "\n",
    "Exemplo de matriz de interaÃ§Ã£o e matrizes de usuÃ¡rio (Ã  esquerda) e item (em cima). O tamanho de incorporaÃ§Ã£o neste exemplo Ã© 2. Imagem de [Google Developers] (https://developers.google.com/machine-learning/recommendation/collaborative/basics).\n",
    "\n",
    "## ML\n",
    "\n",
    "Agora que sabemos o que queremos, como podemos implementar a soluÃ§Ã£o?\n",
    "\n",
    "Ã‰ aqui que o aprendizado de mÃ¡quina entra em aÃ§Ã£o. Aproximamos essas matrizes $ U $ e $ I $ com base em exemplos. ComeÃ§amos com valores aleatÃ³rios para $ U $ e $ I $, produzindo um conjunto aleatÃ³rio de nÃºmeros para $ R_ {pred} $, a matriz de interaÃ§Ã£o aproximada. Podemos comparar $ R_ {actual} $ e $ R_ {pred} $ usando qualquer funÃ§Ã£o de perda (pode pensar em algo como [entropia cruzada binÃ¡ria] (https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression) , mas somando para cada elemento na matriz) e iterar usando qualquer algoritmo de otimizaÃ§Ã£o (pode pensar em [gradiente descida] (https://en.wikipedia.org/wiki/Gradient_descent)), alterando $ U $ e $ I $ incrementalmente para chegar mais perto de $ R_ {real} $.\n",
    "\n",
    "Depois de muitas iteraÃ§Ãµes, devemos ter algo semelhante a\n",
    "\n",
    "! [https://developers.google.com/machine-learning/recommendation/images/Matrixfactor.svg] (https://developers.google.com/machine-learning/recommendation/images/Matrixfactor.svg)\n",
    "\n",
    "A matriz de interaÃ§Ã£o real Ã  esquerda ($ R_ {real} $) e a matriz aproximada, ou prevista, dadas as matrizes treinadas $ U $ e $ I $ ($ R_ {pred} $). Imagem de [Google Developers] (https://developers.google.com/machine-learning/recommendation/collaborative/matrix).\n",
    "\n",
    "Depois de muitas iteraÃ§Ãµes, a matriz converge na aproximaÃ§Ã£o das interaÃ§Ãµes reais e podemos produzir os itens com as pontuaÃ§Ãµes de prediÃ§Ã£o mais altas (que ele ainda nÃ£o gostou). Voltando para a mulher ruiva, a modelo recomendaria \"The Dark Knight Rises\".\n",
    "\n",
    "Existem outras alternativas alternativas como para perdas e algoritmos de otimizaÃ§Ã£o, que podem convergir mais rapidamente, mas podem ser mais caros computacionalmente, como os mÃ­nimos quadrados alternados ponderados (WALS). Os desenvolvedores do Google oferecem uma [visÃ£o geral] rÃ¡pida (https://developers.google.com/machine-learning/recommendation/collaborative/matrix) entre a descida gradiente e o WALS. Continuaremos com a descida gradiente assim que falaremos sobre redes neurais.\n",
    "\n",
    "### Isso faz sentido?\n",
    "\n",
    "Por que isso faz sentido com o que descrevemos [acima] (https://www.notion.so/dataroots/Neural-Collaborative-Filtering-a1277ebcc01c464fbcacbd106b6a761e#a468829b0a294c9a996cd926b298e226)?\n",
    "\n",
    "Para tornar as coisas mais simples, digamos que os encaixes dos itens sejam fixos. Ã‰ mais fÃ¡cil ver que, se dois usuÃ¡rios com comportamento muito semelhante, eles acabariam com embeddings semelhantes e, portanto, um item apreciado por um usuÃ¡rio seria recomendado ao outro.\n",
    "\n",
    "# ðŸ§  Filtragem neural colaborativa\n",
    "\n",
    "## Parte \"Neural\"\n",
    "\n",
    "A principal adiÃ§Ã£o que temos nesta parte Ã© incluir uma rede neural com esses embeddings que criamos. Isso nÃ£o Ã© diferente do processo de criaÃ§Ã£o de embeddings de palavras com redes neurais. NÃ³s aproximamos os embeddings aleatÃ³rios inicializados com base nos rÃ³tulos, usando retropropagaÃ§Ã£o. Ã‰ interessante adicionar funÃ§Ãµes nÃ£o lineares Ã s camadas da rede, uma vez que a filtragem colaborativa \"vanilla\" jÃ¡ cuida das combinaÃ§Ãµes lineares entre os embeddings de usuÃ¡rio e item (no [produto matriz] (https://dzone.com/articles / visualizing-matrix)).\n",
    "\n",
    "[Https://lh6.googleusercontent.com/kioqr4bQsvJdfvl0YJwnnyNyLG3f55ChHzkYt9cRMQYHttemX9-5vK3-005tMBZdWCSkfkSt0hQjcNxDrV46wqOLRWCLQWyuxoNfX9dSYEF7JBWXIqH1oMcQlmAy6mtMyF1KuiZ2jjs](https://lh6.googleusercontent.com/kioqr4bQsvJdfvl0YJwnnyNyLG3f55ChHzkYt9cRMQYHttemX9-5vK3-005tMBZdWCSkfkSt0hQjcNxDrV46wqOLRWCLQWyuxoNfX9dSYEF7JBWXIqH1oMcQlmAy6mtMyF1KuiZ2jjs)\n",
    "\n",
    "Rede neural para filtragem colaborativa, com base no usuÃ¡rio e embeddings de itens. Na camada de entrada, $ u $ e $ i $ sÃ£o uma codificaÃ§Ã£o ativa que representa o Ã­ndice desse usuÃ¡rio. Imagem do artigo [Neural Collaborative Filtering] (https://arxiv.org/pdf/1708.05031.pdf).\n",
    "\n",
    "Pode-se notar que as representaÃ§Ãµes aqui serÃ£o diferentes daquelas encontradas na filtragem colaborativa \"vanilla\". A ideia nÃ£o Ã© \"substituir\", mas \"adicionar\". Podemos realizar a fatoraÃ§Ã£o da matriz como uma rede neural, concatenar as camadas finais e passÃ¡-las por uma camada final que produzirÃ¡ as previsÃµes. Todos juntos, vai parecer\n",
    "\n",
    "[Https://lh4.googleusercontent.com/_UeIXyWB5RiO-wapO60ZpeB2f9MjGmXRnJk2hCUHtXdAuGyHtbTRgO8RmYCix4bWt4Snh8LUEBgiuexUR_VmsdQjo9aH4i35G3YiI8lBcyMYbNuOs1po_xjlfhudWDpnJ5O4RsKj3mw](https://lh4.googleusercontent.com/_UeIXyWB5RiO-wapO60ZpeB2f9MjGmXRnJk2hCUHtXdAuGyHtbTRgO8RmYCix4bWt4Snh8LUEBgiuexUR_VmsdQjo9aH4i35G3YiI8lBcyMYbNuOs1po_xjlfhudWDpnJ5O4RsKj3mw)\n",
    "\n",
    "Arquitetura neural colaborativa. Imagem do artigo [Neural Collaborative Filtering] (https://arxiv.org/pdf/1708.05031.pdf).\n",
    "\n",
    "Esses dois modelos diferentes juntos formam a arquitetura geral. Eles podem, no entanto, ser treinados separadamente e ajustados no final (aprendizagem por transferÃªncia). Isso pode acelerar o tempo de treinamento e produzir melhores resultados.\n",
    "\n",
    "## ðŸ’ª Ganhos\n",
    "\n",
    "A questÃ£o Ã©: a complexidade adicional vale a pena?\n",
    "\n",
    "Ao comparar experimentalmente os resultados usando o [conjunto de dados MovieLens] (https://grouplens.org/datasets/movielens/), os resultados entre o LightFM e a filtragem neural colaborativa foram semelhantes (sinta-se Ã  vontade para dar uma olhada na [demonstraÃ§Ã£o] (https://www.notion.so/dataroots/Neural-Collaborative-Filtering-a1277ebcc01c464fbcacbd106b6a761e#95a6c4f134644d1bb0d95958e978082e)!), com um custo computacional consideravelmente maior para redes neurais.\n",
    "\n",
    "Mas, por outro lado, obtemos mais flexibilidade com o modelo. AlÃ©m do mais, podemos integrar facilmente um modelo baseado em conteÃºdo (neural) para formar um sistema de recomendaÃ§Ã£o hÃ­brido no Tensorflow. E a complexidade dos problemas que podem ser resolvidos tambÃ©m aumenta - problemas complexos de PNL ou de sÃ©rie temporal podem ser integrados. PoderÃ­amos, por exemplo, alavancar modelos prÃ©-treinados como o BERT e integrÃ¡-los neste sistema hÃ­brido de recomendaÃ§Ã£o.\n",
    "\n",
    "# ðŸ’» Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso esteja rodando o notebook nÃ£o esqueÃ§a de fazer o download das bibliotecas e inicie o `tensorboard` no background:\n",
    "\n",
    "No terminal\n",
    "```bash\n",
    "pip install tensorflow lightfm pandas\n",
    "tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs\n",
    "```\n",
    "\n",
    "ou no notebook\n",
    "```python\n",
    "!pip install tensorflow lightfm pandas\n",
    "```\n",
    "\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "!tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs &\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import lightfm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy import sparse\n",
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.3.0\n",
      "LightFM version: 1.15\n",
      "Pandas version: 1.1.1\n",
      "Numpy version: 1.18.5\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"LightFM version: {lightfm.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "TOP_K = 5\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Os dados\n",
    "\n",
    "![](https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/2020-09-11-neural_collaborative_filter/matrix_factorization_with_alpha.png \"Credit: https://developers.google.com/machine-learning/recommendation/collaborative/basics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix:\n",
      "[[5 3 4 3 3 5 4 0 5 3]\n",
      " [4 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0 4 4 0]\n",
      " [0 0 0 5 0 0 5 5 5 4]\n",
      " [0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0]\n",
      " [4 0 0 4 0 0 0 0 4 0]]\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "data = fetch_movielens(min_rating=3.0)\n",
    "\n",
    "print(\"Interaction matrix:\")\n",
    "print(data[\"train\"].toarray()[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix:\n",
      "[[1 1 1 1 1 1 1 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 1 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 0]]\n",
      "\n",
      "Ratings:\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#collapse\n",
    "for dataset in [\"test\", \"train\"]:\n",
    "    data[dataset] = (data[dataset].toarray() > 0).astype(\"int8\")\n",
    "\n",
    "# Make the ratings binary\n",
    "print(\"Interaction matrix:\")\n",
    "print(data[\"train\"][:10, :10])\n",
    "\n",
    "print(\"\\nRatings:\")\n",
    "unique_ratings = np.unique(data[\"train\"])\n",
    "print(unique_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def wide_to_long(wide: np.array, possible_ratings: List[int]) -> np.array:\n",
    "    \"\"\"Go from wide table to long.\n",
    "    :param wide: wide array with user-item interactions\n",
    "    :param possible_ratings: list of possible ratings that we may have.\"\"\"\n",
    "\n",
    "    def _get_ratings(arr: np.array, rating: int) -> np.array:\n",
    "        \"\"\"Generate long array for the rating provided\n",
    "        :param arr: wide array with user-item interactions\n",
    "        :param rating: the rating that we are interested\"\"\"\n",
    "        idx = np.where(arr == rating)\n",
    "        return np.vstack(\n",
    "            (idx[0], idx[1], np.ones(idx[0].size, dtype=\"int8\") * rating)\n",
    "        ).T\n",
    "\n",
    "    long_arrays = []\n",
    "    for r in possible_ratings:\n",
    "        long_arrays.append(_get_ratings(wide, r))\n",
    "\n",
    "    return np.vstack(long_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_train = wide_to_long(data[\"train\"], unique_ratings)\n",
    "df_train = pd.DataFrame(long_train, columns=[\"user_id\", \"item_id\", \"interaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All interactions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  interaction\n",
       "0        0        7            0\n",
       "1        0       10            0\n",
       "2        0       19            0\n",
       "3        0       20            0\n",
       "4        0       26            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "print(\"All interactions:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only positive interactions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1511499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511500</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511501</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511502</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511503</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  interaction\n",
       "1511499        0        0            1\n",
       "1511500        0        1            1\n",
       "1511501        0        2            1\n",
       "1511502        0        3            1\n",
       "1511503        0        4            1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "print(\"Only positive interactions:\")\n",
    "df_train[df_train[\"interaction\"] > 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O modelo (Neural Collaborative Filtering)\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/2020-09-11-neural_collaborative_filter/ncf_all_with_alpha.png\" width=\"70%\" url=\"https://developers.google.com/machine-learning/recommendation/collaborative/basics\" description=\"Fonte: https://developers.google.com/machine-learning/recommendation/collaborative/basics\" /> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Multiply,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "def create_ncf(\n",
    "    number_of_users: int,\n",
    "    number_of_items: int,\n",
    "    latent_dim_mf: int = 4,\n",
    "    latent_dim_mlp: int = 32,\n",
    "    reg_mf: int = 0,\n",
    "    reg_mlp: int = 0.01,\n",
    "    dense_layers: List[int] = [8, 4],\n",
    "    reg_layers: List[int] = [0.01, 0.01],\n",
    "    activation_dense: str = \"relu\",\n",
    ") -> keras.Model:\n",
    "\n",
    "    # input layer\n",
    "    user = Input(shape=(), dtype=\"int32\", name=\"user_id\")\n",
    "    item = Input(shape=(), dtype=\"int32\", name=\"item_id\")\n",
    "\n",
    "    # embedding layers\n",
    "    mf_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mf_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    mlp_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mlp_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    # MF vector\n",
    "    mf_user_latent = Flatten()(mf_user_embedding(user))\n",
    "    mf_item_latent = Flatten()(mf_item_embedding(item))\n",
    "    mf_cat_latent = Multiply()([mf_user_latent, mf_item_latent])\n",
    "\n",
    "    # MLP vector\n",
    "    mlp_user_latent = Flatten()(mlp_user_embedding(user))\n",
    "    mlp_item_latent = Flatten()(mlp_item_embedding(item))\n",
    "    mlp_cat_latent = Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    mlp_vector = mlp_cat_latent\n",
    "\n",
    "    # build dense layers for model\n",
    "    for i in range(len(dense_layers)):\n",
    "        layer = Dense(\n",
    "            dense_layers[i],\n",
    "            activity_regularizer=l2(reg_layers[i]),\n",
    "            activation=activation_dense,\n",
    "            name=\"layer%d\" % i,\n",
    "        )\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "\n",
    "    predict_layer = Concatenate()([mf_cat_latent, mlp_vector])\n",
    "\n",
    "    result = Dense(\n",
    "        1, activation=\"sigmoid\", kernel_initializer=\"lecun_uniform\", name=\"interaction\"\n",
    "    )\n",
    "\n",
    "    output = result(predict_layer)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[user, item],\n",
    "        outputs=[output],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"neural_collaborative_filtering\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_user_embedding (Embedding)  (None, 32)           30176       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mlp_item_embedding (Embedding)  (None, 32)           53824       item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 32)           0           mlp_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           mlp_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mf_user_embedding (Embedding)   (None, 4)            3772        user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mf_item_embedding (Embedding)   (None, 4)            6728        item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4)            0           mf_user_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4)            0           mf_item_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer0 (Dense)                  (None, 8)            520         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 4)            0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 4)            36          layer0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8)            0           multiply[0][0]                   \n",
      "                                                                 layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "interaction (Dense)             (None, 1)            9           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 95,065\n",
      "Trainable params: 95,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#collapse\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "n_users, n_items = data[\"train\"].shape\n",
    "ncf_model = create_ncf(n_users, n_items)\n",
    "\n",
    "ncf_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")\n",
    "ncf_model._name = \"neural_collaborative_filtering\"\n",
    "ncf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    targets: List[str],\n",
    "    val_split: float = 0.1,\n",
    "    batch_size: int = 512,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"Make TensorFlow dataset from Pandas DataFrame.\n",
    "    :param df: input DataFrame - only contains features and target(s)\n",
    "    :param targets: list of columns names corresponding to targets\n",
    "    :param val_split: fraction of the data that should be used for validation\n",
    "    :param batch_size: batch size for training\n",
    "    :param seed: random seed for shuffling the data - setting to `None` will not shuffle the data\"\"\"\n",
    "\n",
    "    n_val = round(df.shape[0] * val_split)\n",
    "    if seed:\n",
    "        # shuffle all the rows\n",
    "        x = df.sample(frac=1, random_state=seed).to_dict(\"series\")\n",
    "    else:\n",
    "        x = df.to_dict(\"series\")\n",
    "    y = dict()\n",
    "    for t in targets:\n",
    "        y[t] = x.pop(t)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "    ds_val = ds.take(n_val).batch(batch_size)\n",
    "    ds_train = ds.skip(n_val).batch(batch_size)\n",
    "    return ds_train, ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation datasets\n",
    "ds_train, ds_val = make_tf_dataset(df_train, [\"interaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2789 [..............................] - ETA: 0s - loss: 2.7761 - tp: 1.0000 - fp: 32.0000 - tn: 459.0000 - fn: 20.0000 - accuracy: 0.8984 - precision: 0.0303 - recall: 0.0476 - auc: 0.4325WARNING:tensorflow:From /usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0254s). Check your callbacks.\n",
      "2789/2789 [==============================] - 9s 3ms/step - loss: 0.2318 - tp: 1691.0000 - fp: 789.0000 - tn: 1359625.0000 - fn: 65408.0000 - accuracy: 0.9536 - precision: 0.6819 - recall: 0.0252 - auc: 0.8033 - val_loss: 0.1408 - val_tp: 902.0000 - val_fp: 416.0000 - val_tn: 150669.0000 - val_fn: 6626.0000 - val_accuracy: 0.9556 - val_precision: 0.6844 - val_recall: 0.1198 - val_auc: 0.9020\n",
      "Epoch 2/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1279 - tp: 11668.0000 - fp: 6340.0000 - tn: 1354074.0000 - fn: 55431.0000 - accuracy: 0.9567 - precision: 0.6479 - recall: 0.1739 - auc: 0.9164 - val_loss: 0.1236 - val_tp: 1532.0000 - val_fp: 854.0000 - val_tn: 150231.0000 - val_fn: 5996.0000 - val_accuracy: 0.9568 - val_precision: 0.6421 - val_recall: 0.2035 - val_auc: 0.9195\n",
      "Epoch 3/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1191 - tp: 13715.0000 - fp: 7758.0000 - tn: 1352656.0000 - fn: 53384.0000 - accuracy: 0.9572 - precision: 0.6387 - recall: 0.2044 - auc: 0.9254 - val_loss: 0.1198 - val_tp: 1587.0000 - val_fp: 835.0000 - val_tn: 150250.0000 - val_fn: 5941.0000 - val_accuracy: 0.9573 - val_precision: 0.6552 - val_recall: 0.2108 - val_auc: 0.9232\n",
      "Epoch 4/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1148 - tp: 14333.0000 - fp: 7576.0000 - tn: 1352838.0000 - fn: 52766.0000 - accuracy: 0.9577 - precision: 0.6542 - recall: 0.2136 - auc: 0.9293 - val_loss: 0.1160 - val_tp: 1610.0000 - val_fp: 797.0000 - val_tn: 150288.0000 - val_fn: 5918.0000 - val_accuracy: 0.9577 - val_precision: 0.6689 - val_recall: 0.2139 - val_auc: 0.9267\n",
      "Epoch 5/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1114 - tp: 15531.0000 - fp: 7649.0000 - tn: 1352765.0000 - fn: 51568.0000 - accuracy: 0.9585 - precision: 0.6700 - recall: 0.2315 - auc: 0.9335 - val_loss: 0.1138 - val_tp: 1777.0000 - val_fp: 877.0000 - val_tn: 150208.0000 - val_fn: 5751.0000 - val_accuracy: 0.9582 - val_precision: 0.6696 - val_recall: 0.2361 - val_auc: 0.9294\n",
      "Epoch 6/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1088 - tp: 16978.0000 - fp: 8344.0000 - tn: 1352070.0000 - fn: 50121.0000 - accuracy: 0.9590 - precision: 0.6705 - recall: 0.2530 - auc: 0.9373 - val_loss: 0.1120 - val_tp: 1927.0000 - val_fp: 975.0000 - val_tn: 150110.0000 - val_fn: 5601.0000 - val_accuracy: 0.9585 - val_precision: 0.6640 - val_recall: 0.2560 - val_auc: 0.9317\n",
      "Epoch 7/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1069 - tp: 18235.0000 - fp: 9057.0000 - tn: 1351357.0000 - fn: 48864.0000 - accuracy: 0.9594 - precision: 0.6681 - recall: 0.2718 - auc: 0.9401 - val_loss: 0.1108 - val_tp: 2033.0000 - val_fp: 1031.0000 - val_tn: 150054.0000 - val_fn: 5495.0000 - val_accuracy: 0.9589 - val_precision: 0.6635 - val_recall: 0.2701 - val_auc: 0.9338\n",
      "Epoch 8/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1055 - tp: 19127.0000 - fp: 9621.0000 - tn: 1350793.0000 - fn: 47972.0000 - accuracy: 0.9597 - precision: 0.6653 - recall: 0.2851 - auc: 0.9421 - val_loss: 0.1100 - val_tp: 2113.0000 - val_fp: 1069.0000 - val_tn: 150016.0000 - val_fn: 5415.0000 - val_accuracy: 0.9591 - val_precision: 0.6640 - val_recall: 0.2807 - val_auc: 0.9350\n",
      "Epoch 9/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1046 - tp: 19749.0000 - fp: 9984.0000 - tn: 1350430.0000 - fn: 47350.0000 - accuracy: 0.9598 - precision: 0.6642 - recall: 0.2943 - auc: 0.9435 - val_loss: 0.1094 - val_tp: 2154.0000 - val_fp: 1107.0000 - val_tn: 149978.0000 - val_fn: 5374.0000 - val_accuracy: 0.9591 - val_precision: 0.6605 - val_recall: 0.2861 - val_auc: 0.9357\n",
      "Epoch 10/10\n",
      "2789/2789 [==============================] - 8s 3ms/step - loss: 0.1040 - tp: 20082.0000 - fp: 10168.0000 - tn: 1350246.0000 - fn: 47017.0000 - accuracy: 0.9599 - precision: 0.6639 - recall: 0.2993 - auc: 0.9445 - val_loss: 0.1090 - val_tp: 2191.0000 - val_fp: 1126.0000 - val_tn: 149959.0000 - val_fn: 5337.0000 - val_accuracy: 0.9593 - val_precision: 0.6605 - val_recall: 0.2910 - val_auc: 0.9364\n",
      "CPU times: user 2min 29s, sys: 43.4 s, total: 3min 12s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define logs and callbacks\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=0\n",
    ")\n",
    "\n",
    "train_hist = ncf_model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_test = wide_to_long(data[\"train\"], unique_ratings)\n",
    "df_test = pd.DataFrame(long_test, columns=[\"user_id\", \"item_id\", \"interaction\"])\n",
    "ds_test, _ = make_tf_dataset(df_test, [\"interaction\"], val_split=0, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.81 s, sys: 210 ms, total: 4.02 s\n",
      "Wall time: 3.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ncf_predictions = ncf_model.predict(ds_test)\n",
    "df_test[\"ncf_predictions\"] = ncf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "      <th>ncf_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.719504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  interaction  ncf_predictions\n",
       "0        0        7            0         0.523643\n",
       "1        0       10            0         0.719504\n",
       "2        0       19            0         0.100669\n",
       "3        0       20            0         0.123813\n",
       "4        0       26            0         0.102480"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# sanity checks - stop execution if we have low standard deviation (all recommendations are the same)\n",
    "std = df_test.describe().loc[\"std\", \"ncf_predictions\"]\n",
    "if std < 0.01:\n",
    "    raise ValueError(\"Model predictions have standard deviation of less than 1e-2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural collaborative filtering predictions\n",
      "[[7.7809501e-01 3.4897393e-01 2.3736593e-01 7.5093412e-01]\n",
      " [1.5352371e-01 1.8476248e-03 2.3163706e-02 3.6399364e-03]\n",
      " [4.6624422e-02 4.7096610e-04 1.2840241e-02 1.1576419e-04]\n",
      " [8.5962385e-02 1.4925003e-03 6.1967373e-03 5.1632524e-04]\n",
      " [5.8516884e-01 2.8336483e-01 7.5634271e-02 3.0715367e-01]\n",
      " [4.0988737e-01 2.2669524e-02 1.0599941e-02 4.0282601e-01]\n",
      " [6.0177052e-01 6.6075641e-01 7.8367621e-02 8.1673837e-01]\n",
      " [4.9012059e-01 8.9323461e-02 6.3689947e-03 6.7939401e-02]\n",
      " [1.5069479e-01 1.3713539e-03 2.8979778e-04 2.2239387e-03]\n",
      " [5.0181168e-01 6.9155514e-02 3.4887791e-02 4.8452517e-01]]\n"
     ]
    }
   ],
   "source": [
    "#collapse\n",
    "data[\"ncf_predictions\"] = df_test.pivot(\n",
    "    index=\"user_id\", columns=\"item_id\", values=\"ncf_predictions\"\n",
    ").values\n",
    "print(\"Neural collaborative filtering predictions\")\n",
    "print(data[\"ncf_predictions\"][:10, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At K = 5, we have a precision of 0.10859 and a recall of 0.06487\n"
     ]
    }
   ],
   "source": [
    "precision_ncf = tf.keras.metrics.Precision(top_k=TOP_K)\n",
    "recall_ncf = tf.keras.metrics.Recall(top_k=TOP_K)\n",
    "\n",
    "precision_ncf.update_state(data[\"test\"], data[\"ncf_predictions\"])\n",
    "recall_ncf.update_state(data[\"test\"], data[\"ncf_predictions\"])\n",
    "print(\n",
    "    f\"At K = {TOP_K}, we have a precision of {precision_ncf.result().numpy():.5f} and a recall of {recall_ncf.result().numpy():.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At K = 5, we have a precision of 0.10541 and a recall of 0.06297\n",
      "CPU times: user 1.01 s, sys: 235 ms, total: 1.25 s\n",
      "Wall time: 858 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LightFM model\n",
    "norm = lambda x: (x - np.min(x)) / np.ptp(x)\n",
    "lightfm_model = LightFM(loss=\"warp\")\n",
    "lightfm_model.fit(sparse.coo_matrix(data[\"train\"]), epochs=N_EPOCHS)\n",
    "\n",
    "lightfm_predictions = lightfm_model.predict(\n",
    "    df_test[\"user_id\"].values, df_test[\"item_id\"].values\n",
    ")\n",
    "df_test[\"lightfm_predictions\"] = lightfm_predictions\n",
    "wide_predictions = df_test.pivot(\n",
    "    index=\"user_id\", columns=\"item_id\", values=\"lightfm_predictions\"\n",
    ").values\n",
    "data[\"lightfm_predictions\"] = norm(wide_predictions)\n",
    "\n",
    "# compute the metrics\n",
    "precision_lightfm = tf.keras.metrics.Precision(top_k=TOP_K)\n",
    "recall_lightfm = tf.keras.metrics.Recall(top_k=TOP_K)\n",
    "precision_lightfm.update_state(data[\"test\"], data[\"lightfm_predictions\"])\n",
    "recall_lightfm.update_state(data[\"test\"], data[\"lightfm_predictions\"])\n",
    "print(\n",
    "    f\"At K = {TOP_K}, we have a precision of {precision_lightfm.result().numpy():.5f} and a recall of {recall_lightfm.result().numpy():.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
