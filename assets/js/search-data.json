{
  
    
        "post0": {
            "title": "Fuzzy string matching",
            "content": "Introdu&#231;&#227;o . V√°rias vezes, n√≥s temos texto como parte dos nossos dados (strings). Em v√°rias aplica√ß√µes (n√£o s√≥ em machine learning), esses dados vem de usu√°rios - quando voc√™ preenche um formul√°rio, coloca seu nome, endere√ßo, etc. . O problema √© que muitas pessoas n√£o escrevem os dados igual. Por exemplo, eu ja vi meu nome escrito como murilo, Murilo, murilio, murillo, Murilo, Mr. Murilo, etc. Mas todos essas strings deveriam se referir pra mesma coisa. Como que a gente pode decidir se esses s√£o iguais ou n√£o? . Fuzzy string matching . Os algoritmos que resolvem esse problema se chamam fuzzy string matching, ou aproxima√ß√µes em compara√ß√µes de strings. Um algoritmo popular √© a dist√¢ncia Levenshtein, que basicamente vai computando quantas altera√ß√µes voc√™ teria de fazer entre as duas strings. Por exemplo, indo de kitten para sitting (exemplo do Wikipedia: . $$kitten rightarrow textbf{s}itten rightarrow sitt textbf{i}n rightarrow sittin textbf{g}$$ . A dist√¢ncia Levenshtein nesse caso √© 3, porque temos 3 transforma√ß√µes entre a palavra de origem e a palavra de destino: . Substitui√ß√£o de k por s | Substitui√ß√£o de e por i | inser√ß√£o de g no final | E essa √© a id√©ia principal (e passando por cima de alguns detalhes üòÖ). Simples, n√©? O algoritmo tamb√©m √© implementado com recurs√£o por efici√™ncia, mas qu√£o efficiente √© esse algoritmo? Na vida real (especialmente em machine learning), n√≥s temos muitos dados, ent√£o √© importante vermos como que esse algoritmo escala. Isso √©, quanto tempo demora/quanta mem√≥ria vamos usar enquando o volume de dados aumenta? . FuzzyWuzzy . FuzzyWuzzy √© uma biblioteca em python (bem popular) que implementa esse algoritmo. Al√©m disso, o pacote tamb√©m oferece uma vers√£o mais r√°pida que faz algumas aproxima√ß√µes. Vamos ver como funciona o API. . # exemplo da documenta√ß√£o da biblioteca from fuzzywuzzy import fuzz, process choices = [&quot;Atlanta Falcons&quot;, &quot;New York Jets&quot;, &quot;New York Giants&quot;, &quot;Dallas Cowboys&quot;] . %timeit process.extract(&quot;new york jets&quot;, choices, limit=2) # s√≥ pra registrar o tempo process.extract(&quot;new york jets&quot;, choices, limit=2) . 89.3 ¬µs ¬± 1.1 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10000 loops each) . [(&#39;New York Jets&#39;, 100), (&#39;New York Giants&#39;, 79)] . %timeit process.extractOne(&quot;cowboys&quot;, choices) # s√≥ pra registrar o tempo process.extractOne(&quot;cowboys&quot;, choices) . 191 ¬µs ¬± 1.45 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10000 loops each) . (&#39;Dallas Cowboys&#39;, 90) . E √© isso! Mas mais uma vez, quanto tempo ser√° que demora quando temos mais dados? Vamos ver. . Conectando datasets . Um outro caso que √© importante √© quando temos dois datasets (tabelas nesse caso), algumas colunas tem os mesmos dados, mas elas est√£o escritos de maneiras diferentes! Ou ent√£o, quando os dados se repetem, e temos que deduplicar os dados. Isso acontece por exemplo quando o usu√°rio se registra mas coloca um email ou nome errado, ent√£o preenche o formul√°rio de novo. Vamos ver um exemplo. . import pandas as pd from recordlinkage.datasets import load_febrl1 df = load_febrl1() df.head() . given_name surname street_number address_1 address_2 suburb postcode state date_of_birth soc_sec_id . rec_id . rec-223-org NaN | waller | 6 | tullaroop street | willaroo | st james | 4011 | wa | 19081209 | 6988048 | . rec-122-org lachlan | berry | 69 | giblin street | killarney | bittern | 4814 | qld | 19990219 | 7364009 | . rec-373-org deakin | sondergeld | 48 | goldfinch circuit | kooltuo | canterbury | 2776 | vic | 19600210 | 2635962 | . rec-10-dup-0 kayla | harrington | NaN | maltby circuit | coaling | coolaroo | 3465 | nsw | 19150612 | 9004242 | . rec-227-org luke | purdon | 23 | ramsay place | mirani | garbutt | 2260 | vic | 19831024 | 8099933 | . Vamos focar no nome completo, ou seja o given_name e surname . # collapse df[[&quot;given_name&quot;, &quot;surname&quot;]] = df[[&quot;given_name&quot;, &quot;surname&quot;]].fillna(&quot;&quot;) df[&quot;full_name&quot;] = df[&quot;given_name&quot;] + &quot; &quot; + df[&quot;surname&quot;] df = df[[&quot;full_name&quot;]].reset_index() df.head() . . rec_id full_name . 0 rec-223-org | waller | . 1 rec-122-org | lachlan berry | . 2 rec-373-org | deakin sondergeld | . 3 rec-10-dup-0 | kayla harrington | . 4 rec-227-org | luke purdon | . Vamos fazer todas as compara√ß√µes poss√≠veis! Esse dataset tem s√≥ 500 entradas ent√£o n√£o tem muito problema . # collapse df = df.merge(df, how=&quot;cross&quot;).sample( frac=1, random_state=42 ) # cria todas as combina√ß√µes e depois mistura as linhas df = df[ df[&quot;full_name_x&quot;] != df[&quot;full_name_y&quot;] ] # vamos retirar as que s√£o exatamente iguais df = df[[&quot;rec_id_x&quot;, &quot;rec_id_y&quot;, &quot;full_name_x&quot;, &quot;full_name_y&quot;]].reset_index( drop=True ) # reorganizando as colunas df[&quot;names&quot;] = pd.Series( zip(df[&quot;full_name_x&quot;], df[&quot;full_name_y&quot;]) ) # criando a coluna pra comparar os nomes df.head() . . rec_id_x rec_id_y full_name_x full_name_y names . 0 rec-498-dup-0 | rec-372-dup-0 | claire crook | talia ho | (claire crook, talia ho) | . 1 rec-484-org | rec-220-org | jacynta hoffman | tyler heerey | (jacynta hoffman, tyler heerey) | . 2 rec-410-dup-0 | rec-261-dup-0 | sachin connerty | wilde | (sachin connerty, wilde) | . 3 rec-54-org | rec-246-dup-0 | emiily morrison | burford jack | (emiily morrison, burford jack) | . 4 rec-370-dup-0 | rec-386-dup-0 | rourke webv | dylan dolby | (rourke webv, dylan dolby) | . E agora podemos computar o algoritmo! . %%time df[&quot;fuzzywuzzy&quot;] = df[&quot;names&quot;].apply(lambda x: fuzz.ratio(x[0], x[1])) df.head() . CPU times: user 2.94 s, sys: 59.6 ms, total: 3 s Wall time: 3.03 s . rec_id_x rec_id_y full_name_x full_name_y names fuzzywuzzy . 0 rec-498-dup-0 | rec-372-dup-0 | claire crook | talia ho | (claire crook, talia ho) | 40 | . 1 rec-484-org | rec-220-org | jacynta hoffman | tyler heerey | (jacynta hoffman, tyler heerey) | 22 | . 2 rec-410-dup-0 | rec-261-dup-0 | sachin connerty | wilde | (sachin connerty, wilde) | 19 | . 3 rec-54-org | rec-246-dup-0 | emiily morrison | burford jack | (emiily morrison, burford jack) | 15 | . 4 rec-370-dup-0 | rec-386-dup-0 | rourke webv | dylan dolby | (rourke webv, dylan dolby) | 18 | . Para a nossa tabela com 998512 linhas, o algoritmo demorou 2.9 segundos. Nada mal. E as compara√ß√µes parecem boas! Alguns exemplos de igualdade: . df[[&quot;full_name_x&quot;, &quot;full_name_y&quot;, &quot;fuzzywuzzy&quot;]].sort_values( by=&quot;fuzzywuzzy&quot;, ascending=False ).head() . full_name_x full_name_y fuzzywuzzy . 926629 charldotte campbell | charlotte campbell | 97 | . 463495 lucas rawldings | lucas rawlings | 97 | . 890513 john van&#39;t hof | john van&#39;wt hof | 97 | . 969177 jaden humphkreys | jaden humphreys | 97 | . 680776 kirah mccarthy | kirrah mccarthy | 97 | . E alguns exemplos de desigualdade: . df[[&quot;full_name_x&quot;, &quot;full_name_y&quot;, &quot;fuzzywuzzy&quot;]].sort_values( by=&quot;fuzzywuzzy&quot;, ascending=False ).tail() . full_name_x full_name_y fuzzywuzzy . 689287 ruby riding | takeisha smallacombe | 6 | . 585410 timothy mccarthy | annablle kounis | 6 | . 232904 jacynta hoffman | brooke durbridge | 6 | . 775239 annablle kounis | timothy mccarthy | 6 | . 148505 brooke durbridge | jacynta hoffman | 6 | . Vamos olhar o tempo mais de perto... Ser√° que a gente poderia melhorar isso? . %timeit df[&quot;names&quot;].apply(lambda x: fuzz.ratio(x[0], x[1])) . 2.99 s ¬± 44.4 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each) . RapidFuzz . RapidFuzz √© uma outra biblioteca em python. Mais nova, que tem algumas pequenas diferen√ßas: . A licen√ßa que eles est√£o usando √© mais permissiva. Aqui voc√™ est√° livre pra usar qualquer licen√ßa no seu projeto (no FuzzyWuzzy voc√™ era obrigado a usar uma licen√ßa GPL). N√£o muito interessante ü•± | √â mais rapida! Tem algumas melhorias na parte da implementa√ß√£o do algoritmo mas tamb√©m √© implementada em C++!!‚ö°Ô∏è‚ö°Ô∏è | . . O qu√£o mais r√°pida? Vamos ver. . Usando a mesma estrat√©gia de antes: . # usando os mesmo exemplos do in√≠cio (e tamb√©m na biblioteca) from rapidfuzz import fuzz, process choices = [&quot;Atlanta Falcons&quot;, &quot;New York Jets&quot;, &quot;New York Giants&quot;, &quot;Dallas Cowboys&quot;] . %timeit process.extract(&quot;new york jets&quot;, choices, limit=2) # s√≥ pra registrar o tempo process.extract(&quot;new york jets&quot;, choices, limit=2) . 8.23 ¬µs ¬± 173 ns per loop (mean ¬± std. dev. of 7 runs, 100000 loops each) . [(&#39;New York Jets&#39;, 100.0, 1), (&#39;New York Giants&#39;, 78.57142857142857, 2)] . %timeit process.extractOne(&quot;cowboys&quot;, choices) # s√≥ pra registrar o tempo process.extractOne(&quot;cowboys&quot;, choices) . 14.4 ¬µs ¬± 236 ns per loop (mean ¬± std. dev. of 7 runs, 100000 loops each) . (&#39;Dallas Cowboys&#39;, 90.0, 3) . Antes o c√≥digo demorou 89.3¬µs e 191¬µs, respectivamente. Agora, demoramos 8.23¬µs e 14.4¬µs (&lt;10% do tempo de antes)! Mas como escala? Vamos de novo olhar pro exemplo da deduplica√ß√£o de dados: . %%time df[&quot;rapidfuzz&quot;] = df[&quot;names&quot;].apply(lambda x: fuzz.ratio(x[0], x[1])) df.head() . CPU times: user 419 ms, sys: 26.7 ms, total: 445 ms Wall time: 449 ms . rec_id_x rec_id_y full_name_x full_name_y names fuzzywuzzy RapidFuzz rapidfuzz . 0 rec-498-dup-0 | rec-372-dup-0 | claire crook | talia ho | (claire crook, talia ho) | 40 | 40.000000 | 40.000000 | . 1 rec-484-org | rec-220-org | jacynta hoffman | tyler heerey | (jacynta hoffman, tyler heerey) | 22 | 22.222222 | 22.222222 | . 2 rec-410-dup-0 | rec-261-dup-0 | sachin connerty | wilde | (sachin connerty, wilde) | 19 | 19.047619 | 19.047619 | . 3 rec-54-org | rec-246-dup-0 | emiily morrison | burford jack | (emiily morrison, burford jack) | 15 | 14.814815 | 14.814815 | . 4 rec-370-dup-0 | rec-386-dup-0 | rourke webv | dylan dolby | (rourke webv, dylan dolby) | 18 | 18.181818 | 18.181818 | . E os resultados dos dois algoritmos s√£o exatamente iguais! (Com a pequena excess√£o que o FuzzyWuzzy retorna n√∫meros inteiros e o RapidFuzz retorna fra√ß√µes) . %timeit df[&quot;names&quot;].apply(lambda x: fuzz.ratio(x[0], x[1])) . 445 ms ¬± 25 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each) . Menos 15% do tempo de antes!! S√≥ trocando a biblioteca! . . Al√©m disso a documenta√ß√£o faz mais compara√ß√µes pra diferentes tarefas e como s√£o os n√∫meros com a maior quantidade de dados. . . Pra mais gr√°ficos, fica a documenta√ß√£o. . Uma &#250;ltima coisa... . A gente pode melhorar isso ainda mais quando quisermos deduplicar linhas na minha tabela? . Sim. Mas n√£o na parte algoritmica. Na vida real, temos tamb√©m de ser espertos na hora de computar as coisas. Se estivermos comparando endere√ßos por exemplo, a rua e n√∫mero talvez estejam diferentes, mas a cidade e estado provavelmente n√£o, especialmente porque numa grande parte esses vem de um dropdown, ent√£o os dados vem &quot;limpos&quot;. . Nesses casos, ao inv√©s de criar todas as combina√ß√µes possiveis, a gente pode criar as combina√ß√µes dentro de cada grupo - no nosso exemplo quando os estados e cidades s√£o iguais. Reduzindo o n√∫mero de combina√ß√µes j√° reduz bastante o trabalho. E na maioria dos casos, √© ai que temos os maiores ganhos. E ainda por cima, existem bibliotecas como o Record Linkage Toolkit que s√£o feitos exatamente pra isso. Ou seja, as vezes √© melhor sentar e pensar antes de ficar quebrando a cabe√ßa em como otimizar um algoritmo. üòá . .",
            "url": "https://murilo-cunha.github.io/inteligencia-superficial/demo/fuzzy%20string%20matching/nlp/2021/06/10/fuzzy_string_matching.html",
            "relUrl": "/demo/fuzzy%20string%20matching/nlp/2021/06/10/fuzzy_string_matching.html",
            "date": " ‚Ä¢ Jun 10, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Sistemas de recommenda√ß√£o - Neural Collaborative Filtering",
            "content": "Neural collaborative filtering . TL; DR . Rootlabs @ lunch session on Neural Collaborative Filtering . . Sistemas de recomenda&#231;&#227;o . &#129349; Objetivo . O objetivo √© gerar recomenda√ß√µes para um usu√°rio. O sistema de recomenda√ß√£o perfeito recomendaria a um usu√°rio um item que ele gostaria, e que a pessoa n√£o chegaria ao item sozinha. Portanto, um modelo que recomenda os itens mais populares para todos os usu√°rios n√£o √© considerado um bom sistema de recomenda√ß√£o - as recomenda√ß√µes n√£o s√£o personalizadas. . O resultado principal de um modelo seria, por exemplo, os 10 principais itens que um usu√°rio pode gostar e ainda n√£o viu. . &#128218; Dados . Os dados podem incluir informa√ß√µes sobre o usu√°rio (ou seja: idade, sexo, informa√ß√µes sobre compras anteriores), mas deve incluir informa√ß√µes da intera√ß√£o entre usu√°rios e itens - se um usu√°rio comprou/gostou/avaliou um item. Essa intera√ß√£o costuma ser chamada de feedback. Existem dois tipos diferentes de feedback: expl√≠cito e impl√≠cito. . &#128172; Feedback expl&#237;cito x impl&#237;cito . Feedback expl√≠cito √© a intera√ß√£o que o usu√°rio fornece intencionalmente - classifica√ß√µes de 5 estrelas em um produto, a üëç em um produto etc. . Feedback impl√≠cito ocorre sempre que temos uma &quot;dica&quot; das prefer√™ncias do usu√°rio. Comprou, viu um filme, etc. Recebemos um interesse entre o usu√°rio e o item, mas n√£o um feedback concreto - se o usu√°rio realmente gostou do item (s√≥ porque eu vi o filme, n√£o significa que gostei). . Como se poderia imaginar, o feedback expl√≠cito √© mais informativo do que o impl√≠cito. Mas, na maioria dos casos, esses dados n√£o est√£o prontamente dispon√≠veis ou s√£o muito escassos. No restante desta postagem, vamos nos concentrar em situa√ß√µes nas quais recebemos feedback impl√≠cito. . Ao trabalhar com feedback impl√≠cito, antes de dividir os dados em teste e treinamento, precisamos fazer a suposi√ß√£o de que toda intera√ß√£o observada √© positiva e a aus√™ncia de intera√ß√£o √© negativa. No exemplo, todos os filmes que assisti eu gostei e todos os filmes que n√£o assisti eu n√£o gostaria (n√£o √© realista, mas necess√°rio para definir o problema). . &#128298; Divis&#227;o de &quot;test&quot; e &quot;train&quot; . Depois de reunir todas as informa√ß√µes, temos todos os usu√°rios, itens e intera√ß√µes. Podemos coloc√°-los em uma matriz - tamb√©m conhecida como matriz de intera√ß√£o. . Ao construir o teste, uma ideia √© manter uma intera√ß√£o entre um usu√°rio e um item e tentar prever isso. Pela imagem acima, poder√≠amos impedir a entrada do casal ruivo Shrek para o teste. . Pode-se fazer isso amostrando uma intera√ß√£o aleatoriamente para cada usu√°rio, mas √© interessante ter em mente a taxa de teste do trem e a possibilidade de vazamento de dados. Pode ser melhor tentar dividir os dados usando os √∫ltimos d dias para teste e o restante para treinamento, ou algo mais pr√≥ximo do caso de uso para o qual o modelo est√° sendo constru√≠do. . De certa forma, temos uma abordagem de aprendizado supervisionado, uma vez que estamos tentando prever dados rotulados. Mas, como mencionado antes, √© anormal no sentido de que um r√≥tulo &quot;verdadeiro&quot; no feedback impl√≠cito pode n√£o corresponder ao usu√°rio realmente ter gostado do item. A ruiva pode n√£o ter gostado de Shrek, embora isso seja desconhecido para n√≥s. Por outro lado, ela pode gostar de &quot;Memento&quot;, mas n√£o tinha conhecimento desse filme. . Mas isso √© o melhor que podemos fazer com os dados que temos. Depois que os dados forem rotulados, as suposi√ß√µes feitas e tivermos uma divis√£o de teste e trem, podemos ver como modelar nossos problemas. . &#129302; Abordagens . Existem duas abordagens principais quando se trata de sistemas de recomenda√ß√£o - content based filtering e collaborative filtering. . Content based filtering . A ideia √© usar as informa√ß√µes dos usu√°rios para fazer previs√µes sobre se ele gostar√° no futuro. Essas informa√ß√µes podem incluir informa√ß√µes pessoais e informa√ß√µes de compras anteriores. A √∫nica coisa a se considerar √© que o recurso est√° dispon√≠vel para a maioria dos usu√°rios. . A abordagem pode ser resumida a qualquer configura√ß√£o de aprendizado supervisionado - temos recursos (do usu√°rio e do item) e um r√≥tulo que queremos prever. A partir da√≠, podemos usar qualquer modelo para classifica√ß√£o - de regress√£o log√≠stica a redes neurais. . Se tivermos um feedback expl√≠cito, tamb√©m poder√≠amos construir um usu√°rio embedding que tenha recursos no mesmo espa√ßo que os itens, e calcular a semelhan√ßa entre eles. Por exemplo, se um usu√°rio definiu que gosta de filmes de a√ß√£o e drama, podemos procurar filmes de a√ß√£o e drama. . Mas a ideia geral √© ter recomenda√ß√µes espec√≠ficas para um √∫nico usu√°rio - o que ele gosta, em oposi√ß√£o ao collaborative filtering. . Compara√ß√£o: . üëç Escala bem - usa apenas dados de um usu√°rio | üëç Posso recomendar interesses de nicho muito espec√≠ficos - muito espec√≠ficos para um usu√°rio | üëé O modelo √© incapaz de explorar e expandir os interesses dos usu√°rios (coisas novas que ele n√£o manifestou interesse no passado) | üëé Se o modelo for constru√≠do com recursos de engenharia manual, √© necess√°rio muito conhecimento de dom√≠nio e o modelo √© t√£o bom quanto seus recursos | . Collaborative filtering . Na collaborative filtering, n√£o usamos recursos de usu√°rio ou item. N√≥s nos concentramos inteiramente em nossa matriz de intera√ß√£o. A principal ideia de alto n√≠vel √© descobrir o que um usu√°rio vai gostar com base no que usu√°rios semelhantes gostaram no passado. . Ideia principal com collaborative filtering. . Na imagem acima - o emoji de festa seria recomendado para ca√ßa-n√≠queis por ser semelhante ao dem√¥nio. Aqui, &quot;usu√°rios semelhantes&quot; s√£o aqueles que compraram os mesmos itens (ou semelhantes) no passado. . No collaborative filtering, olhamos apenas para todas as compras e todos os itens. Ent√£o o modelo n√£o liga para o que s√£o os itens e nem os usu√°rios. Tentamos criar embeddings de usu√°rio e item √∫teis com base nas intera√ß√µes entre usu√°rios e itens - ou seja: a matriz de intera√ß√£o. . Essa √© a ideia principal, mas vamos mergulhar no funcionamento desse modelo mais tarde. . Compara√ß√£o: . üëç Nenhum conhecimento necess√°rio - n√£o precisamos saber nada sobre o problema para o qual estamos modelando | üëç Pode generalizar interesses e recomendar mais itens novos para um usu√°rio | üëé N√£o dimensiona bem - precisa de todas as intera√ß√µes de todos os itens e todos os usu√°rios | üëé N√£o inclu√≠mos quaisquer outros recursos espec√≠ficos do usu√°rio nem recursos espec√≠ficos do item | üëé Baseamos nosso modelo na matriz de intera√ß√£o - n√£o podemos gerar previs√µes para usu√°rios sem intera√ß√£o registrada (um novo usu√°rio no varejo online, por exemplo); isso √© conhecido como problema de inicializa√ß√£o a frio | . Abordagem h&#237;brida . √â poss√≠vel um h√≠brido entre as duas abordagens. E na maioria dos casos o que √© implementado. Em uma vis√£o mais geral, o que √© feito √© ter os dois modelos lado a lado e pesar suas previs√µes. Tamb√©m podemos determinar esses pesos de maneira orientada por dados. . Isso tamb√©m permite o fallback quando n√£o h√° dados de intera√ß√£o para um usu√°rio. Nesse caso, nos concentramos na abordagem &quot;content based&quot; at√© que os dados de intera√ß√£o estejam dispon√≠veis. . Uma implementa√ß√£o muito popular e f√°cil de usar √© o modelo LightFM, que √© conhecido por alcan√ßar resultados muito bons. . &#129300; Avalia&#231;&#227;o . Como se poderia imaginar, t√©cnicas de avalia√ß√£o de aprendizagem supervisionada podem ser aplicadas aqui, incluindo curvas de sustenta√ß√£o, ganhos cumulativos, entre outros. No entanto, como se espera que forne√ßamos ao usu√°rio um conjunto de recomenda√ß√µes e n√£o nos importamos necessariamente com previs√µes de baixa classifica√ß√£o, outros m√©todos de avalia√ß√£o que diferem das abordagens tradicionais se aplicam. . As m√©tricas populares incluem precis√£o superior @k, precis√£o @k e recall @k. K √© o n√∫mero de itens que recomendamos a um usu√°rio (no exemplo inicial, usei k = 10). A ideia √© calcular as m√©tricas olhando apenas para os K itens mais bem classificados. Tensorflow tamb√©m oferece essas m√©tricas como uma op√ß√£o para precis√£o regular e m√©tricas de recall. . Tamb√©m √© poss√≠vel avaliar que gama de itens est√£o sendo recomendados - para evitar modelos em que apenas um subconjunto de todos os itens aparecem como recomenda√ß√µes. Ou personaliza√ß√£o - evite que os itens mais populares acabem como recomenda√ß√µes. Recmetrics oferece algumas id√©ias para avalia√ß√£o de motores de recomenda√ß√£o. . &#128129;&#8205;&#9794;&#65039; Collaborative filtering . ‚ö†Ô∏è Agora vamos mergulhar na matem√°tica ‚ö†Ô∏è . Fatora&#231;&#227;o de matriz . Matematicamente falando, √© uma ideia bastante direta - podemos fatorar a matriz de intera√ß√£o para obter os embeddings para os itens e usu√°rios. . Semelhante √† fatora√ß√£o normal, estamos procurando as matrizes $U$ (para usu√°rios) e $I$ (para itens) que, quando multiplicadas, geram a matriz de intera√ß√£o $R$ (para avalia√ß√µes), ou . $$U cdot I = R$$ . Observe que $ cdot$ denota multiplica√ß√£o de matrizes e que as matrizes $U$ e $I$ podem variar em suas dimens√µes dependendo do tamanho de seu vetor de incorpora√ß√£o. . . Exemplo de matriz de intera√ß√£o e matrizes de usu√°rio (√† esquerda) e item (em cima). O tamanho de incorpora√ß√£o neste exemplo √© 2. Imagem de Google Developers. . ML . Agora que sabemos o que queremos, como podemos implementar a solu√ß√£o? . √â aqui que o aprendizado de m√°quina entra em a√ß√£o. Aproximamos essas matrizes $U$ e $I$ com base em exemplos. Come√ßamos com valores aleat√≥rios para $U$ e $I$, produzindo um conjunto aleat√≥rio de n√∫meros para $R_{pred}$, a matriz de intera√ß√£o aproximada. Podemos comparar $R_ {actual}$ e $R_ {pred}$ usando qualquer fun√ß√£o de perda (pode pensar em algo como entropia cruzada bin√°ria , mas somando para cada elemento na matriz) e iterar usando qualquer algoritmo de otimiza√ß√£o (pode pensar em &quot;gradient descent&quot;), alterando $U$ e $I$ incrementalmente para chegar mais perto de $R_ {real}$. . Depois de muitas itera√ß√µes, devemos ter algo semelhante a . . A matriz de intera√ß√£o real √† esquerda ($R_ {real}$) e a matriz aproximada, ou prevista, dadas as matrizes treinadas $U$ e $I$ ($R_ {pred}$). Imagem de Google Developers. . Depois de muitas itera√ß√µes, a matriz converge na aproxima√ß√£o das intera√ß√µes reais e podemos produzir os itens com as pontua√ß√µes de predi√ß√£o mais altas (que ele ainda n√£o gostou). Voltando para a mulher ruiva, a modelo recomendaria &quot;The Dark Knight Rises&quot;. . Existem outras alternativas alternativas como para perdas e algoritmos de otimiza√ß√£o, que podem convergir mais rapidamente, mas podem ser mais caros computacionalmente, como os m√≠nimos quadrados alternados ponderados (WALS). Os Google Developers oferecem uma compara√ß√£o geral entre o &quot;gradient descent&quot; e o WALS. Continuaremos com a &quot;gradient descent&quot; assim que falaremos sobre redes neurais. . Isso faz sentido? . Por que isso faz sentido com o que descrevemos acima? . Para tornar as coisas mais simples, digamos que os encaixes dos itens sejam fixos. √â mais f√°cil ver que, se dois usu√°rios com comportamento muito semelhante, eles acabariam com embeddings semelhantes e, portanto, um item apreciado por um usu√°rio seria recomendado ao outro. . &#129504; Neural collaborative filtering . Parte &quot;Neural&quot; . A principal adi√ß√£o que temos nesta parte √© incluir uma rede neural com esses embeddings que criamos. Isso n√£o √© diferente do processo de cria√ß√£o de embeddings de palavras com redes neurais. N√≥s aproximamos os embeddings aleat√≥rios inicializados com base nos r√≥tulos, usando retropropaga√ß√£o. √â interessante adicionar fun√ß√µes n√£o lineares √†s camadas da rede, uma vez que o &quot;collaborative filtering&quot; &quot;vanilla&quot; j√° cuida das combina√ß√µes lineares entre os embeddings de usu√°rio e item (no produto matriz). . . Rede neural para &quot;collaborative filtering&quot;, com base no usu√°rio e embeddings de itens. Na camada de entrada, $u$ e $i$ s√£o uma codifica√ß√£o ativa que representa o √≠ndice desse usu√°rio. Imagem do artigo Neural Collaborative Filtering. . Pode-se notar que as representa√ß√µes aqui ser√£o diferentes daquelas encontradas no &quot;collaborative filtering&quot; &quot;vanilla&quot;. A ideia n√£o √© &quot;substituir&quot;, mas &quot;adicionar&quot;. Podemos realizar a fatora√ß√£o da matriz como uma rede neural, concatenar as camadas finais e pass√°-las por uma camada final que produzir√° as previs√µes. Todos juntos, vai parecer . . Arquitetura neural colaborativa. Imagem do artigo Neural Collaborative Filtering. . Esses dois modelos diferentes juntos formam a arquitetura geral. Eles podem, no entanto, ser treinados separadamente e ajustados no final (aprendizagem por transfer√™ncia). Isso pode acelerar o tempo de treinamento e produzir melhores resultados. . &#128170; Ganhos . A quest√£o √©: a complexidade adicional vale a pena? . Ao comparar experimentalmente os resultados usando o conjunto de dados MovieLens, os resultados entre o LightFM e o neural collaborative filtering foram semelhantes (sinta-se √† vontade para dar uma olhada na demo!), com um custo computacional consideravelmente maior para redes neurais. . Mas, por outro lado, obtemos mais flexibilidade com o modelo. Al√©m do mais, podemos integrar facilmente um modelo de content based filtering (usando redes neurais) para formar um sistema de recomenda√ß√£o h√≠brido no Tensorflow. E a complexidade dos problemas que podem ser resolvidos tamb√©m aumenta - problemas complexos de PNL ou de s√©rie temporal podem ser integrados. Poder√≠amos, por exemplo, alavancar modelos pr√©-treinados como o BERT e integr√°-los neste sistema h√≠brido de recomenda√ß√£o. . &#128187; Demo . Caso esteja rodando o notebook n√£o esque√ßa de fazer o download das bibliotecas e inicie o tensorboard no background: . No terminal . pip install tensorflow lightfm pandas tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs . ou no notebook . !pip install tensorflow lightfm pandas . %load_ext tensorboard !tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs &amp; . Os dados . Interaction matrix: [[5 3 4 3 3 5 4 0 5 3] [4 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [4 0 0 0 0 0 0 4 4 0] [0 0 0 5 0 0 5 5 5 4] [0 0 0 0 0 0 3 0 0 0] [0 0 0 0 0 0 4 0 0 0] [4 0 0 4 0 0 0 0 4 0]] . # collapse for dataset in [&quot;test&quot;, &quot;train&quot;]: data[dataset] = (data[dataset].toarray() &gt; 0).astype(&quot;int8&quot;) # Make the ratings binary print(&quot;Interaction matrix:&quot;) print(data[&quot;train&quot;][:10, :10]) print(&quot; nRatings:&quot;) unique_ratings = np.unique(data[&quot;train&quot;]) print(unique_ratings) . . Interaction matrix: [[1 1 1 1 1 1 1 0 1 1] [1 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [1 0 0 0 0 0 0 1 1 0] [0 0 0 1 0 0 1 1 1 1] [0 0 0 0 0 0 1 0 0 0] [0 0 0 0 0 0 1 0 0 0] [1 0 0 1 0 0 0 0 1 0]] Ratings: [0 1] . from typing import List def wide_to_long(wide: np.array, possible_ratings: List[int]) -&gt; np.array: &quot;&quot;&quot;Go from wide table to long. :param wide: wide array with user-item interactions :param possible_ratings: list of possible ratings that we may have.&quot;&quot;&quot; def _get_ratings(arr: np.array, rating: int) -&gt; np.array: &quot;&quot;&quot;Generate long array for the rating provided :param arr: wide array with user-item interactions :param rating: the rating that we are interested&quot;&quot;&quot; idx = np.where(arr == rating) return np.vstack( (idx[0], idx[1], np.ones(idx[0].size, dtype=&quot;int8&quot;) * rating) ).T long_arrays = [] for r in possible_ratings: long_arrays.append(_get_ratings(wide, r)) return np.vstack(long_arrays) . long_train = wide_to_long(data[&quot;train&quot;], unique_ratings) df_train = pd.DataFrame(long_train, columns=[&quot;user_id&quot;, &quot;item_id&quot;, &quot;interaction&quot;]) . All interactions: . user_id item_id interaction . 0 0 | 7 | 0 | . 1 0 | 10 | 0 | . 2 0 | 19 | 0 | . 3 0 | 20 | 0 | . 4 0 | 26 | 0 | . Only positive interactions: . user_id item_id interaction . 1511499 0 | 0 | 1 | . 1511500 0 | 1 | 1 | . 1511501 0 | 2 | 1 | . 1511502 0 | 3 | 1 | . 1511503 0 | 4 | 1 | . O modelo (Neural Collaborative Filtering) . import tensorflow.keras as keras from tensorflow.keras.layers import ( Concatenate, Dense, Embedding, Flatten, Input, Multiply, ) from tensorflow.keras.models import Model from tensorflow.keras.regularizers import l2 def create_ncf( number_of_users: int, number_of_items: int, latent_dim_mf: int = 4, latent_dim_mlp: int = 32, reg_mf: int = 0, reg_mlp: int = 0.01, dense_layers: List[int] = [8, 4], reg_layers: List[int] = [0.01, 0.01], activation_dense: str = &quot;relu&quot;, ) -&gt; keras.Model: # input layer user = Input(shape=(), dtype=&quot;int32&quot;, name=&quot;user_id&quot;) item = Input(shape=(), dtype=&quot;int32&quot;, name=&quot;item_id&quot;) # embedding layers mf_user_embedding = Embedding( input_dim=number_of_users, output_dim=latent_dim_mf, name=&quot;mf_user_embedding&quot;, embeddings_initializer=&quot;RandomNormal&quot;, embeddings_regularizer=l2(reg_mf), input_length=1, ) mf_item_embedding = Embedding( input_dim=number_of_items, output_dim=latent_dim_mf, name=&quot;mf_item_embedding&quot;, embeddings_initializer=&quot;RandomNormal&quot;, embeddings_regularizer=l2(reg_mf), input_length=1, ) mlp_user_embedding = Embedding( input_dim=number_of_users, output_dim=latent_dim_mlp, name=&quot;mlp_user_embedding&quot;, embeddings_initializer=&quot;RandomNormal&quot;, embeddings_regularizer=l2(reg_mlp), input_length=1, ) mlp_item_embedding = Embedding( input_dim=number_of_items, output_dim=latent_dim_mlp, name=&quot;mlp_item_embedding&quot;, embeddings_initializer=&quot;RandomNormal&quot;, embeddings_regularizer=l2(reg_mlp), input_length=1, ) # MF vector mf_user_latent = Flatten()(mf_user_embedding(user)) mf_item_latent = Flatten()(mf_item_embedding(item)) mf_cat_latent = Multiply()([mf_user_latent, mf_item_latent]) # MLP vector mlp_user_latent = Flatten()(mlp_user_embedding(user)) mlp_item_latent = Flatten()(mlp_item_embedding(item)) mlp_cat_latent = Concatenate()([mlp_user_latent, mlp_item_latent]) mlp_vector = mlp_cat_latent # build dense layers for model for i in range(len(dense_layers)): layer = Dense( dense_layers[i], activity_regularizer=l2(reg_layers[i]), activation=activation_dense, name=&quot;layer%d&quot; % i, ) mlp_vector = layer(mlp_vector) predict_layer = Concatenate()([mf_cat_latent, mlp_vector]) result = Dense( 1, activation=&quot;sigmoid&quot;, kernel_initializer=&quot;lecun_uniform&quot;, name=&quot;interaction&quot; ) output = result(predict_layer) model = Model( inputs=[user, item], outputs=[output], ) return model . # collapse from tensorflow.keras.optimizers import Adam n_users, n_items = data[&quot;train&quot;].shape ncf_model = create_ncf(n_users, n_items) ncf_model.compile( optimizer=Adam(), loss=&quot;binary_crossentropy&quot;, metrics=[ tf.keras.metrics.TruePositives(name=&quot;tp&quot;), tf.keras.metrics.FalsePositives(name=&quot;fp&quot;), tf.keras.metrics.TrueNegatives(name=&quot;tn&quot;), tf.keras.metrics.FalseNegatives(name=&quot;fn&quot;), tf.keras.metrics.BinaryAccuracy(name=&quot;accuracy&quot;), tf.keras.metrics.Precision(name=&quot;precision&quot;), tf.keras.metrics.Recall(name=&quot;recall&quot;), tf.keras.metrics.AUC(name=&quot;auc&quot;), ], ) ncf_model._name = &quot;neural_collaborative_filtering&quot; ncf_model.summary() . . Model: &#34;neural_collaborative_filtering&#34; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== user_id (InputLayer) [(None,)] 0 __________________________________________________________________________________________________ item_id (InputLayer) [(None,)] 0 __________________________________________________________________________________________________ mlp_user_embedding (Embedding) (None, 32) 30176 user_id[0][0] __________________________________________________________________________________________________ mlp_item_embedding (Embedding) (None, 32) 53824 item_id[0][0] __________________________________________________________________________________________________ flatten_2 (Flatten) (None, 32) 0 mlp_user_embedding[0][0] __________________________________________________________________________________________________ flatten_3 (Flatten) (None, 32) 0 mlp_item_embedding[0][0] __________________________________________________________________________________________________ mf_user_embedding (Embedding) (None, 4) 3772 user_id[0][0] __________________________________________________________________________________________________ mf_item_embedding (Embedding) (None, 4) 6728 item_id[0][0] __________________________________________________________________________________________________ concatenate (Concatenate) (None, 64) 0 flatten_2[0][0] flatten_3[0][0] __________________________________________________________________________________________________ flatten (Flatten) (None, 4) 0 mf_user_embedding[0][0] __________________________________________________________________________________________________ flatten_1 (Flatten) (None, 4) 0 mf_item_embedding[0][0] __________________________________________________________________________________________________ layer0 (Dense) (None, 8) 520 concatenate[0][0] __________________________________________________________________________________________________ multiply (Multiply) (None, 4) 0 flatten[0][0] flatten_1[0][0] __________________________________________________________________________________________________ layer1 (Dense) (None, 4) 36 layer0[0][0] __________________________________________________________________________________________________ concatenate_1 (Concatenate) (None, 8) 0 multiply[0][0] layer1[0][0] __________________________________________________________________________________________________ interaction (Dense) (None, 1) 9 concatenate_1[0][0] ================================================================================================== Total params: 95,065 Trainable params: 95,065 Non-trainable params: 0 __________________________________________________________________________________________________ . def make_tf_dataset( df: pd.DataFrame, targets: List[str], val_split: float = 0.1, batch_size: int = 512, seed=42, ): &quot;&quot;&quot;Make TensorFlow dataset from Pandas DataFrame. :param df: input DataFrame - only contains features and target(s) :param targets: list of columns names corresponding to targets :param val_split: fraction of the data that should be used for validation :param batch_size: batch size for training :param seed: random seed for shuffling data - set to `None` to not shuffle&quot;&quot;&quot; n_val = round(df.shape[0] * val_split) if seed: # shuffle all the rows x = df.sample(frac=1, random_state=seed).to_dict(&quot;series&quot;) else: x = df.to_dict(&quot;series&quot;) y = dict() for t in targets: y[t] = x.pop(t) ds = tf.data.Dataset.from_tensor_slices((x, y)) ds_val = ds.take(n_val).batch(batch_size) ds_train = ds.skip(n_val).batch(batch_size) return ds_train, ds_val . # create train and validation datasets ds_train, ds_val = make_tf_dataset(df_train, [&quot;interaction&quot;]) . %%time # define logs and callbacks logdir = os.path.join(&quot;logs&quot;, datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;)) tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1) early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor=&quot;val_loss&quot;, patience=0 ) train_hist = ncf_model.fit( ds_train, validation_data=ds_val, epochs=N_EPOCHS, callbacks=[tensorboard_callback, early_stopping_callback], verbose=1, ) . Epoch 1/10 . /usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &#34; . 1/2789 [..............................] - ETA: 0s - loss: 2.7761 - tp: 1.0000 - fp: 32.0000 - tn: 459.0000 - fn: 20.0000 - accuracy: 0.8984 - precision: 0.0303 - recall: 0.0476 - auc: 0.4325WARNING:tensorflow:From /usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01. Instructions for updating: use `tf.profiler.experimental.stop` instead. WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0254s). Check your callbacks. 2789/2789 [==============================] - 9s 3ms/step - loss: 0.2318 - tp: 1691.0000 - fp: 789.0000 - tn: 1359625.0000 - fn: 65408.0000 - accuracy: 0.9536 - precision: 0.6819 - recall: 0.0252 - auc: 0.8033 - val_loss: 0.1408 - val_tp: 902.0000 - val_fp: 416.0000 - val_tn: 150669.0000 - val_fn: 6626.0000 - val_accuracy: 0.9556 - val_precision: 0.6844 - val_recall: 0.1198 - val_auc: 0.9020 Epoch 2/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1279 - tp: 11668.0000 - fp: 6340.0000 - tn: 1354074.0000 - fn: 55431.0000 - accuracy: 0.9567 - precision: 0.6479 - recall: 0.1739 - auc: 0.9164 - val_loss: 0.1236 - val_tp: 1532.0000 - val_fp: 854.0000 - val_tn: 150231.0000 - val_fn: 5996.0000 - val_accuracy: 0.9568 - val_precision: 0.6421 - val_recall: 0.2035 - val_auc: 0.9195 Epoch 3/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1191 - tp: 13715.0000 - fp: 7758.0000 - tn: 1352656.0000 - fn: 53384.0000 - accuracy: 0.9572 - precision: 0.6387 - recall: 0.2044 - auc: 0.9254 - val_loss: 0.1198 - val_tp: 1587.0000 - val_fp: 835.0000 - val_tn: 150250.0000 - val_fn: 5941.0000 - val_accuracy: 0.9573 - val_precision: 0.6552 - val_recall: 0.2108 - val_auc: 0.9232 Epoch 4/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1148 - tp: 14333.0000 - fp: 7576.0000 - tn: 1352838.0000 - fn: 52766.0000 - accuracy: 0.9577 - precision: 0.6542 - recall: 0.2136 - auc: 0.9293 - val_loss: 0.1160 - val_tp: 1610.0000 - val_fp: 797.0000 - val_tn: 150288.0000 - val_fn: 5918.0000 - val_accuracy: 0.9577 - val_precision: 0.6689 - val_recall: 0.2139 - val_auc: 0.9267 Epoch 5/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1114 - tp: 15531.0000 - fp: 7649.0000 - tn: 1352765.0000 - fn: 51568.0000 - accuracy: 0.9585 - precision: 0.6700 - recall: 0.2315 - auc: 0.9335 - val_loss: 0.1138 - val_tp: 1777.0000 - val_fp: 877.0000 - val_tn: 150208.0000 - val_fn: 5751.0000 - val_accuracy: 0.9582 - val_precision: 0.6696 - val_recall: 0.2361 - val_auc: 0.9294 Epoch 6/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1088 - tp: 16978.0000 - fp: 8344.0000 - tn: 1352070.0000 - fn: 50121.0000 - accuracy: 0.9590 - precision: 0.6705 - recall: 0.2530 - auc: 0.9373 - val_loss: 0.1120 - val_tp: 1927.0000 - val_fp: 975.0000 - val_tn: 150110.0000 - val_fn: 5601.0000 - val_accuracy: 0.9585 - val_precision: 0.6640 - val_recall: 0.2560 - val_auc: 0.9317 Epoch 7/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1069 - tp: 18235.0000 - fp: 9057.0000 - tn: 1351357.0000 - fn: 48864.0000 - accuracy: 0.9594 - precision: 0.6681 - recall: 0.2718 - auc: 0.9401 - val_loss: 0.1108 - val_tp: 2033.0000 - val_fp: 1031.0000 - val_tn: 150054.0000 - val_fn: 5495.0000 - val_accuracy: 0.9589 - val_precision: 0.6635 - val_recall: 0.2701 - val_auc: 0.9338 Epoch 8/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1055 - tp: 19127.0000 - fp: 9621.0000 - tn: 1350793.0000 - fn: 47972.0000 - accuracy: 0.9597 - precision: 0.6653 - recall: 0.2851 - auc: 0.9421 - val_loss: 0.1100 - val_tp: 2113.0000 - val_fp: 1069.0000 - val_tn: 150016.0000 - val_fn: 5415.0000 - val_accuracy: 0.9591 - val_precision: 0.6640 - val_recall: 0.2807 - val_auc: 0.9350 Epoch 9/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1046 - tp: 19749.0000 - fp: 9984.0000 - tn: 1350430.0000 - fn: 47350.0000 - accuracy: 0.9598 - precision: 0.6642 - recall: 0.2943 - auc: 0.9435 - val_loss: 0.1094 - val_tp: 2154.0000 - val_fp: 1107.0000 - val_tn: 149978.0000 - val_fn: 5374.0000 - val_accuracy: 0.9591 - val_precision: 0.6605 - val_recall: 0.2861 - val_auc: 0.9357 Epoch 10/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1040 - tp: 20082.0000 - fp: 10168.0000 - tn: 1350246.0000 - fn: 47017.0000 - accuracy: 0.9599 - precision: 0.6639 - recall: 0.2993 - auc: 0.9445 - val_loss: 0.1090 - val_tp: 2191.0000 - val_fp: 1126.0000 - val_tn: 149959.0000 - val_fn: 5337.0000 - val_accuracy: 0.9593 - val_precision: 0.6605 - val_recall: 0.2910 - val_auc: 0.9364 CPU times: user 2min 29s, sys: 43.4 s, total: 3min 12s Wall time: 1min 20s . long_test = wide_to_long(data[&quot;train&quot;], unique_ratings) df_test = pd.DataFrame(long_test, columns=[&quot;user_id&quot;, &quot;item_id&quot;, &quot;interaction&quot;]) ds_test, _ = make_tf_dataset(df_test, [&quot;interaction&quot;], val_split=0, seed=None) . %%time ncf_predictions = ncf_model.predict(ds_test) df_test[&quot;ncf_predictions&quot;] = ncf_predictions . CPU times: user 3.81 s, sys: 210 ms, total: 4.02 s Wall time: 3.69 s . user_id item_id interaction ncf_predictions . 0 0 | 7 | 0 | 0.523643 | . 1 0 | 10 | 0 | 0.719504 | . 2 0 | 19 | 0 | 0.100669 | . 3 0 | 20 | 0 | 0.123813 | . 4 0 | 26 | 0 | 0.102480 | . # collapse data[&quot;ncf_predictions&quot;] = df_test.pivot( index=&quot;user_id&quot;, columns=&quot;item_id&quot;, values=&quot;ncf_predictions&quot; ).values print(&quot;Neural collaborative filtering predictions&quot;) print(data[&quot;ncf_predictions&quot;][:10, :4]) . . Neural collaborative filtering predictions [[7.7809501e-01 3.4897393e-01 2.3736593e-01 7.5093412e-01] [1.5352371e-01 1.8476248e-03 2.3163706e-02 3.6399364e-03] [4.6624422e-02 4.7096610e-04 1.2840241e-02 1.1576419e-04] [8.5962385e-02 1.4925003e-03 6.1967373e-03 5.1632524e-04] [5.8516884e-01 2.8336483e-01 7.5634271e-02 3.0715367e-01] [4.0988737e-01 2.2669524e-02 1.0599941e-02 4.0282601e-01] [6.0177052e-01 6.6075641e-01 7.8367621e-02 8.1673837e-01] [4.9012059e-01 8.9323461e-02 6.3689947e-03 6.7939401e-02] [1.5069479e-01 1.3713539e-03 2.8979778e-04 2.2239387e-03] [5.0181168e-01 6.9155514e-02 3.4887791e-02 4.8452517e-01]] . precision_ncf = tf.keras.metrics.Precision(top_k=TOP_K) recall_ncf = tf.keras.metrics.Recall(top_k=TOP_K) precision_ncf.update_state(data[&quot;test&quot;], data[&quot;ncf_predictions&quot;]) recall_ncf.update_state(data[&quot;test&quot;], data[&quot;ncf_predictions&quot;]) print( f&quot;At K = {TOP_K}, we have a precision of {precision_ncf.result().numpy():.5f} and a recall of {recall_ncf.result().numpy():.5f}&quot; ) . At K = 5, we have a precision of 0.10859 and a recall of 0.06487 . %%time # LightFM model norm = lambda x: (x - np.min(x)) / np.ptp(x) lightfm_model = LightFM(loss=&quot;warp&quot;) lightfm_model.fit(sparse.coo_matrix(data[&quot;train&quot;]), epochs=N_EPOCHS) lightfm_predictions = lightfm_model.predict( df_test[&quot;user_id&quot;].values, df_test[&quot;item_id&quot;].values ) df_test[&quot;lightfm_predictions&quot;] = lightfm_predictions wide_predictions = df_test.pivot( index=&quot;user_id&quot;, columns=&quot;item_id&quot;, values=&quot;lightfm_predictions&quot; ).values data[&quot;lightfm_predictions&quot;] = norm(wide_predictions) # compute the metrics precision_lightfm = tf.keras.metrics.Precision(top_k=TOP_K) recall_lightfm = tf.keras.metrics.Recall(top_k=TOP_K) precision_lightfm.update_state(data[&quot;test&quot;], data[&quot;lightfm_predictions&quot;]) recall_lightfm.update_state(data[&quot;test&quot;], data[&quot;lightfm_predictions&quot;]) print( f&quot;At K = {TOP_K}, we have a precision of {precision_lightfm.result().numpy():.5f} and a recall of {recall_lightfm.result().numpy():.5f}&quot; ) . At K = 5, we have a precision of 0.10541 and a recall of 0.06297 CPU times: user 1.01 s, sys: 235 ms, total: 1.25 s Wall time: 858 ms .",
            "url": "https://murilo-cunha.github.io/inteligencia-superficial/demo/neural%20networks/deep%20learning/recommender%20systems/paper/2020/12/17/neural_collaborative_filter.html",
            "relUrl": "/demo/neural%20networks/deep%20learning/recommender%20systems/paper/2020/12/17/neural_collaborative_filter.html",
            "date": " ‚Ä¢ Dec 17, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Recommender systems - Neural Collaborative Filtering",
            "content": "Download dependencies and run tensorboard in the background: . !pip install tensorflow lightfm pandas . %load_ext tensorboard !tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs &amp; . Data . Interaction matrix: [[5 3 4 3 3 5 4 0 5 3] [4 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [4 0 0 0 0 0 0 4 4 0] [0 0 0 5 0 0 5 5 5 4] [0 0 0 0 0 0 3 0 0 0] [0 0 0 0 0 0 4 0 0 0] [4 0 0 4 0 0 0 0 4 0]] . # collapse for dataset in [&quot;test&quot;, &quot;train&quot;]: data[dataset] = (data[dataset].toarray() &gt; 0).astype(&quot;int8&quot;) # Make the ratings binary print(&quot;Interaction matrix:&quot;) print(data[&quot;train&quot;][:10, :10]) print(&quot; nRatings:&quot;) unique_ratings = np.unique(data[&quot;train&quot;]) print(unique_ratings) . . Interaction matrix: [[1 1 1 1 1 1 1 0 1 1] [1 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] [1 0 0 0 0 0 0 1 1 0] [0 0 0 1 0 0 1 1 1 1] [0 0 0 0 0 0 1 0 0 0] [0 0 0 0 0 0 1 0 0 0] [1 0 0 1 0 0 0 0 1 0]] Ratings: [0 1] . from typing import List def wide_to_long(wide: np.array, possible_ratings: List[int]) -&gt; np.array: &quot;&quot;&quot;Go from wide table to long. :param wide: wide array with user-item interactions :param possible_ratings: list of possible ratings that we may have.&quot;&quot;&quot; def _get_ratings(arr: np.array, rating: int) -&gt; np.array: &quot;&quot;&quot;Generate long array for the rating provided :param arr: wide array with user-item interactions :param rating: the rating that we are interested&quot;&quot;&quot; idx = np.where(arr == rating) return np.vstack( (idx[0], idx[1], np.ones(idx[0].size, dtype=&quot;int8&quot;) * rating) ).T long_arrays = [] for r in possible_ratings: long_arrays.append(_get_ratings(wide, r)) return np.vstack(long_arrays) . long_train = wide_to_long(data[&quot;train&quot;], unique_ratings) df_train = pd.DataFrame(long_train, columns=[&quot;user_id&quot;, &quot;item_id&quot;, &quot;interaction&quot;]) . All interactions: . user_id item_id interaction . 0 0 | 7 | 0 | . 1 0 | 10 | 0 | . 2 0 | 19 | 0 | . 3 0 | 20 | 0 | . 4 0 | 26 | 0 | . Only positive interactions: . user_id item_id interaction . 1511499 0 | 0 | 1 | . 1511500 0 | 1 | 1 | . 1511501 0 | 2 | 1 | . 1511502 0 | 3 | 1 | . 1511503 0 | 4 | 1 | . The model (Neural Collaborative Filtering) . import tensorflow.keras as keras from tensorflow.keras.layers import ( Concatenate, Dense, Embedding, Flatten, Input, Multiply, ) from tensorflow.keras.models import Model from tensorflow.keras.regularizers import l2 def create_ncf( number_of_users: int, number_of_items: int, latent_dim_mf: int = 4, latent_dim_mlp: int = 32, reg_mf: int = 0, reg_mlp: int = 0.01, dense_layers: List[int] = [8, 4], reg_layers: List[int] = [0.01, 0.01], activation_dense: str = &quot;relu&quot;, ) -&gt; keras.Model: # input layer user = Input(shape=(), dtype=&quot;int32&quot;, name=&quot;user_id&quot;) item = Input(shape=(), dtype=&quot;int32&quot;, name=&quot;item_id&quot;) # embedding layers mf_user_embedding = Embedding( input_dim=number_of_users, output_dim=latent_dim_mf, name=&quot;mf_user_embedding&quot;, embeddings_initializer=&quot;RandomNormal&quot;, embeddings_regularizer=l2(reg_mf), input_length=1, ) mf_item_embedding = Embedding( input_dim=number_of_items, output_dim=latent_dim_mf, name=&quot;mf_item_embedding&quot;, embeddings_initializer=&quot;RandomNormal&quot;, embeddings_regularizer=l2(reg_mf), input_length=1, ) mlp_user_embedding = Embedding( input_dim=number_of_users, output_dim=latent_dim_mlp, name=&quot;mlp_user_embedding&quot;, embeddings_initializer=&quot;RandomNormal&quot;, embeddings_regularizer=l2(reg_mlp), input_length=1, ) mlp_item_embedding = Embedding( input_dim=number_of_items, output_dim=latent_dim_mlp, name=&quot;mlp_item_embedding&quot;, embeddings_initializer=&quot;RandomNormal&quot;, embeddings_regularizer=l2(reg_mlp), input_length=1, ) # MF vector mf_user_latent = Flatten()(mf_user_embedding(user)) mf_item_latent = Flatten()(mf_item_embedding(item)) mf_cat_latent = Multiply()([mf_user_latent, mf_item_latent]) # MLP vector mlp_user_latent = Flatten()(mlp_user_embedding(user)) mlp_item_latent = Flatten()(mlp_item_embedding(item)) mlp_cat_latent = Concatenate()([mlp_user_latent, mlp_item_latent]) mlp_vector = mlp_cat_latent # build dense layers for model for i in range(len(dense_layers)): layer = Dense( dense_layers[i], activity_regularizer=l2(reg_layers[i]), activation=activation_dense, name=&quot;layer%d&quot; % i, ) mlp_vector = layer(mlp_vector) predict_layer = Concatenate()([mf_cat_latent, mlp_vector]) result = Dense( 1, activation=&quot;sigmoid&quot;, kernel_initializer=&quot;lecun_uniform&quot;, name=&quot;interaction&quot; ) output = result(predict_layer) model = Model( inputs=[user, item], outputs=[output], ) return model . # collapse from tensorflow.keras.optimizers import Adam n_users, n_items = data[&quot;train&quot;].shape ncf_model = create_ncf(n_users, n_items) ncf_model.compile( optimizer=Adam(), loss=&quot;binary_crossentropy&quot;, metrics=[ tf.keras.metrics.TruePositives(name=&quot;tp&quot;), tf.keras.metrics.FalsePositives(name=&quot;fp&quot;), tf.keras.metrics.TrueNegatives(name=&quot;tn&quot;), tf.keras.metrics.FalseNegatives(name=&quot;fn&quot;), tf.keras.metrics.BinaryAccuracy(name=&quot;accuracy&quot;), tf.keras.metrics.Precision(name=&quot;precision&quot;), tf.keras.metrics.Recall(name=&quot;recall&quot;), tf.keras.metrics.AUC(name=&quot;auc&quot;), ], ) ncf_model._name = &quot;neural_collaborative_filtering&quot; ncf_model.summary() . . Model: &#34;neural_collaborative_filtering&#34; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== user_id (InputLayer) [(None,)] 0 __________________________________________________________________________________________________ item_id (InputLayer) [(None,)] 0 __________________________________________________________________________________________________ mlp_user_embedding (Embedding) (None, 32) 30176 user_id[0][0] __________________________________________________________________________________________________ mlp_item_embedding (Embedding) (None, 32) 53824 item_id[0][0] __________________________________________________________________________________________________ flatten_2 (Flatten) (None, 32) 0 mlp_user_embedding[0][0] __________________________________________________________________________________________________ flatten_3 (Flatten) (None, 32) 0 mlp_item_embedding[0][0] __________________________________________________________________________________________________ mf_user_embedding (Embedding) (None, 4) 3772 user_id[0][0] __________________________________________________________________________________________________ mf_item_embedding (Embedding) (None, 4) 6728 item_id[0][0] __________________________________________________________________________________________________ concatenate (Concatenate) (None, 64) 0 flatten_2[0][0] flatten_3[0][0] __________________________________________________________________________________________________ flatten (Flatten) (None, 4) 0 mf_user_embedding[0][0] __________________________________________________________________________________________________ flatten_1 (Flatten) (None, 4) 0 mf_item_embedding[0][0] __________________________________________________________________________________________________ layer0 (Dense) (None, 8) 520 concatenate[0][0] __________________________________________________________________________________________________ multiply (Multiply) (None, 4) 0 flatten[0][0] flatten_1[0][0] __________________________________________________________________________________________________ layer1 (Dense) (None, 4) 36 layer0[0][0] __________________________________________________________________________________________________ concatenate_1 (Concatenate) (None, 8) 0 multiply[0][0] layer1[0][0] __________________________________________________________________________________________________ interaction (Dense) (None, 1) 9 concatenate_1[0][0] ================================================================================================== Total params: 95,065 Trainable params: 95,065 Non-trainable params: 0 __________________________________________________________________________________________________ . def make_tf_dataset( df: pd.DataFrame, targets: List[str], val_split: float = 0.1, batch_size: int = 512, seed=42, ): &quot;&quot;&quot;Make TensorFlow dataset from Pandas DataFrame. :param df: input DataFrame - only contains features and target(s) :param targets: list of columns names corresponding to targets :param val_split: fraction of the data that should be used for validation :param batch_size: batch size for training :param seed: random seed for shuffling the data - setting to `None` will not shuffle the data&quot;&quot;&quot; n_val = round(df.shape[0] * val_split) if seed: # shuffle all the rows x = df.sample(frac=1, random_state=seed).to_dict(&quot;series&quot;) else: x = df.to_dict(&quot;series&quot;) y = dict() for t in targets: y[t] = x.pop(t) ds = tf.data.Dataset.from_tensor_slices((x, y)) ds_val = ds.take(n_val).batch(batch_size) ds_train = ds.skip(n_val).batch(batch_size) return ds_train, ds_val . # create train and validation datasets ds_train, ds_val = make_tf_dataset(df_train, [&quot;interaction&quot;]) . %%time # define logs and callbacks logdir = os.path.join(&quot;logs&quot;, datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;)) tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1) early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor=&quot;val_loss&quot;, patience=0 ) train_hist = ncf_model.fit( ds_train, validation_data=ds_val, epochs=N_EPOCHS, callbacks=[tensorboard_callback, early_stopping_callback], verbose=1, ) . Epoch 1/10 . /usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. &#34;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &#34; . 1/2789 [..............................] - ETA: 0s - loss: 2.7761 - tp: 1.0000 - fp: 32.0000 - tn: 459.0000 - fn: 20.0000 - accuracy: 0.8984 - precision: 0.0303 - recall: 0.0476 - auc: 0.4325WARNING:tensorflow:From /usr/local/anaconda3/envs/inteligencia-superficial/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01. Instructions for updating: use `tf.profiler.experimental.stop` instead. WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0254s). Check your callbacks. 2789/2789 [==============================] - 9s 3ms/step - loss: 0.2318 - tp: 1691.0000 - fp: 789.0000 - tn: 1359625.0000 - fn: 65408.0000 - accuracy: 0.9536 - precision: 0.6819 - recall: 0.0252 - auc: 0.8033 - val_loss: 0.1408 - val_tp: 902.0000 - val_fp: 416.0000 - val_tn: 150669.0000 - val_fn: 6626.0000 - val_accuracy: 0.9556 - val_precision: 0.6844 - val_recall: 0.1198 - val_auc: 0.9020 Epoch 2/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1279 - tp: 11668.0000 - fp: 6340.0000 - tn: 1354074.0000 - fn: 55431.0000 - accuracy: 0.9567 - precision: 0.6479 - recall: 0.1739 - auc: 0.9164 - val_loss: 0.1236 - val_tp: 1532.0000 - val_fp: 854.0000 - val_tn: 150231.0000 - val_fn: 5996.0000 - val_accuracy: 0.9568 - val_precision: 0.6421 - val_recall: 0.2035 - val_auc: 0.9195 Epoch 3/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1191 - tp: 13715.0000 - fp: 7758.0000 - tn: 1352656.0000 - fn: 53384.0000 - accuracy: 0.9572 - precision: 0.6387 - recall: 0.2044 - auc: 0.9254 - val_loss: 0.1198 - val_tp: 1587.0000 - val_fp: 835.0000 - val_tn: 150250.0000 - val_fn: 5941.0000 - val_accuracy: 0.9573 - val_precision: 0.6552 - val_recall: 0.2108 - val_auc: 0.9232 Epoch 4/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1148 - tp: 14333.0000 - fp: 7576.0000 - tn: 1352838.0000 - fn: 52766.0000 - accuracy: 0.9577 - precision: 0.6542 - recall: 0.2136 - auc: 0.9293 - val_loss: 0.1160 - val_tp: 1610.0000 - val_fp: 797.0000 - val_tn: 150288.0000 - val_fn: 5918.0000 - val_accuracy: 0.9577 - val_precision: 0.6689 - val_recall: 0.2139 - val_auc: 0.9267 Epoch 5/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1114 - tp: 15531.0000 - fp: 7649.0000 - tn: 1352765.0000 - fn: 51568.0000 - accuracy: 0.9585 - precision: 0.6700 - recall: 0.2315 - auc: 0.9335 - val_loss: 0.1138 - val_tp: 1777.0000 - val_fp: 877.0000 - val_tn: 150208.0000 - val_fn: 5751.0000 - val_accuracy: 0.9582 - val_precision: 0.6696 - val_recall: 0.2361 - val_auc: 0.9294 Epoch 6/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1088 - tp: 16978.0000 - fp: 8344.0000 - tn: 1352070.0000 - fn: 50121.0000 - accuracy: 0.9590 - precision: 0.6705 - recall: 0.2530 - auc: 0.9373 - val_loss: 0.1120 - val_tp: 1927.0000 - val_fp: 975.0000 - val_tn: 150110.0000 - val_fn: 5601.0000 - val_accuracy: 0.9585 - val_precision: 0.6640 - val_recall: 0.2560 - val_auc: 0.9317 Epoch 7/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1069 - tp: 18235.0000 - fp: 9057.0000 - tn: 1351357.0000 - fn: 48864.0000 - accuracy: 0.9594 - precision: 0.6681 - recall: 0.2718 - auc: 0.9401 - val_loss: 0.1108 - val_tp: 2033.0000 - val_fp: 1031.0000 - val_tn: 150054.0000 - val_fn: 5495.0000 - val_accuracy: 0.9589 - val_precision: 0.6635 - val_recall: 0.2701 - val_auc: 0.9338 Epoch 8/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1055 - tp: 19127.0000 - fp: 9621.0000 - tn: 1350793.0000 - fn: 47972.0000 - accuracy: 0.9597 - precision: 0.6653 - recall: 0.2851 - auc: 0.9421 - val_loss: 0.1100 - val_tp: 2113.0000 - val_fp: 1069.0000 - val_tn: 150016.0000 - val_fn: 5415.0000 - val_accuracy: 0.9591 - val_precision: 0.6640 - val_recall: 0.2807 - val_auc: 0.9350 Epoch 9/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1046 - tp: 19749.0000 - fp: 9984.0000 - tn: 1350430.0000 - fn: 47350.0000 - accuracy: 0.9598 - precision: 0.6642 - recall: 0.2943 - auc: 0.9435 - val_loss: 0.1094 - val_tp: 2154.0000 - val_fp: 1107.0000 - val_tn: 149978.0000 - val_fn: 5374.0000 - val_accuracy: 0.9591 - val_precision: 0.6605 - val_recall: 0.2861 - val_auc: 0.9357 Epoch 10/10 2789/2789 [==============================] - 8s 3ms/step - loss: 0.1040 - tp: 20082.0000 - fp: 10168.0000 - tn: 1350246.0000 - fn: 47017.0000 - accuracy: 0.9599 - precision: 0.6639 - recall: 0.2993 - auc: 0.9445 - val_loss: 0.1090 - val_tp: 2191.0000 - val_fp: 1126.0000 - val_tn: 149959.0000 - val_fn: 5337.0000 - val_accuracy: 0.9593 - val_precision: 0.6605 - val_recall: 0.2910 - val_auc: 0.9364 CPU times: user 2min 29s, sys: 43.4 s, total: 3min 12s Wall time: 1min 20s . long_test = wide_to_long(data[&quot;train&quot;], unique_ratings) df_test = pd.DataFrame(long_test, columns=[&quot;user_id&quot;, &quot;item_id&quot;, &quot;interaction&quot;]) ds_test, _ = make_tf_dataset(df_test, [&quot;interaction&quot;], val_split=0, seed=None) . %%time ncf_predictions = ncf_model.predict(ds_test) df_test[&quot;ncf_predictions&quot;] = ncf_predictions . CPU times: user 3.81 s, sys: 210 ms, total: 4.02 s Wall time: 3.69 s . user_id item_id interaction ncf_predictions . 0 0 | 7 | 0 | 0.523643 | . 1 0 | 10 | 0 | 0.719504 | . 2 0 | 19 | 0 | 0.100669 | . 3 0 | 20 | 0 | 0.123813 | . 4 0 | 26 | 0 | 0.102480 | . # collapse data[&quot;ncf_predictions&quot;] = df_test.pivot( index=&quot;user_id&quot;, columns=&quot;item_id&quot;, values=&quot;ncf_predictions&quot; ).values print(&quot;Neural collaborative filtering predictions&quot;) print(data[&quot;ncf_predictions&quot;][:10, :4]) . . Neural collaborative filtering predictions [[7.7809501e-01 3.4897393e-01 2.3736593e-01 7.5093412e-01] [1.5352371e-01 1.8476248e-03 2.3163706e-02 3.6399364e-03] [4.6624422e-02 4.7096610e-04 1.2840241e-02 1.1576419e-04] [8.5962385e-02 1.4925003e-03 6.1967373e-03 5.1632524e-04] [5.8516884e-01 2.8336483e-01 7.5634271e-02 3.0715367e-01] [4.0988737e-01 2.2669524e-02 1.0599941e-02 4.0282601e-01] [6.0177052e-01 6.6075641e-01 7.8367621e-02 8.1673837e-01] [4.9012059e-01 8.9323461e-02 6.3689947e-03 6.7939401e-02] [1.5069479e-01 1.3713539e-03 2.8979778e-04 2.2239387e-03] [5.0181168e-01 6.9155514e-02 3.4887791e-02 4.8452517e-01]] . precision_ncf = tf.keras.metrics.Precision(top_k=TOP_K) recall_ncf = tf.keras.metrics.Recall(top_k=TOP_K) precision_ncf.update_state(data[&quot;test&quot;], data[&quot;ncf_predictions&quot;]) recall_ncf.update_state(data[&quot;test&quot;], data[&quot;ncf_predictions&quot;]) print( f&quot;At K = {TOP_K}, we have a precision of {precision_ncf.result().numpy():.5f} and a recall of {recall_ncf.result().numpy():.5f}&quot; ) . At K = 5, we have a precision of 0.10859 and a recall of 0.06487 . %%time # LightFM model norm = lambda x: (x - np.min(x)) / np.ptp(x) lightfm_model = LightFM(loss=&quot;warp&quot;) lightfm_model.fit(sparse.coo_matrix(data[&quot;train&quot;]), epochs=N_EPOCHS) lightfm_predictions = lightfm_model.predict( df_test[&quot;user_id&quot;].values, df_test[&quot;item_id&quot;].values ) df_test[&quot;lightfm_predictions&quot;] = lightfm_predictions wide_predictions = df_test.pivot( index=&quot;user_id&quot;, columns=&quot;item_id&quot;, values=&quot;lightfm_predictions&quot; ).values data[&quot;lightfm_predictions&quot;] = norm(wide_predictions) # compute the metrics precision_lightfm = tf.keras.metrics.Precision(top_k=TOP_K) recall_lightfm = tf.keras.metrics.Recall(top_k=TOP_K) precision_lightfm.update_state(data[&quot;test&quot;], data[&quot;lightfm_predictions&quot;]) recall_lightfm.update_state(data[&quot;test&quot;], data[&quot;lightfm_predictions&quot;]) print( f&quot;At K = {TOP_K}, we have a precision of {precision_lightfm.result().numpy():.5f} and a recall of {recall_lightfm.result().numpy():.5f}&quot; ) . At K = 5, we have a precision of 0.10541 and a recall of 0.06297 CPU times: user 1.01 s, sys: 235 ms, total: 1.25 s Wall time: 858 ms .",
            "url": "https://murilo-cunha.github.io/inteligencia-superficial/demo/neural%20networks/deep%20learning/recommender%20systems/paper/2020/09/11/neural_collaborative_filter.html",
            "relUrl": "/demo/neural%20networks/deep%20learning/recommender%20systems/paper/2020/09/11/neural_collaborative_filter.html",
            "date": " ‚Ä¢ Sep 11, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "O que √© 'Gradient Descent' (GD)?",
            "content": "TL;DR . ‚ÄúGradient descent‚Äù √© um algoritmo de otimiza√ß√£o. Ele √© usado pra procurar m√≠nimos de uma fun√ß√£o de modo iterativo, dando passos em dire√ß√£o ao ponto ‚Äúmais baixo‚Äù da fun√ß√£o. . . Gradient Descent . Quando a gente fala em ‚Äúmachine learning‚Äù, ou ‚Äúaprendizado de m√°quina‚Äù, o que eles querem dizer com esse ‚Äúaprender‚Äù? Como que se ensina uma m√°quina? . Ehh‚Ä¶ n√£o √© bem assim. Bem menos sexy, na verdade, mas tamb√©m mais simples. . O Setup . Como que n√≥s podemos medir o qu√£o bom o nosso modelo de machine learning √©? Como comparamos dois modelos diferentes? Existe uma fun√ß√£o que mede exatamente isso, uma fun√ß√£o que mede o erro de cada modelo. Essa fun√ß√£o aceita os par√¢metros do modelo, e retorna o erro do modelo. . . N√≥s temos que saber a derivada dessa nossa fun√ß√£o de erro. Por exemplo, se eu estou jogando curling eu n√£o posso jogar o disco muito forte nem muito fraco. Eu tenho que jogar na for√ßa certa. Se eu conseguir formular uma fun√ß√£o matem√°tica que pega a for√ßa que eu joguei o disco retorna a dist√¢ncia da disco at√© o meu alvo, esse seria a fun√ß√£o do erro, e eu seria o modelo.1 . Aqui n√≥s estamos tentando encontrar o par√¢metro (no nosso exemplo a for√ßa) que vai reduzir o erro (dist√¢ncia) ao m√°ximo. Mas como? . Encontrando o M√≠nimo . Essa pergunta n√£o √© nova. Desde o colegial n√≥s aprendemos a achar m√≠nimos e m√°ximos de uma fun√ß√£o. Mas e se n√≥s tivermos v√°rias vari√°veis? Poder√≠amos usar c√°lculo multivari√°vel, resolvendo um sistema de equa√ß√µes com as derivadas parciais. . O problema √© n√≥s resolvemos essas equa√ß√µes simbolicamente - com vari√°veis simb√≥licas como $x$ e $y$. Mas isso √© muito dif√≠cil para um computador. Algumas calculadoras at√© oferecem essa op√ß√£o mas muitas vezes n√£o encontra resultado. Uma solu√ß√£o mais robusta √© resolver esse problema numericamente. . Al√©m disso, resolvendo numericamente n√≥s evitamos alguns problemas te√≥ricos relacionados ao uso de derivadas de fun√ß√µes que n√£o s√£o cont√≠nuas.2 . A Matem√°tica . Resolver numericamente consiste em computar valores aproximados da nossa fun√ß√£o do erro e iterativamente mudar os par√¢metros de nossa fun√ß√£o, reduzindo esse erro aos poucos (se est√° confuso, calma que vai ficar mais claro at√© o fim desse post). Antes, vamos definir nossos termos: . . Fazendo aproxima√ß√µes e resolvendo numericamente, n√≥s nunca chegamos de verdade no m√≠nimo, mas chegamos bem perto dele. Ou seja, o resultado que temos tamb√©m √© uma aproxima√ß√£o do m√≠nimo da nossa fun√ß√£o. f‚Üíf rightarrowf‚Üí nossa fun√ß√£o que indica o erro do nosso modelo | p‚Üíp rightarrowp‚Üí o par√¢metro da nossa fun√ß√£o | e‚Üíe rightarrowe‚Üí o erro do nosso modelo para esse par√¢metro | . ‚à¥f(p)=e therefore f(p) = e‚à¥f(p)=e . Vamos tamb√©m supor para o nosso exemplo que nossa fun√ß√£o seja concava, bonitinha, com um m√≠nimo s√≥. Alguma coisa assim: . . √â importante perceber que uma fun√ß√£o de erro √© dificilmente assim. Em casos mais pr√°ticos a fun√ß√£o √© bem mais bagun√ßada e t√™m v√°rios m√°ximos e m√≠nimos. E quando isso acontece, esses m√©todos v√£o aproximar um m√≠nimo local, e n√£o global. . Derivadas . Lembrando que uma derivada √© o coeficiente angular de uma linha tangente √† uma curva, se a gente ‚Äúcai‚Äù num ponto aleat√≥rio da nossa fun√ß√£o de erro, a gente percebe que: . Quando estamos ‚Äúa frente‚Äù do nosso ponto mais baixo $ rightarrow$ nossa derivada √© negativa | Quando estamos ‚Äúpra tr√°s‚Äù do nosso ponto mais baixo $ rightarrow$ nossa derivada √© positiva | . . Ou seja, a derivada j√° nos indica pra que lado devemos caminhar. Mais tecnicamente, ela indica se o m√≠nimo da nossa fun√ß√£o est√° num valor maior ou menor do que o nosso $p$ atual! . Mais que isso, quando chegamos mais perto do m√≠nimo nossa derivada tamb√©m diminui. Ou seja, a magnitude da derivada tamb√©m nos fala qu√£o pr√≥ximo desse m√≠nimo n√≥s estamos. . Passo a Passo - O Algor√≠tmo . Agora n√≥s podemos come√ßar de um ponto aleat√≥rio e dar v√°rios passinhos at√© chegar mais e mais perto do nosso m√≠nimo. O nosso passo-a-passo fica assim: . Chuta aonde est√° o ponto mais baixo | Calcule a derivada da fun√ß√£o nesse ponto | Ajuste o seu chute dando um passo em proporcional √† derivada (na dire√ß√£o oposta) | Repita o processo at√© que esteja satisfeito | . . E √© isso! A id√©ia b√°sica √© essa. O resto s√£o detalhes de implementa√ß√£o. . Passo Maior que a Perna - Learning Rate . Mas e se a curva √© muito √≠ngreme e se nosso passo acaba sendo muito largo? E se a gente nunca consegue parar nesse m√≠nimo porque sempre passamos dele? . . N√≥s podemos ajustar o passo, multiplicando por uma constante. Mas temos de tomar cuidado - se o passo for muito pequeno, talvez nunca chegaremos no m√≠nimo (al√©m de demorar muito mais do que o necess√°rio) e se muito largo, e vamos acabar mais longe ainda. Como encontrar o essa constante? Tentativa e erro. Ao contr√°rio do(s) par√¢metro(s) da fun√ß√£o, n√£o encontramos esse valor atrav√©s desse processo automatizado. . Essa constante √© o que chamamos de learning rate (taxa de aprendizado, muitas vezes denominado $ alpha$), e √© um hyperpar√¢metro do modelo. A equa√ß√£o ent√£o fica: . pt‚Üíp_{t} rightarrowpt‚Äã‚Üí o ‚Äúnovo‚Äù par√¢metro | pt‚àí1‚Üíp_{t-1} rightarrowpt‚àí1‚Äã‚Üí o par√¢metro anterior | Œ±‚Üí alpha rightarrowŒ±‚Üí uma constante que multiplicamos pela derivada, controlando o passo - a taxa de aprendizado | mt‚àí1‚Üím_{t-1} rightarrowmt‚àí1‚Äã‚Üí a derivada da fun√ß√£o do erro, que √© a linha tangente √† fun√ß√£o, computada no ponto $p_{t-1}$ | . pt‚Üêpt‚àí1‚àíŒ±mt‚àí1p_{t} leftarrow p_{t-1} - alpha m_{t-1}pt‚Äã‚Üêpt‚àí1‚Äã‚àíŒ±mt‚àí1‚Äã . Os par√¢metros de um modelo s√£o os valores que s√£o otimizados nesse processo. Os hyperpar√¢metros de um modelo s√£o valores que n√£o s√£o otimizados sistematicamente e devemos ajust√°-los manualmente. . Mas os mesmos cuidados aplicam aqui. Essa constante n√£o pode ser muito larga, nem muito pequena. Se muito grande, voltamos a dar passos muito largos, e vice-versa. . V√°rias Vari√°veis - O Gradiente . Por enquanto n√≥s estamos olhando exemplos muito simples. Mas e se tiv√©ssemos muitas vari√°veis no nosso modelo? A id√©ia √© a mesma: computamos a derivada parcial em rela√ß√£o a cada uma dessas vari√°veis, e damos passos nessas dire√ß√µes. Quando empacotamos todas essas derivadas parciais, n√≥s temos o gradiente da nossa fun√ß√£o de erro! Dai que vem o nome gradient descent (ou descida do gradiente). . Em duas dimens√µes, podemos pensar na nossa fun√ß√£o de erro como tentando encontrar o ponto mais baixo de uma cratera, num dia muito nublado - damos um passo pra onde a inclina√ß√£o indica. Quanto mais √≠ngrime, maior o passo que damos. . Inclusive, o gradiente de uma fun√ß√£o sempre aponta pra dire√ß√£o de maior aumento. Se formos para o sentido oposto do gradiente, estamos indo na dire√ß√£o de maior decl√≠nio. . Ah, e a nossa linha tangente vira um plano tangente √† curva! . . Empacotando os par√¢metros (um para cada dimens√£o) em um vetor, nos ficamos com: . pt‚Éó‚Üí vec{p_{t}} rightarrowpt‚Äã‚Äã‚Üí os ‚Äúnovos‚Äù par√¢metros (um para cada dimens√£o) | pt‚àí1‚Éó‚Üí vec{p_{t-1}} rightarrowpt‚àí1‚Äã‚Äã‚Üí os par√¢metros ‚Äúanteriores‚Äù (um para cada dimens√£o) | ‚àáf(pt‚àí1‚Éó)‚Üí nabla f( vec{p_{t-1}}) rightarrow‚àáf(pt‚àí1‚Äã‚Äã)‚Üí o gradiente da fun√ß√£o do erro, que s√£o as derivadas parciais de cada uma das dimens√µes do nosso problema, computadas no ponto $ vec{p_{t-1}}$ | Œ±‚Üí alpha rightarrowŒ±‚Üí uma constante que multiplicamos pelo gradiente, controlando o passo - a taxa de aprendizado | . pt‚Éó‚Üêpt‚àí1‚Éó‚àíŒ±‚àáf(pt‚àí1‚Éó) vec{p_{t}} leftarrow vec{p_{t-1}} - alpha nabla f( vec{p_{t-1}})pt‚Äã . ‚Äã‚Üêpt‚àí1‚Äã . ‚Äã‚àíŒ±‚àáf(pt‚àí1‚Äã . ‚Äã) . Eu sei que se voc√™ n√£o est√° 100% confort√°vel com √°lgebra linear isso pode assustar um pouco. Mas o que essa equa√ß√£o descreve s√£o v√°rias equa√ß√µes iguais √† que apresentamos acima. Uma para cada dimens√£o do nosso problema. Ou seja: . d‚Üíd rightarrowd‚Üí a dimens√£o do par√¢metro | pt(d)‚Üíp_{t}^{(d)} rightarrowpt(d)‚Äã‚Üí o ‚Äúnovo‚Äù par√¢metro da dimens√£o $d$ | pt‚àí1(d)‚Üíp_{t-1}^{(d)} rightarrowpt‚àí1(d)‚Äã‚Üí o par√¢metro anterior da dimens√£o $d$ | Œ±‚Üí alpha rightarrowŒ±‚Üí uma constante que multiplicamos pela derivada, controlando o passo - a taxa de aprendizado | ‚àÇ‚àÇpt‚àí1(d)f(pt‚àí1(d)))‚Üí frac{ partial}{ partial p_{t-1}^{(d)}} f (p_{t-1}^{(d)})) rightarrow‚àÇpt‚àí1(d)‚Äã‚àÇ‚Äãf(pt‚àí1(d)‚Äã))‚Üí a derivadas parcial da nossa fun√ß√£o do erro para a dimens√£o $d$, em rela√ß√£o ao par√¢metro anterior da mesma dimens√£o | . pt(d)‚Üêpt‚àí1(d)‚àíŒ±‚àÇ‚àÇpt‚àí1(d)f(pt‚àí1(d))p_{t}^{(d)} leftarrow p_{t-1}^{(d)} - alpha frac{ partial}{ partial p_{t-1}^{(d)}} f (p_{t-1}^{(d)})pt(d)‚Äã‚Üêpt‚àí1(d)‚Äã‚àíŒ±‚àÇpt‚àí1(d)‚Äã‚àÇ‚Äãf(pt‚àí1(d)‚Äã) . Eu sei que ainda √© muita letrinha, e que pode ser confuso. Respira fundo e vai com calma. Reveja isso quanto necess√°rio e verifica que isso faz sentido. Quando falarmos de regress√£o linear isso tamb√©m vai ficar mais claro. . ‚ÄúAprendizado‚Äù? . Esse processo de reduzir o erro de um modelo √© o que chamamos de ‚Äúaprendizado‚Äù, ou como ‚Äúensinamos‚Äù do modelo! . Bom, eu sei que √© meio decepcionante. Ningu√©m aprende assim. Mas calma, deixe-me explicar. em machine learning, essa fun√ß√£o de erro √© formulada a partir dos exemplos. Essa fun√ß√£o muda de modelo para modelo. . No exemplo do come√ßo do post, quando eu jogo curling, uma fun√ß√£o de erro poderia ser a soma de todas as dist√¢ncias do centro do alvo at√© o meu disco. Ou seja, cada experi√™ncia minha √© levada em considera√ß√£o quando eu tento minimizar meu erro. . Quando seguimos as etapas desse algor√≠tmo, cada passo √© dado depois de computar a derivada. E a derivada leva em considera√ß√£o todos as nossas tentat√≠vas (exemplos)3. Ou seja, reduzimos o erro depois de ‚Äúvisitarmos‚Äù essas experi√™ncias passadas. Do mesmo jeito que eu, quanto mais vezes eu tento, vou melhorando (reduzindo meu erro). . Tudo depende de como definimos ‚Äúaprender‚Äù. Se eu definir como ‚Äúa melhora de performance com nossas experi√™ncias‚Äù, at√© faz sentido falar que a m√°quina aprende. . Al√©m disso, quando falamos de stochastic gradient descent (descida do gradiente estoc√°stico), ou online learning, n√≥s visitamos uma parte dos exemplos pra cada passo, o que traz mais essa id√©ia de melhorar performance quando o modelo ‚Äúv√™‚Äù novas observa√ß√µes, e refor√ßando essa ideia de aprendizado. . N√£o vamos falar de stochastic gradient descent ou online learning nesse post. Ali√°s, existem muitas varia√ß√µes desses algoritmos de otimiza√ß√£o. Na pr√°tica, ningu√©m acaba usando gradient descent desse jeito que eu expliquei por haver op√ß√µes melhores, mas a id√©ia central de todos os algoritmos √© a mesma. . Outras Implementa√ß√µes . Existem maneiras de melhorar a performance desses algoritmos. Por exemplo, n√≥s poder√≠amos reduzir o learning rate a cada passo, usar uma id√©ia de momento, usar mais que apenas a primeira derivada, etc. Algum desses algor√≠tmos s√£o: . M√©todos de Newton | M√©todos de Quasi-Newton | Adam | . N√£o vamos explicar esses m√©todos nesse post. Mas cada um deles procura melhorar um aspecto do gradient descent, de uma maneira ou outra, mas todos tem suas ressalvas. As vezes eles acabam demorando mais pra chegar no nosso m√≠nimo, ou ent√£o n√£o conseguimos us√°-los quando o n√∫mero de dimens√µes aumenta, entre outros. . Nomenclatura . N√≥s falamos bastante dessa ‚Äúfun√ß√£o do erro‚Äù. Mas existem v√°rios nomes que tamb√©m s√£o usados: . Fun√ß√£o do erro (error function) | Fun√ß√£o objetivo (objective function) | Fun√ß√£o de custo (cost function) | Fun√ß√£o de energia (energy function) | Fun√ß√£o de perda (loss function) | . Em todos os casos, n√≥s procuramos o m√≠nimo dessa fun√ß√£o. . Al√©m disso, n√≥s falamos sobre ‚Äúaprender‚Äù. Em machine learning, esse processo tamb√©m √© chamado por nomes diferentes: . Aprender (learn) | Treinar (train) | Ajustar (fit) | . Explicamos o que s√£o os par√¢metros e os hyperpar√¢metros. Esse par√¢metros s√£o chamados de: . Par√¢metros (parameters) - duh | Pesos (weights) | . S√£o diferentes nomes, mas eles se referem √†s mesmas coisas! . Footnotes . Obviamente esse exemplo √© muito simples. Existem muitos outros fatores que deveriam ser levados em considera√ß√£o. Mas ainda assim esse √© um problema comum em machine learning - muitas vezes existe bastante incerteza de que os dados obtidos possuem as informa√ß√µes necess√°rias para qualquer tipo de previs√µes.¬†&#8617; . | Nossa fun√ß√£o de erro n√£o precisa ser diferenci√°vel em todos os pontos. A fun√ß√£o $f(x)= mid x mid$ por exemplo n√£o √© diferenci√°vel quando $x=0$, mas como estamos resolvendo numericamente isso n√£o √© um problema (nunca vamos cair no ponto $0.00000‚Ä¶0$, mas talvez no $0.00000‚Ä¶1$, etc.). Mesmo que fosse, n√≥s poder√≠amos, se quis√©ssemos, definir uma ‚Äúderivada‚Äù no ponto $x=0$.¬†&#8617; . | Para ver mais sobre como formulamos essas fun√ß√µes de erro (custo) a partir de nossas observa√ß√µes, veja um exemplo sobre regress√£o linear ou regress√£o log√≠stica.¬†&#8617; . |",
            "url": "https://murilo-cunha.github.io/inteligencia-superficial/machine%20learning/algoritmos%20de%20otimiza%C3%A7%C3%A3o/aprendizado%20supervisionado/2020/04/12/grad_desc.html",
            "relUrl": "/machine%20learning/algoritmos%20de%20otimiza%C3%A7%C3%A3o/aprendizado%20supervisionado/2020/04/12/grad_desc.html",
            "date": " ‚Ä¢ Apr 12, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Sobre",
          "content": "Sobre mim . Ol√°, eu nome √© Murilo Cunha . Atualmente, eu moro e trabalho na Europa, como um engenheiro de machine learning. . Eu nasci em S√£o Paulo, onde vivi at√© o colegial. De l√° fui para os Estados Unidos, onde me formei em engenharia mec√¢nica com concentra√ß√£o em mecatr√¥nica. No meu √∫ltimo ano da faculdade, eu tive a oportunidade de trabalhar em engenharia industrial. Foi l√° que eu percebi que n√£o era exatamente isso com o que eu queria fazer. Resolvi fazer um mestrado em intelig√™ncia artificial na B√©lgica, pa√≠s onde moro hoje em dia. . Ao longo dos anos, eu percebi que por mais que exista bastante conte√∫do legal sobre machine learning online, a maior parte √© em ingl√™s. Tamb√©m entendo que por mais que muitos dominem a l√≠ngua inglesa, ter o conte√∫do em portugu√™s facilitaria muito o aprendizado de muita gente. . Meu objetivo √© ajudar a compartilhar o conte√∫do que eu fui acumulando durante meus anos de aluno e de trabalho. Tudo em portugu√™s, de maneira simples e clara. . Agradecimentos . Gostaria de agradecer meu irm√£o, Marcelo Cunha e Alicja Mazur que sempre me mandam coisas pra ler e rever. Aprendi muita coisa com eles e mais que isso eles me ajudam com a revis√£o do conte√∫do do blog. . Sobre o blog . O blog foi criado usando fastpages, criado pela fast.ai. Essas p√°ginas foram elaboradas a partir de Github Pages, usando Github Actions para criar posts de Markdown, Jupyter Notebooks out at√© Microsoft Word. Tudo baseado em Jekyll Pages. . O blog √© uma p√°gina Jekyll, que facilita na cria√ß√£o de p√°ginas est√°ticas usando Markdown. Com o Github Pages, fica f√°cil hostear essas paginas no Github, de gra√ßa. Em cima disso muitas pessoas desenvolveram maneiras de fazer as p√°ginas mais interativas - coment√°rios, pesquisa, etc. E o fastpages criou em cima de tudo isso, disponibilizando a cria√ß√£o de posts com Jupyter Notebooks, Markdown e at√© Microsoft Word. . Inclusive, todos os posts criados com Jupyter Notebooks podem ser reproduzidos pra voc√™ brincar e experimentar com o c√≥digo, usando Google Colab ou Binder. Se dispon√≠vel, voc√™ s√≥ precisa clicar nos √≠cones no come√ßo do post. . . . Sobre as anima√ß√µes . Nas anima√ß√µes eu uso uma biblioteca em Python chamada Manim, criada pelo Grant Sanderson, mesmo criador do canal 3Blue1Brown. . As anima√ß√µes criadas por mim s√£o inspiradas pelo 3Blue1Brown, um excelente canal para v√≠deos educativos sobre matem√°tica - c√°lculo, algebra linear e at√© redes neurais. Pessoalmente, acho um dos melhores educadores do Youtube. Recomendo bastante. .",
          "url": "https://murilo-cunha.github.io/inteligencia-superficial/sobre/",
          "relUrl": "/sobre/",
          "date": ""
      }
      
  

  

  

  
  

  

  
  

  

  
  

  
  

}